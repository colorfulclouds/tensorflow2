{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.layers import Input , Dense , Reshape , Flatten , Dropout\n",
    "from keras.layers import BatchNormalization , Activation , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D , Conv2D\n",
    "\n",
    "from keras.models import Sequential , Model\n",
    "\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====\n",
    "WIDTH = 96\n",
    "HEIGHT = 96\n",
    "CHANNEL = 3\n",
    "\n",
    "LATENT_DIM = 100 #latent variable z\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = 'faces/'\n",
    "\n",
    "load_index = 0\n",
    "\n",
    "images_name = os.listdir(PATH)\n",
    "\n",
    "IMAGES_COUNT = len(images_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#========\n",
    "def load_image(batch_size = BATCH_SIZE):\n",
    "    global load_index\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        images.append(matplotlib.image.imread(PATH + images_name[(load_index + i) % IMAGES_COUNT]))\n",
    "    \n",
    "    load_index += batch_size\n",
    "    \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.img_rows = 96\n",
    "        self.img_cols = 96\n",
    "        self.channels = 3 #black and white\n",
    "        \n",
    "        self.img_shape = (self.img_rows , self.img_cols , self.channels)\n",
    "        self.latent_dim = 100 #z dimension 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002 , beta_1=0.5)\n",
    "        \n",
    "        #构造 判别器\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        #判别器\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                  optimizer=optimizer , metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "        #构造 生成器\n",
    "        self.generator = self.build_generator()\n",
    "        z = Input(shape=(self.latent_dim , ))\n",
    "        #使用噪音生成一个图像\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        #在combined的整体模型中 将判别器固定起来 不进行训练\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        #使用判别器判断利用噪音生成的图像的真假\n",
    "        validity = self.discriminator(img) #因为判别器最后一层是sigmoid 所以返回一个0-1之间的实数\n",
    "        \n",
    "        self.combines = Model(z , validity)\n",
    "        self.combines.compile(loss='binary_crossentropy' , optimizer=optimizer)\n",
    "        \n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Flatten(input_shape = self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(Dense(1 , activation='sigmoid'))\n",
    "        \n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img , validity)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "        #从100维的噪音中生成出来\n",
    "        model.add(Dense(256 , input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape) , activation='tanh')) #构造同尺寸的图片\n",
    "        model.add(Reshape(self.img_shape)) #Flatten的逆操作\n",
    "        \n",
    "        noise = Input(shape=(self.latent_dim,)) #100 dimension\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise , img)\n",
    "    \n",
    "\n",
    "    def train(self , epochs , sample_internal=50):\n",
    "        X_train=load_image()\n",
    "        \n",
    "        X_train = X_train/127.5 - 1\n",
    "        #X_train = np.expand_dims(X_train , axis=3)\n",
    "        \n",
    "        valid = np.ones((BATCH_SIZE , 1)) #real img\n",
    "        fake = np.ones((BATCH_SIZE , 1)) #fake img\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            #in paper\n",
    "            #训练判别器\n",
    "            #idx = np.random.randint(0 , X_train.shape[0] , size=BATCH_SIZE) #随机的batch\n",
    "            #imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.normal(0,1,size=(BATCH_SIZE , self.latent_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            #d_loss_real = self.discriminator.train_on_batch(imgs , valid)\n",
    "            d_loss_real = self.discriminator.train_on_batch(X_train , valid)\n",
    "\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs , fake)\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real , d_loss_fake)\n",
    "            \n",
    "            \n",
    "            #训练生成器\n",
    "            noise = np.random.normal(0,1,size=(BATCH_SIZE , self.latent_dim))\n",
    "            \n",
    "            g_loss = self.combines.train_on_batch(noise , valid)\n",
    "            \n",
    "            print('%d Discriminator loss%f acc%f Generator loss%f' % (epoch , d_loss[0] , d_loss[1] , g_loss))\n",
    "            \n",
    "            if epoch%sample_internal == 0:\n",
    "                self.sample_images(epoch)\n",
    "        \n",
    "    def sample_images(self , epoch):\n",
    "        r , c = 5 , 5\n",
    "        noise = np.random.normal(0,1,size=(r*c , self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        gen_imgs = (gen_imgs+1)*127.5\n",
    "        \n",
    "        fig , axs = plt.subplots(r,c)\n",
    "        \n",
    "        cnt = 0\n",
    "        \n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i][j].imshow(gen_imgs[cnt , :,:,0])# , cmap=plt.cm.gray)\n",
    "                axs[i][j].axis('off')\n",
    "                \n",
    "                cnt+=1\n",
    "        \n",
    "        fig.savefig('No.%d.png' % epoch)\n",
    "        #plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cedb056390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fig , axs = plt.subplots(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gan = GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan.train(epochs=20000 , sample_internal=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
