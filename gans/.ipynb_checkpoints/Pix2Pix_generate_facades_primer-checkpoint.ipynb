{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense ,  BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D , Conv2DTranspose , UpSampling2D , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU , PReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "from keras.initializers import truncated_normal , constant , random_normal\n",
    "\n",
    "from keras.optimizers import Adam , RMSprop\n",
    "\n",
    "#残差块使用\n",
    "from keras.layers import Add\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#导入存在的模型\n",
    "from keras.applications import VGG16 , VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#数据集中的图像都是256*256*3的\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "CHANNEL = 3\n",
    "\n",
    "SHAPE = (WIDTH , HEIGHT , CHANNEL)\n",
    "\n",
    "\n",
    "LATENT_DIM = 100 #latent variable z sample from normal distribution\n",
    "\n",
    "BATCH_SIZE = 4 #crazy!!! slow turtle\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = '../dataset/facades/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 3 #几行决定显示几个测试样例\n",
    "COL = 3 #3列是因为要显示 原始图像 faded图像 由G生成的原始图像\n",
    "\n",
    "TRAIN_PATH = glob(PATH + 'train/*')\n",
    "TEST_PATH = glob(PATH + 'test/*')\n",
    "VAL_PATH = glob(PATH + 'val/*')\n",
    "\n",
    "#卷积使用 基卷积核大小\n",
    "G_filters = 64\n",
    "D_filters = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch = int(HEIGHT/(2**4)) #16\n",
    "disc_patch = (patch , patch , 1) #16*16*1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(batch_size = BATCH_SIZE , training = True):\n",
    "    #随机在图片库中挑选\n",
    "    if training:\n",
    "        IMAGES_PATH = TRAIN_PATH\n",
    "    else:\n",
    "        IMAGES_PATH = TEST_PATH\n",
    "        #IMAGES_PATH = VAL_PATH\n",
    "        \n",
    "    images = np.random.choice(IMAGES_PATH , size=batch_size)\n",
    "    \n",
    "    original_facades = []\n",
    "    faded_facades = []\n",
    "    \n",
    "    for i in images:\n",
    "        image = scipy.misc.imread(i , mode='RGB').astype(np.float)\n",
    "        \n",
    "        height , width , channel = image.shape\n",
    "        \n",
    "        origin = image[: , :int(width/2) , :] #样本图像的左侧\n",
    "        fade = image[: , int(width/2): , :] #样本图像的右侧\n",
    "        \n",
    "        #尽管原图像不是指定的大小 下面将强制将图像resize\n",
    "        origin = scipy.misc.imresize(origin , size=(HEIGHT , WIDTH))\n",
    "        fade = scipy.misc.imresize(fade , size=(HEIGHT,WIDTH))\n",
    "        \n",
    "        #随机性地对训练样本进行 左右反转\n",
    "        if training and np.random.random()<0.5:\n",
    "            origin = np.fliplr(origin)\n",
    "            fade = np.fliplr(fade)\n",
    "        \n",
    "        original_facades.append(origin)\n",
    "        faded_facades.append(fade)\n",
    "        \n",
    "    original_facades = np.array(original_facades)/127.5 - 1\n",
    "    faded_facades = np.array(faded_facades)/127.5 - 1\n",
    "    \n",
    "    return original_facades , faded_facades\n",
    "\n",
    "\n",
    "def write_image(epoch):\n",
    "    #生成高分图像时 进行对比显示\n",
    "    original_facades , faded_facades = load_image(batch_size=ROW , training=False)\n",
    "    fake_faded_facades = generator_i.predict(faded_facades) #使用G来生成高分图像 使用低分图像生成原始的高分图像 但是难免有偏差 细节表现\n",
    "    \n",
    "    original_facades = original_facades*0.5+0.5\n",
    "    faded_facades = faded_facades*0.5+0.5\n",
    "    fake_faded_facades = fake_faded_facades*0.5+0.5\n",
    "    \n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    count=0\n",
    "    \n",
    "    axes[0][0].imshow(faded_facades[0])\n",
    "    axes[0][0].set_title('faded')\n",
    "    axes[0][0].axis('off')\n",
    "\n",
    "    axes[0][1].imshow(original_facades[0])\n",
    "    axes[0][1].set_title('original')\n",
    "    axes[0][1].axis('off')\n",
    "    \n",
    "    axes[0][2].imshow(fake_faded_facades[0])\n",
    "    axes[0][2].set_title('generated original')\n",
    "    axes[0][2].axis('off')\n",
    "\n",
    "    axes[1][0].imshow(faded_facades[1])\n",
    "    axes[1][0].set_title('faded')\n",
    "    axes[1][0].axis('off')\n",
    "\n",
    "    axes[1][1].imshow(original_facades[1])\n",
    "    axes[1][1].set_title('original')\n",
    "    axes[1][1].axis('off')\n",
    "    \n",
    "    axes[1][2].imshow(fake_faded_facades[1])\n",
    "    axes[1][2].set_title('generated original')\n",
    "    axes[1][2].axis('off')\n",
    "\n",
    "    axes[2][0].imshow(faded_facades[2])\n",
    "    axes[2][0].set_title('faded')\n",
    "    axes[2][0].axis('off')\n",
    "    \n",
    "    axes[2][1].imshow(original_facades[2])\n",
    "    axes[2][1].set_title('original')\n",
    "    axes[2][1].axis('off')\n",
    "    \n",
    "    axes[2][2].imshow(fake_faded_facades[2])\n",
    "    axes[2][2].set_title('generated original')\n",
    "    axes[2][2].axis('off')\n",
    "            \n",
    "    fig.savefig('facades_pix2pix/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "    \n",
    "    \n",
    "#    for i in range(ROW):\n",
    "#        fig = plt.pyplot.figure()\n",
    "#        plt.pyplot.imshow(low_resolution_image[i])\n",
    "#        fig.savefig('celeba_srgan/No.%d_low_resolution%d.png' % (epoch , i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input_data , output_size , filter_size=4 , batch_norm = True):\n",
    "    h = Conv2D(output_size , filter_size , strides=(2,2) , padding='same')(input_data)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    if batch_norm:\n",
    "        h = BatchNormalization(momentum=0.8)(h)\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "#实现U-Net使用 需要网络的跳连接\n",
    "def deconv2d(input_data , skip_input , output_size , filter_size=4 , dropout_rate=0.0):\n",
    "    h = UpSampling2D(size=2)(input_data)\n",
    "    h = Conv2D(output_size , filter_size , strides=(1,1) , padding='same')(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "    if dropout_rate:\n",
    "        h = Dropout(rate=dropout_rate)(h)\n",
    "    \n",
    "    h = BatchNormalization(momentum=0.8)(h)\n",
    "    h =  Concatenate()([h , skip_input]) #跳连接具体实现\n",
    "\n",
    "    return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G使用encoder-decoder结构 但是需要引入跳连接 即U-Net\n",
    "def generator(G_filters):\n",
    "    #输入为faded的图像 输出为还原后的图像\n",
    "    faded_facades = Input(shape=SHAPE)\n",
    "    \n",
    "    #encoder\n",
    "    d1 = conv2d(faded_facades , G_filters , batch_norm=False)\n",
    "    d2 = conv2d(d1 , G_filters*2)\n",
    "    d3 = conv2d(d2 , G_filters*4)\n",
    "    d4 = conv2d(d3 , G_filters*8)\n",
    "    d5 = conv2d(d4 , G_filters*8)\n",
    "    d6 = conv2d(d5 , G_filters*8)\n",
    "    d7 = conv2d(d6 , G_filters*8)\n",
    "\n",
    "    #decoder\n",
    "    u1 = deconv2d(d7 , d6 , G_filters*8)\n",
    "    u2 = deconv2d(u1 , d5 , G_filters*8)\n",
    "    u3 = deconv2d(u2 , d4 , G_filters*8)\n",
    "    u4 = deconv2d(u3 , d3 , G_filters*4)\n",
    "    u5 = deconv2d(u4 , d2 , G_filters*2)\n",
    "    u6 = deconv2d(u5 , d1 , G_filters)\n",
    "    \n",
    "    u7 = UpSampling2D(size=(2,2))(u6)\n",
    "    original_facades = Conv2D(filters=CHANNEL , kernel_size=(4,4) , strides=(1,1) , padding='same' , activation='tanh')(u7) #还原后的图像\n",
    "    \n",
    "    return Model(faded_facades , original_facades , name='generator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(D_filters):\n",
    "    original_facades = Input(shape=SHAPE) #原始图像\n",
    "    faded_facades = Input(shape=SHAPE) #fade的图像\n",
    "    \n",
    "    original_faded = Concatenate()([original_facades , faded_facades])\n",
    "    \n",
    "    h1 = conv2d(original_faded , output_size=D_filters , batch_norm=False)\n",
    "    h2 = conv2d(h1 , output_size=D_filters*2)\n",
    "    h3 = conv2d(h2 , output_size=D_filters*4)\n",
    "    h4 = conv2d(h3 , output_size=D_filters*8)\n",
    "    \n",
    "    validity =  Conv2D(1 , kernel_size=(4,4) , strides=(1,1) , padding='same')(h4)\n",
    "    \n",
    "    return Model([original_facades , faded_facades] , validity , name='discriminator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.0002 , beta_1=0.5)\n",
    "\n",
    "discriminator_i = discriminator(D_filters)\n",
    "discriminator_i.compile(optimizer = adam , loss='mse' , metrics=['accuracy'])\n",
    "\n",
    "\n",
    "generator_i = generator(G_filters)\n",
    "\n",
    "original_facades = Input(shape=SHAPE)\n",
    "faded_facades = Input(shape=SHAPE)\n",
    "\n",
    "fake_original_facades = generator_i(faded_facades) #使用G来将faded的图像生成为original的图像\n",
    "\n",
    "#freeze D\n",
    "discriminator_i.trainable = False\n",
    "\n",
    "validity = discriminator_i([original_facades , fake_original_facades])\n",
    "\n",
    "combined = Model([original_facades , faded_facades] , [validity , fake_original_facades])\n",
    "combined.compile(optimizer=adam , loss=['mse' , 'mae'] , loss_weights=[1 , 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\misc\\pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "C:\\Anaconda3\\lib\\site-packages\\scipy\\misc\\pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss:7.832784 accu:0.166504 gene_loss[mse]:72.484123 gene_loss[mae]:7.555965\n",
      "epoch:1 loss:5.259813 accu:0.217285 gene_loss[mse]:83.311386 gene_loss[mae]:6.121254\n",
      "epoch:2 loss:5.132148 accu:0.161133 gene_loss[mse]:67.606712 gene_loss[mae]:4.105922\n",
      "epoch:3 loss:5.752017 accu:0.212891 gene_loss[mse]:66.070778 gene_loss[mae]:5.652461\n",
      "epoch:4 loss:4.760056 accu:0.183105 gene_loss[mse]:58.208942 gene_loss[mae]:2.663837\n",
      "epoch:5 loss:2.574740 accu:0.247070 gene_loss[mse]:57.938038 gene_loss[mae]:1.558858\n",
      "epoch:6 loss:1.478557 accu:0.317871 gene_loss[mse]:46.534214 gene_loss[mae]:1.975221\n",
      "epoch:7 loss:1.406126 accu:0.319824 gene_loss[mse]:53.109257 gene_loss[mae]:2.345088\n",
      "epoch:8 loss:1.495165 accu:0.313477 gene_loss[mse]:51.997662 gene_loss[mae]:1.549183\n",
      "epoch:9 loss:1.417614 accu:0.351562 gene_loss[mse]:47.919079 gene_loss[mae]:1.633167\n",
      "epoch:10 loss:1.183360 accu:0.371094 gene_loss[mse]:47.679951 gene_loss[mae]:1.374204\n",
      "epoch:11 loss:0.819663 accu:0.413574 gene_loss[mse]:42.008179 gene_loss[mae]:1.464726\n",
      "epoch:12 loss:0.918528 accu:0.383789 gene_loss[mse]:40.566555 gene_loss[mae]:1.556705\n",
      "epoch:13 loss:0.961055 accu:0.398926 gene_loss[mse]:44.031429 gene_loss[mae]:1.311118\n",
      "epoch:14 loss:0.750427 accu:0.445312 gene_loss[mse]:52.814747 gene_loss[mae]:1.467406\n",
      "epoch:15 loss:0.831087 accu:0.427734 gene_loss[mse]:43.199596 gene_loss[mae]:1.222517\n",
      "epoch:16 loss:0.717224 accu:0.460938 gene_loss[mse]:43.289825 gene_loss[mae]:1.414416\n",
      "epoch:17 loss:0.800282 accu:0.448730 gene_loss[mse]:39.339283 gene_loss[mae]:1.025691\n",
      "epoch:18 loss:0.589610 accu:0.495117 gene_loss[mse]:41.352364 gene_loss[mae]:0.871864\n",
      "epoch:19 loss:0.641176 accu:0.456543 gene_loss[mse]:37.205746 gene_loss[mae]:1.014322\n",
      "epoch:20 loss:0.646194 accu:0.448730 gene_loss[mse]:38.612221 gene_loss[mae]:1.125654\n",
      "epoch:21 loss:0.653405 accu:0.447754 gene_loss[mse]:45.401035 gene_loss[mae]:1.599555\n",
      "epoch:22 loss:0.795005 accu:0.484375 gene_loss[mse]:48.636993 gene_loss[mae]:1.175385\n",
      "epoch:23 loss:1.208172 accu:0.387207 gene_loss[mse]:35.903690 gene_loss[mae]:1.457089\n",
      "epoch:24 loss:1.042054 accu:0.374512 gene_loss[mse]:45.066994 gene_loss[mae]:1.278250\n",
      "epoch:25 loss:0.847917 accu:0.394043 gene_loss[mse]:37.296589 gene_loss[mae]:1.017666\n",
      "epoch:26 loss:0.672387 accu:0.418457 gene_loss[mse]:37.279675 gene_loss[mae]:0.814156\n",
      "epoch:27 loss:0.614081 accu:0.469727 gene_loss[mse]:33.128498 gene_loss[mae]:0.966298\n",
      "epoch:28 loss:0.489219 accu:0.505371 gene_loss[mse]:40.242439 gene_loss[mae]:0.666849\n",
      "epoch:29 loss:0.473936 accu:0.492188 gene_loss[mse]:41.119984 gene_loss[mae]:1.017735\n",
      "epoch:30 loss:0.586277 accu:0.451660 gene_loss[mse]:35.246311 gene_loss[mae]:0.901651\n",
      "epoch:31 loss:0.422219 accu:0.500977 gene_loss[mse]:36.235920 gene_loss[mae]:0.777557\n",
      "epoch:32 loss:0.470254 accu:0.506348 gene_loss[mse]:39.668388 gene_loss[mae]:0.752643\n",
      "epoch:33 loss:0.516378 accu:0.470215 gene_loss[mse]:36.192780 gene_loss[mae]:1.024588\n",
      "epoch:34 loss:0.665968 accu:0.476562 gene_loss[mse]:34.386990 gene_loss[mae]:1.051583\n",
      "epoch:35 loss:0.493868 accu:0.497559 gene_loss[mse]:42.043968 gene_loss[mae]:0.915816\n",
      "epoch:36 loss:0.520750 accu:0.477539 gene_loss[mse]:38.831020 gene_loss[mae]:0.813502\n",
      "epoch:37 loss:0.437545 accu:0.506348 gene_loss[mse]:40.221489 gene_loss[mae]:0.764312\n",
      "epoch:38 loss:0.401917 accu:0.534668 gene_loss[mse]:41.258564 gene_loss[mae]:0.790217\n",
      "epoch:39 loss:0.504523 accu:0.475098 gene_loss[mse]:43.264534 gene_loss[mae]:0.745506\n",
      "epoch:40 loss:0.349173 accu:0.572266 gene_loss[mse]:39.470318 gene_loss[mae]:0.545060\n",
      "epoch:41 loss:0.341893 accu:0.553711 gene_loss[mse]:44.770424 gene_loss[mae]:0.549073\n",
      "epoch:42 loss:0.414946 accu:0.500977 gene_loss[mse]:43.430740 gene_loss[mae]:0.552474\n",
      "epoch:43 loss:0.491686 accu:0.484375 gene_loss[mse]:34.342541 gene_loss[mae]:0.611736\n",
      "epoch:44 loss:0.394873 accu:0.520020 gene_loss[mse]:39.971973 gene_loss[mae]:0.770386\n",
      "epoch:45 loss:0.431616 accu:0.523926 gene_loss[mse]:34.023262 gene_loss[mae]:0.705554\n",
      "epoch:46 loss:0.417300 accu:0.483398 gene_loss[mse]:42.658119 gene_loss[mae]:0.729018\n",
      "epoch:47 loss:0.419276 accu:0.530762 gene_loss[mse]:37.896976 gene_loss[mae]:0.543867\n",
      "epoch:48 loss:0.546632 accu:0.406738 gene_loss[mse]:31.778070 gene_loss[mae]:0.755754\n",
      "epoch:49 loss:0.420348 accu:0.486328 gene_loss[mse]:37.690655 gene_loss[mae]:0.647716\n",
      "epoch:50 loss:0.375464 accu:0.539551 gene_loss[mse]:32.239410 gene_loss[mae]:0.602285\n",
      "epoch:51 loss:0.374443 accu:0.531738 gene_loss[mse]:37.895267 gene_loss[mae]:0.681154\n",
      "epoch:52 loss:0.389885 accu:0.511719 gene_loss[mse]:41.017838 gene_loss[mae]:0.568380\n",
      "epoch:53 loss:0.451910 accu:0.523926 gene_loss[mse]:42.774879 gene_loss[mae]:0.693876\n",
      "epoch:54 loss:0.395547 accu:0.551758 gene_loss[mse]:42.494846 gene_loss[mae]:0.657267\n",
      "epoch:55 loss:0.427589 accu:0.491699 gene_loss[mse]:39.256241 gene_loss[mae]:0.623242\n",
      "epoch:56 loss:0.390450 accu:0.541016 gene_loss[mse]:34.749413 gene_loss[mae]:0.750867\n",
      "epoch:57 loss:0.406596 accu:0.504883 gene_loss[mse]:35.550735 gene_loss[mae]:0.704801\n",
      "epoch:58 loss:0.316291 accu:0.583008 gene_loss[mse]:46.203144 gene_loss[mae]:0.517108\n",
      "epoch:59 loss:0.442349 accu:0.498535 gene_loss[mse]:39.890324 gene_loss[mae]:0.559875\n",
      "epoch:60 loss:0.887882 accu:0.437012 gene_loss[mse]:45.541004 gene_loss[mae]:2.292492\n",
      "epoch:61 loss:0.733266 accu:0.440918 gene_loss[mse]:36.733433 gene_loss[mae]:0.838614\n",
      "epoch:62 loss:0.566978 accu:0.458984 gene_loss[mse]:37.232685 gene_loss[mae]:0.578455\n",
      "epoch:63 loss:0.372203 accu:0.532227 gene_loss[mse]:34.789501 gene_loss[mae]:0.670382\n",
      "epoch:64 loss:0.365452 accu:0.540039 gene_loss[mse]:41.959202 gene_loss[mae]:0.623514\n",
      "epoch:65 loss:0.390432 accu:0.526855 gene_loss[mse]:41.569176 gene_loss[mae]:0.693997\n",
      "epoch:66 loss:0.420958 accu:0.502930 gene_loss[mse]:31.368067 gene_loss[mae]:0.648946\n",
      "epoch:67 loss:0.318163 accu:0.551758 gene_loss[mse]:37.094143 gene_loss[mae]:0.526175\n",
      "epoch:68 loss:0.378159 accu:0.498047 gene_loss[mse]:39.800060 gene_loss[mae]:0.593050\n",
      "epoch:69 loss:0.442680 accu:0.526855 gene_loss[mse]:40.663460 gene_loss[mae]:0.675359\n",
      "epoch:70 loss:0.360314 accu:0.553711 gene_loss[mse]:45.329887 gene_loss[mae]:0.575374\n",
      "epoch:71 loss:0.916469 accu:0.419922 gene_loss[mse]:38.803070 gene_loss[mae]:0.535899\n",
      "epoch:72 loss:0.555896 accu:0.556641 gene_loss[mse]:41.301586 gene_loss[mae]:0.548532\n",
      "epoch:73 loss:0.410650 accu:0.489746 gene_loss[mse]:35.160213 gene_loss[mae]:0.458407\n",
      "epoch:74 loss:0.464620 accu:0.423340 gene_loss[mse]:35.957890 gene_loss[mae]:0.565193\n",
      "epoch:75 loss:0.350891 accu:0.550781 gene_loss[mse]:37.757511 gene_loss[mae]:0.627015\n",
      "epoch:76 loss:0.536328 accu:0.513672 gene_loss[mse]:32.323036 gene_loss[mae]:0.895296\n",
      "epoch:77 loss:0.307539 accu:0.592285 gene_loss[mse]:35.370937 gene_loss[mae]:0.402858\n",
      "epoch:78 loss:0.275673 accu:0.618164 gene_loss[mse]:32.465065 gene_loss[mae]:0.411180\n",
      "epoch:79 loss:0.291258 accu:0.582031 gene_loss[mse]:36.791195 gene_loss[mae]:0.388347\n",
      "epoch:80 loss:0.285684 accu:0.567871 gene_loss[mse]:40.069931 gene_loss[mae]:0.447316\n",
      "epoch:81 loss:0.348047 accu:0.506348 gene_loss[mse]:43.248592 gene_loss[mae]:0.534739\n",
      "epoch:82 loss:0.368118 accu:0.507324 gene_loss[mse]:35.263805 gene_loss[mae]:0.684242\n",
      "epoch:83 loss:0.361297 accu:0.552246 gene_loss[mse]:36.410954 gene_loss[mae]:0.708543\n",
      "epoch:84 loss:0.322698 accu:0.560547 gene_loss[mse]:37.733570 gene_loss[mae]:0.480590\n",
      "epoch:85 loss:0.342172 accu:0.533691 gene_loss[mse]:39.590847 gene_loss[mae]:0.386442\n",
      "epoch:86 loss:0.371337 accu:0.539551 gene_loss[mse]:36.987019 gene_loss[mae]:0.640030\n",
      "epoch:87 loss:0.313919 accu:0.585938 gene_loss[mse]:39.887039 gene_loss[mae]:0.417417\n",
      "epoch:88 loss:0.338182 accu:0.553223 gene_loss[mse]:32.499863 gene_loss[mae]:0.730434\n",
      "epoch:89 loss:0.269108 accu:0.604492 gene_loss[mse]:37.171051 gene_loss[mae]:0.354080\n",
      "epoch:90 loss:0.264739 accu:0.635742 gene_loss[mse]:47.125561 gene_loss[mae]:0.415210\n",
      "epoch:91 loss:0.303840 accu:0.570312 gene_loss[mse]:36.963711 gene_loss[mae]:0.387515\n",
      "epoch:92 loss:0.264346 accu:0.618164 gene_loss[mse]:39.486801 gene_loss[mae]:0.395109\n",
      "epoch:93 loss:0.247175 accu:0.629395 gene_loss[mse]:40.248512 gene_loss[mae]:0.522125\n",
      "epoch:94 loss:0.306579 accu:0.575195 gene_loss[mse]:44.386600 gene_loss[mae]:0.376323\n",
      "epoch:95 loss:0.307347 accu:0.568848 gene_loss[mse]:34.903362 gene_loss[mae]:0.581255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:96 loss:0.265455 accu:0.605957 gene_loss[mse]:37.801289 gene_loss[mae]:0.397601\n",
      "epoch:97 loss:0.262490 accu:0.610352 gene_loss[mse]:38.499443 gene_loss[mae]:0.298945\n",
      "epoch:98 loss:0.345510 accu:0.492188 gene_loss[mse]:34.082409 gene_loss[mae]:0.404987\n",
      "epoch:99 loss:0.298820 accu:0.546387 gene_loss[mse]:37.948097 gene_loss[mae]:0.472358\n",
      "epoch:100 loss:0.205752 accu:0.698730 gene_loss[mse]:37.299141 gene_loss[mae]:0.224012\n",
      "epoch:101 loss:0.264847 accu:0.581543 gene_loss[mse]:39.582424 gene_loss[mae]:0.467382\n",
      "epoch:102 loss:0.362912 accu:0.495117 gene_loss[mse]:39.252415 gene_loss[mae]:0.766432\n",
      "epoch:103 loss:0.276628 accu:0.641113 gene_loss[mse]:42.181019 gene_loss[mae]:0.380269\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-2e70d712481f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0moriginal_facades_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mfaded_facades_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfake_original_facades_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaded_facades_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#使用G生成真faded样本的原始样本\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m#训练判别器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mreal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moriginal_facades_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mfaded_facades_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#使用真实的原始图像 训练 label全1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1170\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1172\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#tuple类型相加 相当于cat连接\n",
    "real_labels = np.ones(shape=(BATCH_SIZE , )+disc_patch) #真实样本label为1\n",
    "fake_labels = np.zeros(shape=(BATCH_SIZE , )+disc_patch) #假样本label为0\n",
    "\n",
    "for i in range(10001):\n",
    "    #original_facades_ , faded_facades_ = next(load_batch()) #真实的原始图像和faded图像都是来自真实样本\n",
    "    original_facades_ , faded_facades_ = load_image()\n",
    "    \n",
    "    fake_original_facades_ = generator_i.predict(faded_facades_) #使用G生成真faded样本的原始样本\n",
    "    #训练判别器\n",
    "    real_loss = discriminator_i.train_on_batch([original_facades_ , faded_facades_] , real_labels) #使用真实的原始图像 训练 label全1\n",
    "    fake_loss = discriminator_i.train_on_batch([fake_original_facades_ , faded_facades_] , fake_labels) #使用G生成的假的原始图像 训练 label全0 \n",
    "\n",
    "    loss = np.add(real_loss , fake_loss)/2\n",
    "\n",
    "    #训练生成器\n",
    "    generator_loss = combined.train_on_batch([original_facades_ , faded_facades_] , [real_labels , original_facades_])\n",
    "    print('epoch:%d loss:%f accu:%f gene_loss[mse]:%f gene_loss[mae]:%f' % (i , loss[0] , loss[1] , generator_loss[0] , generator_loss[1]))\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        write_image(i)\n",
    "\n",
    "write_image(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 1.  1.5 2. ]\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3,4]\n",
    "aa=np.array(a)/2\n",
    "\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of cbe5617147190e668d6c5d5026f83318 so we will re-download the data.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574717952/574710816 [==============================] - 729s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1ddbc5e7a58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG19(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
