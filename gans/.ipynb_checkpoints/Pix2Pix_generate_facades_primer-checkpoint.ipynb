{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense ,  BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D , Conv2DTranspose , UpSampling2D , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU , PReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "from keras.initializers import truncated_normal , constant , random_normal\n",
    "\n",
    "from keras.optimizers import Adam , RMSprop\n",
    "\n",
    "#残差块使用\n",
    "from keras.layers import Add\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#导入存在的模型\n",
    "from keras.applications import VGG16 , VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "CHANNEL = 3\n",
    "\n",
    "SHAPE = (WIDTH , HEIGHT , CHANNEL)\n",
    "\n",
    "\n",
    "LATENT_DIM = 100 #latent variable z sample from normal distribution\n",
    "\n",
    "BATCH_SIZE = 4 #crazy!!! slow turtle\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = '../dataset/facades/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 3\n",
    "COL = 3\n",
    "\n",
    "TRAIN_PATH = glob(PATH + 'train/*')\n",
    "TEST_PATH = glob(PATH + 'test/*')\n",
    "\n",
    "#卷积使用 基卷积核大小\n",
    "G_filters = 64\n",
    "D_filters = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch = int(HEIGHT/(2**4)) #16\n",
    "disc_patch = (patch , patch , 1) #16*16*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(batch_size = BATCH_SIZE , training = True):\n",
    "    #随机在图片库中挑选\n",
    "    if training:\n",
    "        IMAGES_PATH = TRAIN_PATH\n",
    "    else:\n",
    "        IMAGES_PATH = TEST_PATH\n",
    "        \n",
    "    images = np.random.choice(IMAGES_PATH , size=batch_size)\n",
    "    \n",
    "    original_facades = []\n",
    "    faded_facades = []\n",
    "    \n",
    "    for i in images:\n",
    "        image = scipy.misc.imread(i , mode='RGB').astype(np.float)\n",
    "        \n",
    "        height , width , channel = image.shape\n",
    "        \n",
    "        origin = image[: , :int(width/2) , :] #样本图像的左侧\n",
    "        fade = image[: , int(width/2): , :] #样本图像的右侧\n",
    "        \n",
    "        #尽管原图像不是指定的大小 下面将强制将图像resize\n",
    "        origin = scipy.misc.imresize(origin , size=(256,256))\n",
    "        fade = scipy.misc.imresize(fade , size=(256,256))\n",
    "        \n",
    "        #随机性地对训练样本进行 左右反转\n",
    "        if training and np.random.random()<0.5:\n",
    "            origin = np.fliplr(origin)\n",
    "            fade = np.fliplr(fade)\n",
    "        \n",
    "        original_facades.append(origin)\n",
    "        faded_facades.append(faded_facades)\n",
    "        \n",
    "    original_facades = np.array(original_facades)/127.5 - 1\n",
    "    faded_facades = np.array(faded_facades)/127.5 - 1\n",
    "    \n",
    "    return original_facades , faded_facades\n",
    "\n",
    "\n",
    "def write_image(epoch):\n",
    "    #生成高分图像时 进行对比显示\n",
    "    original_facades , faded_facades = load_image(batch_size=3 , training=False)\n",
    "    fake_faded_facades = generator_i.predict(faded_facades) #使用G来生成高分图像 使用低分图像生成原始的高分图像 但是难免有偏差 细节表现\n",
    "    \n",
    "    original_facades = original_facades*0.5+0.5\n",
    "    faded_facades = faded_facades*0.5+0.5\n",
    "    fake_faded_facades = fake_faded_facades*0.5+0.5\n",
    "    \n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    count=0\n",
    "    \n",
    "    axes[0][0].imshow(faded_facades[0])\n",
    "    axes[0][0].set_title('faded')\n",
    "    axes[0][0].axis('off')\n",
    "\n",
    "    axes[0][1].imshow(original_facades[0])\n",
    "    axes[0][1].set_title('original')\n",
    "    axes[0][1].axis('off')\n",
    "    \n",
    "    axes[0][2].imshow(fake_faded_facades[0])\n",
    "    axes[0][2].set_title('fake faded')\n",
    "    axes[0][2].axis('off')\n",
    "\n",
    "    axes[1][0].imshow(faded_facades[1])\n",
    "    axes[1][0].set_title('faded')\n",
    "    axes[1][0].axis('off')\n",
    "\n",
    "    axes[1][1].imshow(original_facades[1])\n",
    "    axes[1][1].set_title('original')\n",
    "    axes[1][1].axis('off')\n",
    "    \n",
    "    axes[1][2].imshow(fake_faded_facades[1])\n",
    "    axes[1][2].set_title('fake faded')\n",
    "    axes[1][2].axis('off')\n",
    "\n",
    "    axes[2][0].imshow(faded_facades[2])\n",
    "    axes[2][0].set_title('faded')\n",
    "    axes[2][0].axis('off')\n",
    "    \n",
    "    axes[2][1].imshow(original_facades[2])\n",
    "    axes[2][1].set_title('original')\n",
    "    axes[2][1].axis('off')\n",
    "    \n",
    "    axes[2][2].imshow(fake_faded_facades[2])\n",
    "    axes[2][2].set_title('fake faded')\n",
    "    axes[2][2].axis('off')\n",
    "            \n",
    "    fig.savefig('facades_pix2pix/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "    \n",
    "    \n",
    "#    for i in range(ROW):\n",
    "#        fig = plt.pyplot.figure()\n",
    "#        plt.pyplot.imshow(low_resolution_image[i])\n",
    "#        fig.savefig('celeba_srgan/No.%d_low_resolution%d.png' % (epoch , i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input_data , output_size , filter_size=4 , batch_norm = True):\n",
    "    h = Conv2D(output_size , filter_size , strides=(2,2) , padding='same')(input_data)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    if batch_norm:\n",
    "        h = BatchNormalization(momentum=0.8)(h)\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "#实现U-Net使用 需要网络的跳连接\n",
    "def deconv2d(input_data , skip_input , output_size , filter_size=4 , dropout_rate=0.0):\n",
    "    h = UpSampling2D(size=2)(input_data)\n",
    "    h = Conv2D(output_size , filter_size , strides=(1,1) , padding='same')(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "    if dropout_rate:\n",
    "        h = Dropout(rate=dropout_rate)(h)\n",
    "    \n",
    "    h = BatchNormalization(momentum=0.8)(h)\n",
    "    h =  Concatenate()([h , skip_input]) #跳连接具体实现\n",
    "\n",
    "    return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G使用encoder-decoder结构 但是需要引入跳连接 即U-Net\n",
    "def generator(G_filters):\n",
    "    #输入为faded的图像 输出为还原后的图像\n",
    "    faded_facades = Input(shape=SHAPE)\n",
    "    \n",
    "    #encoder\n",
    "    d1 = conv2d(faded_facades , G_filters , batch_norm=False)\n",
    "    d2 = conv2d(d1 , G_filters*2)\n",
    "    d3 = conv2d(d2 , G_filters*4)\n",
    "    d4 = conv2d(d3 , G_filters*8)\n",
    "    d5 = conv2d(d4 , G_filters*8)\n",
    "    d6 = conv2d(d5 , G_filters*8)\n",
    "    d7 = conv2d(d6 , G_filters*8)\n",
    "\n",
    "    #decoder\n",
    "    u1 = deconv2d(d7 , d6 , G_filters*8)\n",
    "    u2 = deconv2d(u1 , d5 , G_filters*8)\n",
    "    u3 = deconv2d(u2 , d4 , G_filters*8)\n",
    "    u4 = deconv2d(u3 , d3 , G_filters*4)\n",
    "    u5 = deconv2d(u4 , d2 , G_filters*2)\n",
    "    u6 = deconv2d(u5 , d1 , G_filters)\n",
    "    \n",
    "    u7 = UpSampling2D(size=(2,2))(u6)\n",
    "    original_facades = Conv2D(filters=CHANNEL , kernel_size=(4,4) , strides=(1,1) , padding='same' , activation='tanh')(u7) #还原后的图像\n",
    "    \n",
    "    return Model(faded_facades , original_facades , name='generator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(D_filters):\n",
    "    original_facades = Input(shape=SHAPE) #原始图像\n",
    "    faded_facades = Input(shape=SHAPE) #fade的图像\n",
    "    \n",
    "    original_faded = Concatenate()([original_facades , faded_facades])\n",
    "    \n",
    "    h1 = conv2d(original_faded , output_size=D_filters , batch_norm=False)\n",
    "    h2 = conv2d(h1 , output_size=D_filters*2)\n",
    "    h3 = conv2d(h2 , output_size=D_filters*4)\n",
    "    h4 = conv2d(h3 , output_size=D_filters*8)\n",
    "    \n",
    "    validity =  Conv2D(1 , kernel_size=(4,4) , strides=(1,1) , padding='same')(h4)\n",
    "    \n",
    "    return Model([original_facades , faded_facades] , validity , name='discriminator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.0002 , beta_1=0.5)\n",
    "\n",
    "discriminator_i = discriminator(D_filters)\n",
    "discriminator_i.compile(optimizer = adam , loss='mse' , metrics=['accuracy'])\n",
    "\n",
    "\n",
    "generator_i = generator(G_filters)\n",
    "\n",
    "original_facades = Input(shape=SHAPE)\n",
    "faded_facades = Input(shape=SHAPE)\n",
    "\n",
    "fake_original_facades = generator_i(faded_facades) #使用G来将faded的图像生成为original的图像\n",
    "\n",
    "#freeze D\n",
    "discriminator_i.trainable = False\n",
    "\n",
    "validity = discriminator_i([original_facades , fake_original_facades])\n",
    "\n",
    "combined = Model([original_facades , faded_facades] , [validity , fake_original_facades])\n",
    "combined.compile(optimizer=adam , loss=['mse' , 'mae'] , loss_weights=[1 , 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tuple类型相加 相当于cat连接\n",
    "real_labels = np.ones(shape=(BATCH_SIZE , )+disc_patch) #真实样本label为1\n",
    "fake_labels = np.zeros(shape=(BATCH_SIZE , )+disc_patch) #假样本label为0\n",
    "\n",
    "for i in range(1001):\n",
    "    \n",
    "    original_facades_ , faded_facades_ = load_image() #真实的原始图像和faded图像都是来自真实样本\n",
    "    \n",
    "    fake_original_facades_ = generator_i.predict(faded_facades_) #使用G生成真faded样本的原始样本\n",
    "    #训练判别器\n",
    "    real_loss = discriminator_i.train_on_batch([original_facades_ , faded_facades_] , real_labels) #使用真实的原始图像 训练 label全1\n",
    "    fake_loss = discriminator_i.train_on_batch([fake_original_facades_ , faded_facades_] , fake_labels) #使用G生成的假的原始图像 训练 label全0 \n",
    "\n",
    "    loss = np.add(real_loss , fake_loss)/2\n",
    "\n",
    "    #训练生成器\n",
    "    generator_loss = combined_model_i.train_on_batch([original_facades_ , faded_facades_] , [real_labels , original_facades_])\n",
    "\n",
    "    print('epoch:%d loss:%f accu:%f gene_loss[mse]:%f gene_loss[mae]:%f' % (i , loss[0] , loss[1] , generator_loss[0] , generator_loss[1]))\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        write_image(i)\n",
    "    #write_image_mnist(i)\n",
    "    \n",
    "write_image(999)\n",
    "#write_image_mnist(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of cbe5617147190e668d6c5d5026f83318 so we will re-download the data.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574717952/574710816 [==============================] - 729s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1ddbc5e7a58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG19(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
