{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Conv2D , MaxPool2D , BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH = 96\n",
    "HEIGHT = 96\n",
    "CHANNEL = 3\n",
    "\n",
    "LATENT_DIM = 100 #latent variable z\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = 'faces/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 5\n",
    "COL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_index = 0\n",
    "\n",
    "images_name = os.listdir(PATH)\n",
    "\n",
    "IMAGES_COUNT = len(images_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(X_train , y_train),(X_test , y_test) = mnist.load_data()\\nX_train = X_train/127.5-1\\nX_train = np.expand_dims(X_train , 3)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "(X_train , y_train),(X_test , y_test) = mnist.load_data()\n",
    "X_train = X_train/127.5-1\n",
    "X_train = np.expand_dims(X_train , 3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef load_mnist():\\n    return X_train[np.random.randint(0, X_train.shape[0], BATCH_SIZE)]\\n    \\ndef write_image_mnist(epoch):\\n    \\n    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\\n    generated_image = generator_i.predict(noise)\\n    generated_image = generated_image*0.5+0.5\\n    \\n    fig , axes = plt.pyplot.subplots(ROW , COL)\\n    \\n    count=0\\n    \\n    for i in range(ROW):\\n        for j in range(COL):\\n            axes[i][j].imshow(generated_image[count,:,:,0] , cmap = 'gray')\\n            axes[i][j].axis('off')\\n            count += 1\\n            \\n    fig.savefig('images/No.%d.png' % epoch)\\n    plt.pyplot.close()\\n\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def load_mnist():\n",
    "    return X_train[np.random.randint(0, X_train.shape[0], BATCH_SIZE)]\n",
    "    \n",
    "def write_image_mnist(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    generated_image = generator_i.predict(noise)\n",
    "    generated_image = generated_image*0.5+0.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count,:,:,0] , cmap = 'gray')\n",
    "            axes[i][j].axis('off')\n",
    "            count += 1\n",
    "            \n",
    "    fig.savefig('images/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(batch_size = BATCH_SIZE):\n",
    "    global load_index\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        images.append(plt.image.imread(PATH + images_name[(load_index + i) % IMAGES_COUNT]))\n",
    "    \n",
    "    load_index += batch_size\n",
    "    \n",
    "    return np.array(images)/127.5-1\n",
    "\n",
    "def write_image(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    generated_image = generator_i.predict(noise)\n",
    "    generated_image = (generated_image+1)*127.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count])\n",
    "            axes[i][j].axis('off')\n",
    "            count += 1\n",
    "            \n",
    "    fig.savefig('generated_faces/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "    \n",
    "    #plt.image.imsave('images/'+str(epoch)+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator():\n",
    "    #sample from noise z\n",
    "    model = Sequential(name='generator')\n",
    "    \n",
    "    model.add(Dense(units = 256 , input_dim = LATENT_DIM , name='dense1'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8 , name='batchnorm1'))\n",
    "    model.add(Dense(units = 512 , name='dense2'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8 , name='batchnorm2'))\n",
    "    model.add(Dense(units = 1024 , name='dense3'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8 , name='batchnorm3'))\n",
    "    #model.add(Dense(units = 5000 , activation='relu' , name='dense4'))\n",
    "    #model.add(BatchNormalization(name='batchnorm4'))\n",
    "    #model.add(Dense(units = 10000 , activation='relu' , name='dense5'))\n",
    "    #model.add(BatchNormalization(name='batchnorm5'))\n",
    "    #model.add(Dense(units = 20000 , activation='relu' , name='dense6'))\n",
    "    #model.add(BatchNormalization(name='batchnorm6'))\n",
    "    model.add(Dense(units = WIDTH*HEIGHT*CHANNEL , activation='tanh' , name='dense7'))\n",
    "    model.add(Reshape(target_shape=(WIDTH , HEIGHT , CHANNEL) , name='reshape1'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    noise = Input(shape=(LATENT_DIM , ) , name='input1')\n",
    "    image = model(noise)\n",
    "    \n",
    "    return Model(noise , image , name='generator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    #input a image to discriminate real or fake\n",
    "    model = Sequential(name='discriminator')\n",
    "    \n",
    "    model.add(Flatten(input_shape = (WIDTH,HEIGHT,CHANNEL) , name='flatten1'))\n",
    "    #model.add(Dense(units=10000 , name='dense8'))\n",
    "    #model.add(LeakyReLU(0.3 , name='leakyrelu1'))\n",
    "    #model.add(Dense(units=5000 , name='dense9'))\n",
    "    #model.add(LeakyReLU(0.3 , name='leakyrelu2'))\n",
    "    #model.add(Dense(units=1024 , name='dense10'))\n",
    "    #model.add(LeakyReLU(0.3 , name='leakyrelu3'))\n",
    "    model.add(Dense(units=512 , name='dense11'))\n",
    "    model.add(LeakyReLU(0.2 , name='leakyrelu4'))\n",
    "    model.add(Dense(units=256 , name='dense12'))\n",
    "    model.add(LeakyReLU(0.2 , name='leakyrelu5'))\n",
    "    #model.add(Dense(units=32 , name='dense13'))\n",
    "    #model.add(LeakyReLU(0.3 , name='leakyrelu6'))\n",
    "    #model.add(Dense(units=4 , name='dense14'))\n",
    "    #model.add(LeakyReLU(0.3 , name='leakyrelu7'))\n",
    "    model.add(Dense(units=1 , activation='sigmoid' , name='dense15'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    image = Input(shape=(WIDTH , HEIGHT , CHANNEL) , name='input1')\n",
    "    validity = model(image)\n",
    "    \n",
    "    return Model(image , validity , name='discriminator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined_model(generator_i , discriminator_i):\n",
    "    #生成器和判别器组合成整体\n",
    "    z = Input(shape=(LATENT_DIM , ) , name='z')\n",
    "    \n",
    "    image = generator_i(z)\n",
    "    discriminator_i.trainable = False\n",
    "    validity = discriminator_i(image)\n",
    "    \n",
    "    return Model(z , validity , name='combined_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_i = discriminator()\n",
    "discriminator_i.compile(optimizer=Adam(lr=0.0002 , beta_1=0.5) , loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "generator_i = generator()\n",
    "\n",
    "combined_model_i = combined_model(generator_i , discriminator_i)\n",
    "\n",
    "\n",
    "combined_model_i.compile(optimizer=Adam(lr=0.0002 , beta_1=0.5) , loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "real_labels = np.ones(shape=(BATCH_SIZE , 1)) #真实样本label为1\n",
    "fake_labels = np.zeros(shape=(BATCH_SIZE , 1)) #假样本label为0\n",
    "\n",
    "for i in range(20000):\n",
    "    noise = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "\n",
    "    real_image = load_image()\n",
    "    #real_image = load_mnist()\n",
    "    #训练判别器\n",
    "    fake_image = generator_i.predict(noise)\n",
    "\n",
    "    real_loss = discriminator_i.train_on_batch(real_image , real_labels)\n",
    "    fake_loss = discriminator_i.train_on_batch(fake_image , fake_labels)\n",
    "\n",
    "    loss = np.add(real_loss , fake_loss)/2\n",
    "\n",
    "    #训练生成器\n",
    "    noise2 = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "    generator_loss = combined_model_i.train_on_batch(noise2 , real_labels)\n",
    "    \n",
    "    print('epoch:%d loss:%f accu:%f gene_loss:%f' % (i , loss[0] , loss[1] , generator_loss))\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        write_image(i)\n",
    "        #write_image_mnist(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator (Sequential)   (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 0\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator (Sequential)       (None, 28, 28, 1)         1097744   \n",
      "=================================================================\n",
      "Total params: 1,097,744\n",
      "Trainable params: 1,095,184\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z (InputLayer)               (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator_Model (Model)      (None, 28, 28, 1)         1097744   \n",
      "_________________________________________________________________\n",
      "discriminator_Model (Model)  (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 1,631,249\n",
      "Trainable params: 1,095,184\n",
      "Non-trainable params: 536,065\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
