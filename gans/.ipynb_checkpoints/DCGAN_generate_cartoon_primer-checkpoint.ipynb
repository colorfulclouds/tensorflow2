{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense ,  BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D , Conv2DTranspose , UpSampling2D , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.initializers import truncated_normal , constant , random_normal\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH = 96\n",
    "HEIGHT = 96\n",
    "CHANNEL = 3\n",
    "\n",
    "LATENT_DIM = 100 #latent variable z sample from normal distribution\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = 'faces/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 5\n",
    "COL = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "load_index = 0\n",
    "\n",
    "images_name = os.listdir(PATH)\n",
    "\n",
    "IMAGES_COUNT = len(images_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(X_train , y_train),(X_test , y_test) = mnist.load_data()\\nX_train = X_train/127.5-1\\nX_train = np.expand_dims(X_train , 3)\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "(X_train , y_train),(X_test , y_test) = mnist.load_data()\n",
    "X_train = X_train/127.5-1\n",
    "X_train = np.expand_dims(X_train , 3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef load_mnist():\\n    return X_train[np.random.randint(0, X_train.shape[0], BATCH_SIZE)]\\n    \\ndef write_image_mnist(epoch):\\n    \\n    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\\n    generated_image = generator_i.predict(noise)\\n    generated_image = generated_image*0.5+0.5\\n    \\n    fig , axes = plt.pyplot.subplots(ROW , COL)\\n    \\n    count=0\\n    \\n    for i in range(ROW):\\n        for j in range(COL):\\n            axes[i][j].imshow(generated_image[count,:,:,0] , cmap = 'gray')\\n            axes[i][j].axis('off')\\n            count += 1\\n            \\n    fig.savefig('mnist_dcgan/No.%d.png' % epoch)\\n    plt.pyplot.close()\\n\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def load_mnist():\n",
    "    return X_train[np.random.randint(0, X_train.shape[0], BATCH_SIZE)]\n",
    "    \n",
    "def write_image_mnist(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    generated_image = generator_i.predict(noise)\n",
    "    generated_image = generated_image*0.5+0.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count,:,:,0] , cmap = 'gray')\n",
    "            axes[i][j].axis('off')\n",
    "            count += 1\n",
    "            \n",
    "    fig.savefig('mnist_dcgan/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_image(batch_size = BATCH_SIZE):\n",
    "    global load_index\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        images.append(plt.image.imread(PATH + images_name[(load_index + i) % IMAGES_COUNT]))\n",
    "    \n",
    "    load_index += batch_size\n",
    "    \n",
    "    return (np.array(images)/127.5)-1.0\n",
    "\n",
    "def write_image(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    generated_image = generator_i.predict(noise)\n",
    "    generated_image = np.floor(((generated_image+1.0)*127.5))\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count])\n",
    "            axes[i][j].axis('off')\n",
    "            count += 1\n",
    "            \n",
    "    fig.savefig('generated_faces_dcgan/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "    \n",
    "    #plt.image.imsave('images/'+str(epoch)+'.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(output_size):\n",
    "    return Conv2D(output_size , kernel_size=(5,5) , strides=(2,2) , padding='same' , kernel_initializer=truncated_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n",
    "def dense(output_size):\n",
    "    return Dense(output_size , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n",
    "def deconv2d(output_size):\n",
    "    return Conv2DTranspose(output_size , kernel_size=(5,5) , strides=(2,2) , padding='same' , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n",
    "def batch_norm():\n",
    "    return BatchNormalization(momentum=0.9 , epsilon=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator():\n",
    "    #sample from noise z\n",
    "    model = Sequential(name='generator')\n",
    "    \n",
    "    #cartoon 图像使用 96*96*3\n",
    "    model.add(Dense(6*6*8*64 , input_shape=(LATENT_DIM,) , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0)))\n",
    "    \n",
    "    model.add(Reshape((6, 6, 64*8)))\n",
    "    \n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(deconv2d(64*4))\n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(deconv2d(64*2))\n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(deconv2d(64*1))\n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(deconv2d(3))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    noise = Input(shape=(LATENT_DIM , ) , name='input1')\n",
    "    image = model(noise)\n",
    "    \n",
    "    return Model(noise , image , name='generator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    #input a image to discriminate real or fake\n",
    "    model = Sequential(name='discriminator')\n",
    "    \n",
    "    model.add(Conv2D(filters=64 , kernel_size=(5,5) , strides=(2,2) , padding='same' , input_shape=(WIDTH , HEIGHT , CHANNEL) , kernel_initializer=truncated_normal(stddev=0.02) , bias_initializer=constant(0.0) , name='conv1'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #model.add(Dropout(0.25))\n",
    "    \n",
    "    #model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(conv2d(64*2))\n",
    "    model.add(batch_norm())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(conv2d(64*4))\n",
    "    model.add(batch_norm())  \n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    \n",
    "    model.add(conv2d(64*8))\n",
    "    model.add(batch_norm())  \n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #===\n",
    "    model.add(dense(1024))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #===\n",
    "    model.add(dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    image = Input(shape=(WIDTH , HEIGHT , CHANNEL) , name='input1')\n",
    "    validity = model(image)\n",
    "    \n",
    "    return Model(image , validity , name='discriminator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined_model(generator_i , discriminator_i):\n",
    "    #生成器和判别器组合成整体\n",
    "    z = Input(shape=(LATENT_DIM , ) , name='z')\n",
    "    \n",
    "    image = generator_i(z)\n",
    "    \n",
    "    #print(image.shape)\n",
    "    \n",
    "    discriminator_i.trainable = False\n",
    "    validity = discriminator_i(image)\n",
    "    \n",
    "    return Model(z , validity , name='combined_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.0002 , beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_i = discriminator()\n",
    "discriminator_i.compile(optimizer=adam , loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "generator_i = generator()\n",
    "\n",
    "combined_model_i = combined_model(generator_i , discriminator_i)\n",
    "\n",
    "\n",
    "combined_model_i.compile(optimizer=adam , loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 batch:0 loss:1.532499 accu:0.031250 gene_loss:0.709593\n",
      "epoch:0 batch:1 loss:0.472405 accu:0.523438 gene_loss:1.578565\n",
      "epoch:0 batch:2 loss:0.371663 accu:1.000000 gene_loss:2.661038\n",
      "epoch:0 batch:3 loss:0.224815 accu:0.992188 gene_loss:4.418355\n",
      "epoch:0 batch:4 loss:0.122419 accu:0.992188 gene_loss:4.013967\n",
      "epoch:0 batch:5 loss:0.157530 accu:1.000000 gene_loss:8.017440\n",
      "epoch:0 batch:6 loss:0.093054 accu:0.968750 gene_loss:6.039183\n",
      "epoch:0 batch:7 loss:0.162589 accu:0.984375 gene_loss:10.644134\n",
      "epoch:0 batch:8 loss:0.067714 accu:0.976562 gene_loss:11.256130\n",
      "epoch:0 batch:9 loss:0.026691 accu:1.000000 gene_loss:4.857416\n",
      "epoch:0 batch:10 loss:0.458809 accu:0.617188 gene_loss:15.747258\n",
      "epoch:0 batch:11 loss:0.324746 accu:0.835938 gene_loss:14.454495\n",
      "epoch:0 batch:12 loss:0.003791 accu:1.000000 gene_loss:8.059889\n",
      "epoch:0 batch:13 loss:1.871708 accu:0.500000 gene_loss:13.974639\n",
      "epoch:0 batch:14 loss:0.496819 accu:0.781250 gene_loss:10.880688\n",
      "epoch:0 batch:15 loss:0.076631 accu:0.976562 gene_loss:6.461460\n",
      "epoch:0 batch:16 loss:0.200489 accu:0.953125 gene_loss:7.631796\n",
      "epoch:0 batch:17 loss:0.097798 accu:0.968750 gene_loss:5.089967\n",
      "epoch:0 batch:18 loss:2.050732 accu:0.476562 gene_loss:9.729780\n",
      "epoch:0 batch:19 loss:0.920202 accu:0.625000 gene_loss:2.244295\n",
      "epoch:0 batch:20 loss:0.462531 accu:0.781250 gene_loss:1.955815\n",
      "epoch:0 batch:21 loss:0.492363 accu:0.718750 gene_loss:4.318455\n",
      "epoch:0 batch:22 loss:0.542715 accu:0.757812 gene_loss:3.826031\n",
      "epoch:0 batch:23 loss:0.213852 accu:0.968750 gene_loss:2.711500\n",
      "epoch:0 batch:24 loss:0.225130 accu:0.984375 gene_loss:5.347240\n",
      "epoch:0 batch:25 loss:0.381452 accu:0.820312 gene_loss:1.641806\n",
      "epoch:0 batch:26 loss:1.382396 accu:0.500000 gene_loss:8.366367\n",
      "epoch:0 batch:27 loss:0.779598 accu:0.664062 gene_loss:4.416759\n",
      "epoch:0 batch:28 loss:0.651537 accu:0.554688 gene_loss:2.309664\n",
      "epoch:0 batch:29 loss:0.246437 accu:0.843750 gene_loss:1.948718\n",
      "epoch:0 batch:30 loss:0.144878 accu:0.976562 gene_loss:0.997524\n",
      "epoch:0 batch:31 loss:0.211625 accu:0.953125 gene_loss:1.045964\n",
      "epoch:0 batch:32 loss:0.242110 accu:0.914062 gene_loss:3.632885\n",
      "epoch:0 batch:33 loss:0.943064 accu:0.507812 gene_loss:5.845024\n",
      "epoch:0 batch:34 loss:0.667987 accu:0.757812 gene_loss:2.800427\n",
      "epoch:0 batch:35 loss:0.271665 accu:0.898438 gene_loss:2.476010\n",
      "epoch:0 batch:36 loss:0.144031 accu:0.945312 gene_loss:2.140146\n",
      "epoch:0 batch:37 loss:0.442271 accu:0.812500 gene_loss:6.882345\n",
      "epoch:0 batch:38 loss:0.494259 accu:0.812500 gene_loss:4.252535\n",
      "epoch:0 batch:39 loss:0.539430 accu:0.726562 gene_loss:6.260743\n",
      "epoch:0 batch:40 loss:0.187580 accu:0.929688 gene_loss:3.082144\n",
      "epoch:0 batch:41 loss:0.935584 accu:0.578125 gene_loss:1.997057\n",
      "epoch:0 batch:42 loss:0.241414 accu:0.921875 gene_loss:2.886386\n",
      "epoch:0 batch:43 loss:0.399668 accu:0.820312 gene_loss:2.517566\n",
      "epoch:0 batch:44 loss:0.402986 accu:0.851562 gene_loss:3.952225\n",
      "epoch:0 batch:45 loss:0.207901 accu:0.929688 gene_loss:3.599007\n",
      "epoch:0 batch:46 loss:0.307885 accu:0.882812 gene_loss:4.477692\n",
      "epoch:0 batch:47 loss:0.201893 accu:0.929688 gene_loss:1.689210\n",
      "epoch:0 batch:48 loss:0.290738 accu:0.875000 gene_loss:5.731266\n",
      "epoch:0 batch:49 loss:0.450784 accu:0.757812 gene_loss:1.190922\n",
      "epoch:0 batch:50 loss:0.770381 accu:0.546875 gene_loss:8.221374\n",
      "epoch:0 batch:51 loss:0.343681 accu:0.828125 gene_loss:6.514257\n",
      "epoch:0 batch:52 loss:0.333145 accu:0.867188 gene_loss:3.369523\n",
      "epoch:0 batch:53 loss:0.245264 accu:0.914062 gene_loss:4.200732\n"
     ]
    }
   ],
   "source": [
    "real_labels = np.ones(shape=(BATCH_SIZE , 1)) #真实样本label为1\n",
    "fake_labels = np.zeros(shape=(BATCH_SIZE , 1)) #假样本label为0\n",
    "\n",
    "for i in range(1000):\n",
    "    for j in range(int(IMAGES_COUNT/BATCH_SIZE)):\n",
    "        noise = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "\n",
    "        real_image = load_image()\n",
    "        #real_image = load_mnist()\n",
    "        #训练判别器\n",
    "        fake_image = generator_i.predict(noise)\n",
    "\n",
    "        real_loss = discriminator_i.train_on_batch(real_image , real_labels)\n",
    "        fake_loss = discriminator_i.train_on_batch(fake_image , fake_labels)\n",
    "\n",
    "        loss = np.add(real_loss , fake_loss)/2\n",
    "\n",
    "        #训练生成器\n",
    "        noise2 = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "        generator_loss = combined_model_i.train_on_batch(noise2 , real_labels)\n",
    "\n",
    "        print('epoch:%d batch:%d loss:%f accu:%f gene_loss:%f' % (i , j , loss[0] , loss[1] , generator_loss))\n",
    "\n",
    "    write_image(i)\n",
    "    #write_image_mnist(i)\n",
    "    \n",
    "write_image(999)\n",
    "#write_image_mnist(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator (Sequential)   (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 0\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator (Sequential)       (None, 28, 28, 1)         1097744   \n",
      "=================================================================\n",
      "Total params: 1,097,744\n",
      "Trainable params: 1,095,184\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z (InputLayer)               (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator_Model (Model)      (None, 96, 96, 3)         29029120  \n",
      "_________________________________________________________________\n",
      "discriminator_Model (Model)  (None, 1)                 14320641  \n",
      "=================================================================\n",
      "Total params: 43,349,761\n",
      "Trainable params: 29,025,536\n",
      "Non-trainable params: 14,324,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeli = Sequential(name='generator')\n",
    "\n",
    "#cartioon 图像使用 96*96*3\n",
    "modeli.add(Dense(6*6*8*64 , input_shape=(LATENT_DIM,) , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0)))\n",
    "\n",
    "modeli.add(Reshape((6, 6, 64*8)))\n",
    "modeli.add(batch_norm())\n",
    "modeli.add(LeakyReLU(0.2))\n",
    "\n",
    "modeli.add(deconv2d(64*4))\n",
    "modeli.add(batch_norm())\n",
    "modeli.add(LeakyReLU(0.2))\n",
    "\n",
    "modeli.add(deconv2d(64*2))\n",
    "modeli.add(batch_norm())\n",
    "modeli.add(LeakyReLU(0.2))\n",
    "\n",
    "modeli.add(deconv2d(64*1))\n",
    "modeli.add(batch_norm())\n",
    "modeli.add(LeakyReLU(0.2))\n",
    "\n",
    "modeli.add(deconv2d(3))\n",
    "modeli.add(Activation('tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7872"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800.359375"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGES_COUNT/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51200"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "800*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51223"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGES_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "22:9:30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
