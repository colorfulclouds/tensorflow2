{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense ,  BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D , Conv2DTranspose , UpSampling2D , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.optimizers import Adam , RMSprop\n",
    "\n",
    "from keras.initializers import truncated_normal , random_normal , constant\n",
    "\n",
    "#_Merge\n",
    "from keras.layers.merge import _Merge\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH = 96\n",
    "HEIGHT = 96\n",
    "CHANNEL = 3\n",
    "\n",
    "LATENT_DIM = 100 #latent variable z sample from normal distribution\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = 'faces/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 5\n",
    "COL = 5\n",
    "\n",
    "#为WGAN增加的\n",
    "N_CRITIC = 5 #训练G时使用\n",
    "CLIP_VALUE = 0.01 #更新G的权重参数时进行截断使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "load_index = 0\n",
    "\n",
    "images_name = os.listdir(PATH)\n",
    "\n",
    "IMAGES_COUNT = len(images_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_image(batch_size = BATCH_SIZE):\n",
    "    global load_index\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        images.append(plt.image.imread(PATH + images_name[(load_index + i) % IMAGES_COUNT]))\n",
    "    \n",
    "    load_index += batch_size\n",
    "    \n",
    "    return np.array(images)/127.5-1\n",
    "\n",
    "def write_image(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    generated_image = generator_i.predict(noise)\n",
    "    generated_image = (generated_image+1)*127.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count])\n",
    "            axes[i][j].axis('off')\n",
    "            count += 1\n",
    "            \n",
    "    fig.savefig('generated_faces_wgan-gp/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "    \n",
    "    #plt.image.imsave('images/'+str(epoch)+'.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(output_size):\n",
    "    return Conv2D(output_size , kernel_size=(5,5) , strides=(2,2) , padding='same' , kernel_initializer=truncated_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n",
    "def dense(output_size):\n",
    "    return Dense(output_size , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n",
    "def deconv2d(output_size):\n",
    "    return Conv2DTranspose(output_size , kernel_size=(5,5) , strides=(2,2) , padding='same' , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n",
    "def batch_norm():\n",
    "    return BatchNormalization(momentum=0.9 , epsilon=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator():\n",
    "    #sample from noise z\n",
    "    model = Sequential(name='generator')\n",
    "    \n",
    "    #cartoon 图像使用 96*96*3\n",
    "    model.add(Dense(6*6*8*64 , input_shape=(LATENT_DIM,) , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0)))\n",
    "    \n",
    "    model.add(Reshape((6, 6, 64*8)))\n",
    "    \n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(deconv2d(64*4))\n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(deconv2d(64*2))\n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(deconv2d(64*1))\n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(deconv2d(3))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    noise = Input(shape=(LATENT_DIM , ) , name='input1')\n",
    "    image = model(noise)\n",
    "    \n",
    "    return Model(noise , image , name='generator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def critic():\n",
    "    #input a image to discriminate real or fake\n",
    "    model = Sequential(name='critic')\n",
    "    \n",
    "    model.add(Conv2D(filters=64 , kernel_size=(5,5) , strides=(2,2) , padding='same' , input_shape=(WIDTH , HEIGHT , CHANNEL) , kernel_initializer=truncated_normal(stddev=0.02) , bias_initializer=constant(0.0) , name='conv1'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #model.add(Dropout(0.25))\n",
    "    \n",
    "    #model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(conv2d(64*2))\n",
    "    model.add(batch_norm())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(conv2d(64*4))\n",
    "    model.add(batch_norm())  \n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    \n",
    "    model.add(conv2d(64*8))\n",
    "    model.add(batch_norm())  \n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #===\n",
    "    #如果没有下面的FC层 训练时发生损失不下降 且生成不出图像\n",
    "    model.add(dense(128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #===\n",
    "    model.add(dense(1)) #不使用sigmoid激活 y=x 激活\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    image = Input(shape=(WIDTH , HEIGHT , CHANNEL) , name='input1')\n",
    "    validity = model(image)\n",
    "    \n",
    "    return Model(image , validity , name='critic_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmsprop = RMSprop(lr=0.00005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要继承_Merge类\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((BATCH_SIZE, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wgan_loss(y_true , y_pred):\n",
    "    return K.mean(y_true*y_pred)\n",
    "\n",
    "def GP_penelty_loss(y_true , y_pred , averaged_samples): #WGAN-GP在原有GAN损失中增加的损失\n",
    "    gradients = K.gradients(y_pred , averaged_samples)[0] #y_true在此位置代替的是averaged_samples \n",
    "    gradients_sqr = K.square(gradients)\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr , axis=np.arange(1 , len(gradients_sqr.shape)))\n",
    "    \n",
    "    gradients_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    \n",
    "    gradients_penalty = K.square(1-gradients_l2_norm)\n",
    "    \n",
    "    return K.mean(gradients_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "critic_i = critic()\n",
    "generator_i = generator()\n",
    "\n",
    "generator_i.trainable = False\n",
    "\n",
    "#critic_i.compile(optimizer=rmsprop , loss=wgan_loss , metrics=['accuracy'])\n",
    "\n",
    "real_image = Input(shape=(HEIGHT , WIDTH , CHANNEL) , name='real_image')\n",
    "\n",
    "\n",
    "z = Input(shape=(LATENT_DIM , ) , name = 'z')\n",
    "fake_image = generator_i(z)\n",
    "\n",
    "validity_fake = critic_i(fake_image)\n",
    "validity_real = critic_i(real_image)\n",
    "\n",
    "#根据WGAN-GP中的loss公式中的插值的样本\n",
    "interpolation_real_fake_image = RandomWeightedAverage()([real_image , fake_image])\n",
    "validity_interpolation = critic_i(interpolation_real_fake_image)\n",
    "\n",
    "#==========\n",
    "#partial为python函数 类似装饰器\n",
    "#下面就是在原有的GAN上的损失添加的惩罚项\n",
    "partial_gp_loss = partial(GP_penelty_loss , averaged_samples=interpolation_real_fake_image)\n",
    "partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "#==========\n",
    "\n",
    "critic_model = Model(inputs=[real_image , z] , outputs=[validity_real , validity_fake , validity_interpolation] , name='critic_model')\n",
    "critic_model.compile(optimizer=rmsprop , loss=[wgan_loss , wgan_loss , partial_gp_loss] , loss_weights=[1,1,10])\n",
    "\n",
    "#==========\n",
    "critic_i.trainable = False\n",
    "generator_i.trainable = True\n",
    "\n",
    "\n",
    "z_ = Input(shape=(LATENT_DIM , ))\n",
    "image_ = generator_i(z_)\n",
    "valid_ = critic_i(image_)\n",
    "\n",
    "generator_model = Model(z_ , valid_)\n",
    "generator_model.compile(optimizer=rmsprop , loss=wgan_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss1:9.728308 loss2:-0.073971 loss3:-0.087728 gene_loss:0.087464\n",
      "epoch:1 loss1:9.707046 loss2:-0.073995 loss3:-0.088454 gene_loss:0.088914\n",
      "epoch:2 loss1:9.715948 loss2:-0.075428 loss3:-0.092194 gene_loss:0.090894\n",
      "epoch:3 loss1:9.698011 loss2:-0.072518 loss3:-0.094405 gene_loss:0.094871\n",
      "epoch:4 loss1:9.673544 loss2:-0.073216 loss3:-0.096763 gene_loss:0.098487\n",
      "epoch:5 loss1:9.678801 loss2:-0.073581 loss3:-0.100370 gene_loss:0.101943\n",
      "epoch:6 loss1:9.642222 loss2:-0.075849 loss3:-0.104160 gene_loss:0.104589\n",
      "epoch:7 loss1:9.616793 loss2:-0.078041 loss3:-0.105591 gene_loss:0.105823\n",
      "epoch:8 loss1:9.566839 loss2:-0.078663 loss3:-0.109154 gene_loss:0.108544\n",
      "epoch:9 loss1:9.479568 loss2:-0.076215 loss3:-0.113224 gene_loss:0.111901\n",
      "epoch:10 loss1:9.337676 loss2:-0.115847 loss3:-0.113366 gene_loss:0.116112\n",
      "epoch:11 loss1:9.210569 loss2:-0.045073 loss3:-0.121073 gene_loss:0.117517\n",
      "epoch:12 loss1:9.141478 loss2:-0.132518 loss3:-0.118188 gene_loss:0.130391\n",
      "epoch:13 loss1:8.290174 loss2:-0.098557 loss3:-0.134852 gene_loss:0.133362\n",
      "epoch:14 loss1:7.444712 loss2:-0.131075 loss3:-0.145320 gene_loss:0.131211\n",
      "epoch:15 loss1:6.948752 loss2:-0.118116 loss3:-0.146886 gene_loss:0.150726\n",
      "epoch:16 loss1:6.950569 loss2:-0.161617 loss3:-0.146863 gene_loss:0.144505\n",
      "epoch:17 loss1:5.890264 loss2:-0.097151 loss3:-0.135185 gene_loss:0.145991\n",
      "epoch:18 loss1:6.956420 loss2:-0.151330 loss3:-0.119338 gene_loss:0.140315\n",
      "epoch:19 loss1:4.279582 loss2:-0.047965 loss3:-0.130704 gene_loss:0.102199\n",
      "epoch:20 loss1:6.127625 loss2:-0.105267 loss3:-0.080413 gene_loss:0.082353\n",
      "epoch:21 loss1:4.528093 loss2:0.027194 loss3:-0.026840 gene_loss:0.027669\n",
      "epoch:22 loss1:6.324838 loss2:-0.071995 loss3:0.112151 gene_loss:-0.046399\n",
      "epoch:23 loss1:5.548553 loss2:0.120629 loss3:0.080614 gene_loss:-0.139221\n",
      "epoch:24 loss1:5.284017 loss2:0.043734 loss3:0.158344 gene_loss:-0.079592\n",
      "epoch:25 loss1:5.411504 loss2:0.095094 loss3:0.125422 gene_loss:-0.166558\n",
      "epoch:26 loss1:5.607407 loss2:0.013160 loss3:0.182105 gene_loss:-0.100343\n",
      "epoch:27 loss1:5.608415 loss2:0.152801 loss3:0.128819 gene_loss:-0.178887\n",
      "epoch:28 loss1:5.721684 loss2:0.040997 loss3:0.159039 gene_loss:-0.181052\n",
      "epoch:29 loss1:5.944353 loss2:0.121780 loss3:0.143229 gene_loss:-0.233022\n",
      "epoch:30 loss1:6.052701 loss2:-0.019581 loss3:0.245003 gene_loss:-0.173266\n",
      "epoch:31 loss1:5.896089 loss2:0.126736 loss3:0.185714 gene_loss:-0.221768\n"
     ]
    }
   ],
   "source": [
    "real_labels = -np.ones(shape=(BATCH_SIZE , 1)) #真实样本label为1\n",
    "fake_labels = np.ones(shape=(BATCH_SIZE , 1)) #假样本label为0\n",
    "dummy = np.zeros(shape=(BATCH_SIZE , 1)) #为WGAN-GP的惩罚项准备的label\n",
    "\n",
    "for i in range(1001):\n",
    "    #============================\n",
    "    #训练一次G就要训练N_CRITIC次D（Discriminator）\n",
    "    for _ in range(N_CRITIC):\n",
    "        \n",
    "        noise = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "\n",
    "        real_image = load_image()\n",
    "        \n",
    "        #训练判别器\n",
    "        loss = critic_model.train_on_batch([real_image , noise] , [real_labels , fake_labels , dummy])\n",
    "        \n",
    "        #取消对权重参数的裁剪 clip\n",
    "        #到底需不需要进行参数截断\n",
    "        #在mnist数据集上需要 在cartoon上不好说 耗长时间去验证\n",
    "        for layer in critic_i.layers:\n",
    "            weights = layer.get_weights()\n",
    "            weights = [np.clip(w , -CLIP_VALUE , CLIP_VALUE) for w in weights]\n",
    "            layer.set_weights(weights)\n",
    "    #============================\n",
    "    \n",
    "    #训练生成器\n",
    "    noise2 = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "    generator_loss = generator_model.train_on_batch(noise2 , real_labels)\n",
    "\n",
    "    print('epoch:%d loss1:%f loss2:%f loss3:%f gene_loss:%f' % (i , loss[0] , loss[1] , loss[2] , generator_loss))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        write_image(i)\n",
    "    \n",
    "write_image(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator (Sequential)   (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 0\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator (Sequential)       (None, 28, 28, 1)         1097744   \n",
      "=================================================================\n",
      "Total params: 1,097,744\n",
      "Trainable params: 1,095,184\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z (InputLayer)               (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator_Model (Model)      (None, 96, 96, 3)         29029120  \n",
      "_________________________________________________________________\n",
      "discriminator_Model (Model)  (None, 1)                 14320641  \n",
      "=================================================================\n",
      "Total params: 43,349,761\n",
      "Trainable params: 29,025,536\n",
      "Non-trainable params: 14,324,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeli = Sequential()\n",
    "\n",
    "modeli.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=(LATENT_DIM,)))\n",
    "modeli.add(Reshape((7, 7, 128)))\n",
    "modeli.add(UpSampling2D())\n",
    "modeli.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "modeli.add(BatchNormalization(momentum=0.8))\n",
    "modeli.add(Activation(\"relu\"))\n",
    "modeli.add(UpSampling2D())\n",
    "modeli.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "modeli.add(BatchNormalization(momentum=0.8))\n",
    "modeli.add(Activation(\"relu\"))\n",
    "modeli.add(Conv2D(CHANNEL, kernel_size=3, padding=\"same\"))\n",
    "modeli.add(Activation(\"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modeli.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
