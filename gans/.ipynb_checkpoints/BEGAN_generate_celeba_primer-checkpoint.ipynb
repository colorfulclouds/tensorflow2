{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reference https://github.com/mokemokechicken/keras_BEGAN\n",
    "#reference https://github.com/siddharthalodha/BEGAN_KERAS/blob/master/BEGAN_v1.ipynb    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense ,  BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D , Conv2DTranspose , UpSampling2D , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU , PReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.initializers import truncated_normal , constant , random_normal\n",
    "\n",
    "from keras.optimizers import Adam , RMSprop\n",
    "\n",
    "#残差块使用\n",
    "from keras.layers import Add\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#addin BEGAN\n",
    "from keras.layers import Lambda #可以自己指定特定层 完成特定的功能 discriminator使用\n",
    "from keras.layers import Concatenate #将discriminator的两个输出合并使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from scipy.misc import imread , imsave\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BEGAN使用64*64*3 图像\n",
    "WIDTH = 64\n",
    "HEIGHT = 64\n",
    "CHANNEL = 3\n",
    "\n",
    "SHAPE = (WIDTH , HEIGHT , CHANNEL)\n",
    "\n",
    "LATENT_DIM = 64 #latent variable z sample from normal distribution\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = '../dataset/CelebA/img_align_celeba/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 2\n",
    "COL = 2\n",
    "\n",
    "#addin BEGAN\n",
    "N_FILTERS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============\n",
    "IMAGES_PATH = glob(PATH+'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(batch_size = BATCH_SIZE , training = True):\n",
    "    #随机在图片库中挑选\n",
    "    image_path = np.random.choice(IMAGES_PATH , size=batch_size)\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for an_image_path in image_path:\n",
    "        img = imread(an_image_path , mode='RGB').astype(np.float)\n",
    "        \n",
    "        #尽管原图像不是指定的大小 下面将强制将图像resize\n",
    "        img = scipy.misc.imresize(img , size=SHAPE) #resize到64*64*3尺寸\n",
    "        \n",
    "        #随机性地对训练样本进行 左右反转\n",
    "        #BEGAN不进行左右反转\n",
    "        #if training and np.random.random()<0.5:\n",
    "        #    img = np.fliplr(img)\n",
    "        \n",
    "        images.append(img)\n",
    "        \n",
    "    images = np.array(images)/127.5 - 1\n",
    "    \n",
    "    return images\n",
    "\n",
    "def write_image(epoch):\n",
    "    #生成高分图像时 进行对比显示\n",
    "    z = np.random.uniform(-1 , 1 , size=(ROW*COL , LATENT_DIM))\n",
    "    images = Generator.predict(z)\n",
    "    \n",
    "    images = images*0.5+0.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    count=0\n",
    "    \n",
    "    axes[0][0].imshow(images[0])\n",
    "    #axes[0][0].set_title('original high')\n",
    "    axes[0][0].axis('off')\n",
    "\n",
    "    axes[0][1].imshow(images[1])\n",
    "    #axes[0][1].set_title('generated high')\n",
    "    axes[0][1].axis('off')\n",
    "    \n",
    "\n",
    "    axes[1][0].imshow(images[2])\n",
    "    #axes[1][0].set_title('original high')\n",
    "    axes[1][0].axis('off')\n",
    "\n",
    "    axes[1][1].imshow(images[3])\n",
    "    #axes[1][1].set_title('generated high')\n",
    "    axes[1][1].axis('off')\n",
    "    \n",
    "    fig.savefig('celeba_began/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_conv2d(x , output_size , strides , n_layer):\n",
    "    for _ in range(n_layer):\n",
    "        x = Conv2D(output_size , kernel_size=(3,3) , strides=(1,1) , activation='elu' , padding='same')(x) #1步卷积 保证图像尺寸不变\n",
    "    \n",
    "    return Conv2D(output_size , kernel_size=(3,3) , strides=strides , activation='elu' , padding='same')(x) #最后的这个卷积的stride为2 进行降2倍采样\n",
    "\n",
    "\n",
    "def multi_deconv2d(x , output_size , n_layer , upsample):\n",
    "    for _ in range(n_layer):\n",
    "        x = Conv2D(output_size , kernel_size=(3,3) , strides=(1,1) , activation='elu' , padding='same')(x)\n",
    "    \n",
    "    if upsample:\n",
    "        x = UpSampling2D()(x)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder():\n",
    "    image = Input(shape=SHAPE)\n",
    "    \n",
    "    h = multi_conv2d(image , output_size=N_FILTERS , strides=(2,2) , n_layer=2)\n",
    "    h = multi_conv2d(h , output_size=N_FILTERS*2 , strides=(2,2) , n_layer=2)\n",
    "    h = multi_conv2d(h , output_size=N_FILTERS*3 , strides=(2,2) , n_layer=2)\n",
    "    h = multi_conv2d(h , output_size=N_FILTERS*4 , strides=(1,1) , n_layer=2)\n",
    "    \n",
    "    h = Flatten()(h)\n",
    "    \n",
    "    feature = Dense(units=64 , activation='linear')(h)\n",
    "    \n",
    "    return Model(image , feature)\n",
    "    \n",
    "def decoder():\n",
    "    feature = Input(shape=(64 , ))\n",
    "    \n",
    "    h = Dense(units=8*8*N_FILTERS , activation='linear')(feature)\n",
    "    h = Reshape(target_shape=(8,8,N_FILTERS))(h)\n",
    "    \n",
    "    h = multi_deconv2d(h , output_size=N_FILTERS , n_layer=2 , upsample=True)\n",
    "    h = multi_deconv2d(h , output_size=N_FILTERS , n_layer=2 , upsample=True)\n",
    "    h = multi_deconv2d(h , output_size=N_FILTERS , n_layer=2 , upsample=True)\n",
    "    h = multi_deconv2d(h , output_size=N_FILTERS , n_layer=2 , upsample=False)\n",
    "    \n",
    "    image = Conv2D(3 , kernel_size=(3,3) , strides=(1,1) , activation='linear' , padding='same')(h)\n",
    "    \n",
    "    return Model(feature , image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoencoder():\n",
    "    image = Input(shape=(SHAPE))\n",
    "    \n",
    "    Encoder = encoder()\n",
    "    Decoder = decoder()\n",
    "    \n",
    "    feature = Encoder(image)\n",
    "    image_hat = Decoder(feature)\n",
    "    \n",
    "    return Model(image , image_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    input_data = Input(shape=(HEIGHT , WIDTH , CHANNEL*2)) #因为discriminator的输入是两幅图像 所以输入的通道翻一倍\n",
    "    \n",
    "    real_image = Lambda(lambda x: x[:,:,:,:3] , output_shape=SHAPE)(input_data)\n",
    "    generator_image = Lambda(lambda x: x[:,:,:,3:] , output_shape=SHAPE)(input_data)\n",
    "    \n",
    "    Autoencoder = autoencoder()\n",
    "    \n",
    "    real_image_hat = Autoencoder(real_image)\n",
    "    generator_image_hat = Autoencoder(generator_image)\n",
    "\n",
    "    output_data = Concatenate()([real_image_hat , generator_image_hat])\n",
    "\n",
    "    return Model(input_data , output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator():\n",
    "    return decoder() #feature to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class D_loss(object):\n",
    "    __name__ = 'discriminator_loss'\n",
    "    \n",
    "    def __init__(self , init_k_var=0.0 , init_lambda_k = 0.001 , init_gamma=0.5):\n",
    "        self.lambda_k = init_lambda_k\n",
    "        self.gamma = init_gamma\n",
    "        self.k_var = K.variable(init_k_var , dtype=K.floatx())\n",
    "        \n",
    "        self.m_global_var = K.variable(0.0 , dtype=K.floatx())\n",
    "        self.loss_real_x_var = K.variable(0)\n",
    "        self.loss_gene_x_var = K.variable(0)\n",
    "        \n",
    "        self.updates = []\n",
    "\n",
    "    def __call__(self , y_true , y_pred):\n",
    "        real_image_hat_true , generator_image_hat_true = y_true[:,:,:,:3] , y_true[:,:,:,3:]\n",
    "        real_image_hat_pred ,generator_image_hat_pred = y_pred[:,:,:,:3] , y_true[:,:,:,3:]\n",
    "\n",
    "        #下面的平均在batch维上还没有平均 所以得到的是1维张量\n",
    "        loss_real_image_hat = K.mean(K.abs(real_image_hat_true-real_image_hat_pred) , axis=[1,2,3])\n",
    "        loss_generator_image_hat = K.mean(K.abs(generator_image_hat_true-generator_image_hat_pred) , axis=[1,2,3])\n",
    "\n",
    "        #paper equation\n",
    "        discriminator_loss = loss_real_image_hat - self.k_var*loss_generator_image_hat\n",
    "\n",
    "        mean_loss_real_image_hat = K.mean(loss_real_image_hat)\n",
    "        mean_loss_generator_image_hat = K.mean(loss_generator_image_hat)\n",
    "        #paper equation\n",
    "        new_k = self.k_var + self.lambda_k*(self.gamma*mean_loss_real_image_hat-mean_loss_generator_image_hat)\n",
    "        new_k = K.clip(new_k , 0 , 1)\n",
    "        self.updates.append(K.update(self.k_var , new_k))\n",
    "        \n",
    "        m_global = mean_loss_real_image_hat + K.abs(self.gamma*mean_loss_real_image_hat-mean_loss_generator_image_hat)\n",
    "        self.updates.append(K.update(self.m_global_var , m_global))\n",
    "        \n",
    "        self.updates.append(K.update(self.loss_real_x_var , mean_loss_real_image_hat))\n",
    "        self.updates.append(K.update(self.loss_gene_x_var , mean_loss_generator_image_hat))\n",
    "        \n",
    "        return discriminator_loss\n",
    "\n",
    "    @property\n",
    "    def k(self):\n",
    "        return K.get_value(self.k_var)\n",
    "    \n",
    "    @property\n",
    "    def m_global(self):\n",
    "        return K.get_value(self.m_global_var)\n",
    "    \n",
    "    @property\n",
    "    def loss_real_x(self):\n",
    "        return K.get_value(self.loss_real_x_var)\n",
    "    \n",
    "    @property\n",
    "    def loss_gene_x(self):\n",
    "        return K.get_value(self.loss_gene_x_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_generator_loss(Autoencoder):\n",
    "    def generator_loss(y_true , y_pred):\n",
    "        y_pred_dash = Autoencoder(y_pred)\n",
    "        \n",
    "        return K.mean(K.abs(y_pred - y_pred_dash) , axis=[1,2,3])\n",
    "    \n",
    "    return generator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Autoencoder = autoencoder()\n",
    "Generator = generator()\n",
    "Discrimminator = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_discriminator = D_loss()\n",
    "Discrimminator.compile(optimizer=Adam(lr=0.0002 , beta_1=0.5) , loss=loss_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Generator.compile(optimizer=Adam(lr=0.0002 , beta_1=0.5) , loss=build_generator_loss(Autoencoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\Anaconda3\\lib\\site-packages\\scipy\\misc\\pilutil.py:480: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "I:\\Anaconda3\\lib\\site-packages\\scipy\\misc\\pilutil.py:483: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss_D:0.624767 loss_G:0.030820\n",
      "epoch:1 loss_D:0.395801 loss_G:0.030991\n",
      "epoch:2 loss_D:0.541951 loss_G:0.025814\n",
      "epoch:3 loss_D:0.585128 loss_G:0.025797\n",
      "epoch:4 loss_D:0.561813 loss_G:0.024716\n",
      "epoch:5 loss_D:0.378884 loss_G:0.024225\n",
      "epoch:6 loss_D:0.514190 loss_G:0.020481\n",
      "epoch:7 loss_D:0.927406 loss_G:0.018667\n",
      "epoch:8 loss_D:0.477981 loss_G:0.018754\n",
      "epoch:9 loss_D:0.577440 loss_G:0.019124\n",
      "epoch:10 loss_D:0.402025 loss_G:0.017704\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    \n",
    "    #训练discriminator\n",
    "    input_x1 = load_image() #真实图像\n",
    "    input_x2 = Generator.predict(np.random.uniform(-1,1, size=(BATCH_SIZE , LATENT_DIM)))\n",
    "    input_x = np.concatenate((input_x1 , input_x2) , axis=-1)\n",
    "    \n",
    "    loss_d = Discrimminator.train_on_batch(input_x , input_x)\n",
    "\n",
    "    #训练generator\n",
    "    input_x3 = np.random.uniform(-1,1 , size=(BATCH_SIZE , LATENT_DIM))\n",
    "    loss_g = Generator.train_on_batch(input_x3 , np.zeros_like(input_x2))\n",
    "    \n",
    "    print('epoch:%d loss_D:%f loss_G:%f' % (i , loss_d , loss_g))\n",
    "\n",
    "    #if i % 50 == 0:\n",
    "    write_image(i)\n",
    "    \n",
    "#write_image(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of cbe5617147190e668d6c5d5026f83318 so we will re-download the data.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
      "574717952/574710816 [==============================] - 729s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1ddbc5e7a58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VGG19(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
