{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense ,  BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D , Conv2DTranspose , UpSampling2D , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.layers import Embedding\n",
    "\n",
    "from keras.layers import Multiply\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH = 28\n",
    "HEIGHT = 28\n",
    "CHANNEL = 1\n",
    "\n",
    "LATENT_DIM = 100 #latent variable z sample from normal distribution\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = 'faces/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 5\n",
    "COL = 5\n",
    "\n",
    "#=========\n",
    "#=========\n",
    "#add new FLAG(s)\n",
    "CLASS_NUM = 10 #mnist=10 CIFAR10=10 CIFAR100=100 CIFAR1000=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nload_index = 0\\n\\nimages_name = os.listdir(PATH)\\n\\nIMAGES_COUNT = len(images_name)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "load_index = 0\n",
    "\n",
    "images_name = os.listdir(PATH)\n",
    "\n",
    "IMAGES_COUNT = len(images_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "(X_train , y_train),(X_test , y_test) = mnist.load_data()\n",
    "X_train = X_train/127.5-1\n",
    "X_train = np.expand_dims(X_train , 3)\n",
    "y_train = np.expand_dims(y_train , 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_mnist():\n",
    "    random_index = np.random.randint(0, X_train.shape[0], BATCH_SIZE)\n",
    "    return X_train[random_index] , y_train[random_index]\n",
    "    \n",
    "def write_image_mnist(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    label = np.random.randint(low=0 , high=CLASS_NUM , size=(ROW*COL , 1)) #CLASS_NUM 是否需要加1\n",
    "    \n",
    "    generated_image = generator_i.predict([noise , label])\n",
    "    generated_image = generated_image*0.5+0.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    fig.subplots_adjust(hspace=0.9 , wspace=0.9) #将每一个图像在高度 宽度 上进行缩放或者放大\n",
    "    #fig.tight_layout()\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count,:,:,0] , cmap = 'gray')\n",
    "            axes[i][j].axis('off')\n",
    "            axes[i][j].set_title('%d' % (label[i*ROW+j]))\n",
    "            count += 1\n",
    "    \n",
    "    \n",
    "    fig.savefig('mnist_acgan/No.%d.png' % (epoch))\n",
    "    plt.pyplot.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef load_image(batch_size = BATCH_SIZE):\\n    global load_index\\n    \\n    images = []\\n    \\n    for i in range(batch_size):\\n        images.append(plt.image.imread(PATH + images_name[(load_index + i) % IMAGES_COUNT]))\\n    \\n    load_index += batch_size\\n    \\n    return np.array(images)/127.5-1\\n\\ndef write_image(epoch):\\n    \\n    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\\n    generated_image = generator_i.predict(noise)\\n    generated_image = (generated_image+1)*127.5\\n    \\n    fig , axes = plt.pyplot.subplots(ROW , COL)\\n    \\n    count=0\\n    \\n    for i in range(ROW):\\n        for j in range(COL):\\n            axes[i][j].imshow(generated_image[count])\\n            axes[i][j].axis('off')\\n            count += 1\\n            \\n    fig.savefig('generated_faces_dcgan/No.%d.png' % epoch)\\n    plt.pyplot.close()\\n    \\n    #plt.image.imsave('images/'+str(epoch)+'.jpg')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def load_image(batch_size = BATCH_SIZE):\n",
    "    global load_index\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        images.append(plt.image.imread(PATH + images_name[(load_index + i) % IMAGES_COUNT]))\n",
    "    \n",
    "    load_index += batch_size\n",
    "    \n",
    "    return np.array(images)/127.5-1\n",
    "\n",
    "def write_image(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    generated_image = generator_i.predict(noise)\n",
    "    generated_image = (generated_image+1)*127.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count])\n",
    "            axes[i][j].axis('off')\n",
    "            count += 1\n",
    "            \n",
    "    fig.savefig('generated_faces_dcgan/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "    \n",
    "    #plt.image.imsave('images/'+str(epoch)+'.jpg')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator():\n",
    "    #sample from noise z\n",
    "    model = Sequential(name='generator')\n",
    "    \n",
    "    #cartoon 图像使用 96*96*3\n",
    "    #model.add(Reshape(target_shape=(10,10,1) , input_shape=(LATENT_DIM , ))) #隐变量的维度为100维 所以将其reshape一下 成为图片的形状\n",
    "    #\n",
    "    #model.add(Conv2DTranspose(filters=2 , kernel_size=(4,4) , activation='relu' , name='transconv1'))\n",
    "    #model.add(BatchNormalization(momentum=0.8 , name='batchnorm1'))\n",
    "    #model.add(Conv2DTranspose(filters=2 , kernel_size=(5,5) , activation='relu' , name='transconv2'))\n",
    "    #model.add(BatchNormalization(momentum=0.8 , name='batchnorm2'))\n",
    "    #model.add(Conv2DTranspose(filters=2 , kernel_size=(5,5) , activation='relu' , name='transconv3'))\n",
    "    #model.add(BatchNormalization(momentum=0.8 , name='batchnorm3'))\n",
    "    #model.add(Conv2DTranspose(filters=2 , kernel_size=(10,10) , activation='relu' , name='transconv4'))\n",
    "    #model.add(BatchNormalization(momentum=0.8 , name='batchnorm4'))\n",
    "    #model.add(Conv2DTranspose(filters=2 , kernel_size=(10,10) , activation='relu' , name='transconv5'))\n",
    "    #model.add(BatchNormalization(momentum=0.8 , name='batchnorm5'))\n",
    "    #model.add(Conv2DTranspose(filters=2 , kernel_size=(20,20) , activation='relu' , name='transconv6'))\n",
    "    #model.add(BatchNormalization(momentum=0.8 , name='batchnorm6'))\n",
    "    #model.add(Conv2DTranspose(filters=2 , kernel_size=(20,20) , activation='relu' , name='transconv7'))\n",
    "    #model.add(BatchNormalization(momentum=0.8 , name='batchnorm7'))\n",
    "    #\n",
    "    #model.add(Conv2DTranspose(filters=FINAL_LAYER_FILTER , kernel_size=(20,20) , activation='tanh' , name='transconv8')) #最后一层必须与判别器的输入channel一致\n",
    "    #model.add(BatchNormalization(momentum=0.8 , name='batchnorm8'))\n",
    "\n",
    "    #mnist 图像使用 28*28*1\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=(LATENT_DIM,)))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(UpSampling2D())\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(UpSampling2D())\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Conv2D(CHANNEL, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    #\n",
    "    model.summary()\n",
    "    \n",
    "    noise = Input(shape=(LATENT_DIM , ) , name='input1')\n",
    "    label = Input(shape=(1,) , dtype='int32')\n",
    "    \n",
    "    _ = Embedding(input_dim=CLASS_NUM , output_dim=LATENT_DIM)(label)\n",
    "    embedding_label = Flatten()(_)\n",
    "    \n",
    "    noise_embedding_label = Multiply()([noise , embedding_label]) #(None , LATENT_DIM)\n",
    "    \n",
    "    image = model(noise_embedding_label)\n",
    "    \n",
    "    return Model([noise , label] , image , name='generator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    #input a image to discriminate real or fake\n",
    "    model = Sequential(name='discriminator')\n",
    "    \n",
    "    model.add(Conv2D(filters=32 , kernel_size=(3,3) , strides=(2,2) , padding='same' , input_shape=(WIDTH , HEIGHT , CHANNEL) , name='conv1'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(filters=64 , kernel_size=(3,3) , strides=(2,2) , padding='same' , name='conv2'))\n",
    "    model.add(ZeroPadding2D(padding=((0,1) , (0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=128 , kernel_size=(3,3) , strides=(2,2) , padding='same' , name='conv3'))\n",
    "    model.add(BatchNormalization(momentum=0.8))  \n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    \n",
    "    model.add(Conv2D(filters=256 , kernel_size=(3,3) , strides=(1,1) , name='conv4'))\n",
    "    model.add(BatchNormalization(momentum=0.8))  \n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    image = Input(shape=(WIDTH , HEIGHT , CHANNEL) , name='input1')\n",
    "    flatten_feature = model(image)\n",
    "    \n",
    "    validity = Dense(1 , activation='sigmoid')(flatten_feature)\n",
    "    label_hat = Dense(CLASS_NUM , activation='softmax')(flatten_feature) #CLASS_NUM位置是否需要加1 双输出 双损失函数 为每一个输出指定损失权重\n",
    "    \n",
    "    return Model(image , [validity , label_hat] , name='discriminator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined_model(generator_i , discriminator_i):\n",
    "    #生成器和判别器组合成整体\n",
    "    z = Input(shape=(LATENT_DIM , ) , name='z')\n",
    "    label = Input(shape=(1,) , dtype='int32')\n",
    "    \n",
    "    image = generator_i([z , label])\n",
    "    \n",
    "    #print(image.shape)\n",
    "    \n",
    "    discriminator_i.trainable = False\n",
    "    validity , label_hat = discriminator_i(image)\n",
    "    \n",
    "    return Model([z , label] , [validity , label_hat] , name='combined_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.0002 , beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1024)              0         \n",
      "=================================================================\n",
      "Total params: 389,632\n",
      "Trainable params: 388,736\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_i = discriminator()\n",
    "discriminator_i.compile(optimizer=adam , loss=['binary_crossentropy' , 'sparse_categorical_crossentropy'] , metrics=['accuracy'])\n",
    "\n",
    "generator_i = generator()\n",
    "\n",
    "combined_model_i = combined_model(generator_i , discriminator_i)\n",
    "\n",
    "\n",
    "combined_model_i.compile(optimizer=adam , loss=['binary_crossentropy' , 'sparse_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss:0.749658 accu:0.714697 gene_loss:[validity:0.763161 softmax:0.761556]\n",
      "epoch:1 loss:0.736843 accu:0.692463 gene_loss:[validity:0.763670 softmax:0.759564]\n",
      "epoch:2 loss:0.751206 accu:0.696420 gene_loss:[validity:0.819959 softmax:0.818049]\n",
      "epoch:3 loss:0.710645 accu:0.663608 gene_loss:[validity:0.808294 softmax:0.793697]\n",
      "epoch:4 loss:0.724748 accu:0.679637 gene_loss:[validity:0.867248 softmax:0.864374]\n",
      "epoch:5 loss:0.707309 accu:0.685248 gene_loss:[validity:0.857503 softmax:0.778340]\n",
      "epoch:6 loss:0.711751 accu:0.681667 gene_loss:[validity:0.907992 softmax:0.898614]\n",
      "epoch:7 loss:0.687202 accu:0.678705 gene_loss:[validity:0.843686 softmax:0.838819]\n",
      "epoch:8 loss:0.733125 accu:0.722096 gene_loss:[validity:0.844076 softmax:0.835639]\n",
      "epoch:9 loss:0.742486 accu:0.675067 gene_loss:[validity:0.774666 softmax:0.770848]\n",
      "epoch:10 loss:0.704974 accu:0.663348 gene_loss:[validity:0.808949 softmax:0.808330]\n",
      "epoch:11 loss:0.683715 accu:0.680913 gene_loss:[validity:0.804107 softmax:0.799430]\n",
      "epoch:12 loss:0.684824 accu:0.658855 gene_loss:[validity:0.785768 softmax:0.778836]\n",
      "epoch:13 loss:0.733128 accu:0.686531 gene_loss:[validity:0.739391 softmax:0.735915]\n",
      "epoch:14 loss:0.691832 accu:0.665214 gene_loss:[validity:0.857965 softmax:0.855054]\n",
      "epoch:15 loss:0.708278 accu:0.663420 gene_loss:[validity:0.834363 softmax:0.830208]\n",
      "epoch:16 loss:0.699487 accu:0.667820 gene_loss:[validity:0.822662 softmax:0.817497]\n",
      "epoch:17 loss:0.689604 accu:0.655613 gene_loss:[validity:0.873830 softmax:0.842375]\n",
      "epoch:18 loss:0.646681 accu:0.641316 gene_loss:[validity:0.800333 softmax:0.797488]\n",
      "epoch:19 loss:0.724187 accu:0.701615 gene_loss:[validity:0.805661 softmax:0.798564]\n",
      "epoch:20 loss:0.672893 accu:0.641828 gene_loss:[validity:0.784796 softmax:0.775509]\n",
      "epoch:21 loss:0.716231 accu:0.681638 gene_loss:[validity:0.788056 softmax:0.787563]\n",
      "epoch:22 loss:0.698360 accu:0.666124 gene_loss:[validity:0.737433 softmax:0.734984]\n",
      "epoch:23 loss:0.725798 accu:0.694825 gene_loss:[validity:0.863624 softmax:0.815177]\n",
      "epoch:24 loss:0.710320 accu:0.680552 gene_loss:[validity:0.803326 softmax:0.770912]\n",
      "epoch:25 loss:0.828395 accu:0.709854 gene_loss:[validity:0.854643 softmax:0.833616]\n",
      "epoch:26 loss:0.715925 accu:0.713711 gene_loss:[validity:0.762819 softmax:0.761721]\n",
      "epoch:27 loss:0.677013 accu:0.664630 gene_loss:[validity:0.796637 softmax:0.795007]\n",
      "epoch:28 loss:0.676772 accu:0.667395 gene_loss:[validity:0.803605 softmax:0.802611]\n",
      "epoch:29 loss:0.712773 accu:0.682976 gene_loss:[validity:0.764677 softmax:0.762876]\n",
      "epoch:30 loss:0.767983 accu:0.715962 gene_loss:[validity:0.821459 softmax:0.821220]\n",
      "epoch:31 loss:0.698732 accu:0.645105 gene_loss:[validity:0.780942 softmax:0.779209]\n",
      "epoch:32 loss:0.708830 accu:0.654335 gene_loss:[validity:0.818454 softmax:0.760581]\n",
      "epoch:33 loss:0.660539 accu:0.649371 gene_loss:[validity:0.750820 softmax:0.749048]\n",
      "epoch:34 loss:0.713915 accu:0.707278 gene_loss:[validity:0.763988 softmax:0.752465]\n",
      "epoch:35 loss:0.710737 accu:0.689059 gene_loss:[validity:0.833212 softmax:0.801654]\n",
      "epoch:36 loss:0.717741 accu:0.671862 gene_loss:[validity:0.845031 softmax:0.842737]\n",
      "epoch:37 loss:0.704183 accu:0.676280 gene_loss:[validity:0.798971 softmax:0.797369]\n",
      "epoch:38 loss:0.690917 accu:0.648892 gene_loss:[validity:0.803520 softmax:0.796294]\n",
      "epoch:39 loss:0.716057 accu:0.680818 gene_loss:[validity:0.920962 softmax:0.895766]\n",
      "epoch:40 loss:0.723505 accu:0.694610 gene_loss:[validity:0.808295 softmax:0.772984]\n",
      "epoch:41 loss:0.764224 accu:0.695935 gene_loss:[validity:0.799421 softmax:0.794725]\n",
      "epoch:42 loss:0.743076 accu:0.686966 gene_loss:[validity:0.700461 softmax:0.698762]\n",
      "epoch:43 loss:0.713681 accu:0.689596 gene_loss:[validity:0.771138 softmax:0.761343]\n",
      "epoch:44 loss:0.642800 accu:0.631580 gene_loss:[validity:0.799262 softmax:0.797895]\n",
      "epoch:45 loss:0.750442 accu:0.694670 gene_loss:[validity:0.778765 softmax:0.778522]\n",
      "epoch:46 loss:0.688095 accu:0.681850 gene_loss:[validity:0.874642 softmax:0.835850]\n",
      "epoch:47 loss:0.700168 accu:0.659448 gene_loss:[validity:0.900046 softmax:0.897769]\n",
      "epoch:48 loss:0.745956 accu:0.730247 gene_loss:[validity:0.886175 softmax:0.836859]\n",
      "epoch:49 loss:0.670078 accu:0.665835 gene_loss:[validity:0.836883 softmax:0.835915]\n",
      "epoch:50 loss:0.704150 accu:0.693470 gene_loss:[validity:0.812007 softmax:0.781943]\n",
      "epoch:51 loss:0.749195 accu:0.714477 gene_loss:[validity:0.726375 softmax:0.725284]\n",
      "epoch:52 loss:0.722063 accu:0.714087 gene_loss:[validity:0.797645 softmax:0.770931]\n",
      "epoch:53 loss:0.704979 accu:0.650418 gene_loss:[validity:0.829232 softmax:0.828002]\n",
      "epoch:54 loss:0.739308 accu:0.703660 gene_loss:[validity:0.766029 softmax:0.765522]\n",
      "epoch:55 loss:0.720697 accu:0.676032 gene_loss:[validity:0.808001 softmax:0.805458]\n",
      "epoch:56 loss:0.697763 accu:0.685521 gene_loss:[validity:0.704486 softmax:0.703044]\n",
      "epoch:57 loss:0.693886 accu:0.675858 gene_loss:[validity:0.835410 softmax:0.829835]\n",
      "epoch:58 loss:0.653579 accu:0.651062 gene_loss:[validity:0.790833 softmax:0.765454]\n",
      "epoch:59 loss:0.833093 accu:0.758952 gene_loss:[validity:0.790635 softmax:0.786387]\n",
      "epoch:60 loss:0.638252 accu:0.634908 gene_loss:[validity:0.726680 softmax:0.716896]\n",
      "epoch:61 loss:0.799778 accu:0.734537 gene_loss:[validity:0.817626 softmax:0.811756]\n",
      "epoch:62 loss:0.728929 accu:0.706675 gene_loss:[validity:0.769041 softmax:0.767939]\n",
      "epoch:63 loss:0.679312 accu:0.666945 gene_loss:[validity:0.852404 softmax:0.835332]\n",
      "epoch:64 loss:0.875933 accu:0.726597 gene_loss:[validity:0.752189 softmax:0.705161]\n",
      "epoch:65 loss:0.693614 accu:0.688729 gene_loss:[validity:0.742380 softmax:0.738934]\n",
      "epoch:66 loss:0.729218 accu:0.724606 gene_loss:[validity:0.792077 softmax:0.787621]\n",
      "epoch:67 loss:0.886508 accu:0.780820 gene_loss:[validity:0.708533 softmax:0.707713]\n",
      "epoch:68 loss:0.732162 accu:0.708789 gene_loss:[validity:0.786532 softmax:0.759091]\n",
      "epoch:69 loss:0.726061 accu:0.714390 gene_loss:[validity:0.727293 softmax:0.724878]\n",
      "epoch:70 loss:0.790863 accu:0.760853 gene_loss:[validity:0.744254 softmax:0.740650]\n",
      "epoch:71 loss:0.636289 accu:0.631995 gene_loss:[validity:0.736946 softmax:0.729826]\n",
      "epoch:72 loss:0.687656 accu:0.678745 gene_loss:[validity:0.733407 softmax:0.730489]\n",
      "epoch:73 loss:0.676367 accu:0.658382 gene_loss:[validity:0.739203 softmax:0.727932]\n",
      "epoch:74 loss:0.713000 accu:0.674563 gene_loss:[validity:0.873312 softmax:0.868677]\n",
      "epoch:75 loss:0.691143 accu:0.670385 gene_loss:[validity:0.801268 softmax:0.793033]\n",
      "epoch:76 loss:0.669591 accu:0.657828 gene_loss:[validity:0.897805 softmax:0.896684]\n",
      "epoch:77 loss:0.748180 accu:0.723513 gene_loss:[validity:0.788366 softmax:0.786504]\n",
      "epoch:78 loss:0.692664 accu:0.623687 gene_loss:[validity:0.728396 softmax:0.727343]\n",
      "epoch:79 loss:0.751657 accu:0.665844 gene_loss:[validity:0.736002 softmax:0.731274]\n",
      "epoch:80 loss:0.756216 accu:0.690737 gene_loss:[validity:0.746070 softmax:0.745033]\n",
      "epoch:81 loss:0.649244 accu:0.647230 gene_loss:[validity:0.810542 softmax:0.798627]\n",
      "epoch:82 loss:0.722245 accu:0.686519 gene_loss:[validity:0.835454 softmax:0.812207]\n",
      "epoch:83 loss:0.683175 accu:0.647821 gene_loss:[validity:0.900878 softmax:0.900094]\n",
      "epoch:84 loss:0.652519 accu:0.640166 gene_loss:[validity:0.829165 softmax:0.821334]\n",
      "epoch:85 loss:0.654960 accu:0.635238 gene_loss:[validity:0.829111 softmax:0.809652]\n",
      "epoch:86 loss:0.791570 accu:0.683859 gene_loss:[validity:0.816343 softmax:0.815700]\n",
      "epoch:87 loss:0.666615 accu:0.661844 gene_loss:[validity:0.786363 softmax:0.784750]\n",
      "epoch:88 loss:0.727535 accu:0.719383 gene_loss:[validity:0.772927 softmax:0.770220]\n",
      "epoch:89 loss:0.807699 accu:0.744603 gene_loss:[validity:0.695784 softmax:0.694773]\n",
      "epoch:90 loss:0.808138 accu:0.760679 gene_loss:[validity:0.799197 softmax:0.797142]\n",
      "epoch:91 loss:0.738463 accu:0.710127 gene_loss:[validity:0.775926 softmax:0.772865]\n",
      "epoch:92 loss:0.737551 accu:0.709716 gene_loss:[validity:0.734073 softmax:0.732611]\n",
      "epoch:93 loss:0.736724 accu:0.704023 gene_loss:[validity:0.840809 softmax:0.838993]\n",
      "epoch:94 loss:0.684985 accu:0.663732 gene_loss:[validity:0.840325 softmax:0.836118]\n",
      "epoch:95 loss:0.732309 accu:0.701453 gene_loss:[validity:0.780633 softmax:0.764535]\n",
      "epoch:96 loss:0.803244 accu:0.703550 gene_loss:[validity:0.841454 softmax:0.839619]\n",
      "epoch:97 loss:0.682799 accu:0.672432 gene_loss:[validity:0.757612 softmax:0.755446]\n",
      "epoch:98 loss:0.665965 accu:0.658981 gene_loss:[validity:0.822797 softmax:0.821730]\n",
      "epoch:99 loss:0.677716 accu:0.673118 gene_loss:[validity:0.798138 softmax:0.795525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:100 loss:0.687064 accu:0.616158 gene_loss:[validity:0.853689 softmax:0.835409]\n"
     ]
    }
   ],
   "source": [
    "real_labels = np.ones(shape=(BATCH_SIZE , 1)) #真实样本label为1\n",
    "fake_labels = np.zeros(shape=(BATCH_SIZE , 1)) #假样本label为0\n",
    "\n",
    "for i in range(101):\n",
    "    noise = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "    corresponding_fake_label = np.random.randint(low=0 , high=CLASS_NUM , size=(BATCH_SIZE , 1)) #label的取值范围 可能会发生变化\n",
    "\n",
    "    #real_image = load_image()\n",
    "    real_image , corresponding_real_label = load_mnist()\n",
    "    #训练判别器\n",
    "    fake_image = generator_i.predict([noise , corresponding_fake_label])\n",
    "\n",
    "    real_loss = discriminator_i.train_on_batch(real_image , [real_labels , corresponding_real_label])\n",
    "    fake_loss = discriminator_i.train_on_batch(fake_image , [fake_labels , corresponding_fake_label])\n",
    "\n",
    "    loss = np.add(real_loss , fake_loss)/2\n",
    "\n",
    "    #训练生成器\n",
    "    noise2 = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "    corresponding_fake_label2 = np.random.randint(low=0 , high=CLASS_NUM , size=(BATCH_SIZE , 1))\n",
    "    \n",
    "        #下面的损失是一个list 有两个损失 一个是validity一个是与label的softmax\n",
    "    generator_loss = combined_model_i.train_on_batch([noise2 , corresponding_fake_label2] , [real_labels , corresponding_fake_label2])\n",
    "    \n",
    "    print('epoch:%d loss:%f accu:%f gene_loss:[validity:%f softmax:%f]' % (i , loss[0] , loss[1] , generator_loss[0] , generator_loss[1]))\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        #write_image(i)\n",
    "        write_image_mnist(i)\n",
    "    \n",
    "#write_image(999)\n",
    "write_image_mnist(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator (Sequential)   (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 0\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator (Sequential)       (None, 28, 28, 1)         1097744   \n",
      "=================================================================\n",
      "Total params: 1,097,744\n",
      "Trainable params: 1,095,184\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z (InputLayer)               (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator_Model (Model)      (None, 96, 96, 3)         29029120  \n",
      "_________________________________________________________________\n",
      "discriminator_Model (Model)  (None, 1)                 14320641  \n",
      "=================================================================\n",
      "Total params: 43,349,761\n",
      "Trainable params: 29,025,536\n",
      "Non-trainable params: 14,324,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeli = Sequential()\n",
    "\n",
    "modeli.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=(LATENT_DIM,)))\n",
    "modeli.add(Reshape((7, 7, 128)))\n",
    "modeli.add(UpSampling2D())\n",
    "modeli.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "modeli.add(BatchNormalization(momentum=0.8))\n",
    "modeli.add(Activation(\"relu\"))\n",
    "modeli.add(UpSampling2D())\n",
    "modeli.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "modeli.add(BatchNormalization(momentum=0.8))\n",
    "modeli.add(Activation(\"relu\"))\n",
    "modeli.add(Conv2D(CHANNEL, kernel_size=3, padding=\"same\"))\n",
    "modeli.add(Activation(\"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modeli.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
