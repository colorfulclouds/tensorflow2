{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense ,  BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D , Conv2DTranspose , UpSampling2D , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.initializers import truncated_normal , constant , random_normal\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH = 96\n",
    "HEIGHT = 96\n",
    "CHANNEL = 3\n",
    "\n",
    "LATENT_DIM = 100 #latent variable z sample from normal distribution\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = 'faces/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 5\n",
    "COL = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "load_index = 0\n",
    "\n",
    "images_name = os.listdir(PATH)\n",
    "\n",
    "IMAGES_COUNT = len(images_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(X_train , y_train),(X_test , y_test) = mnist.load_data()\\nX_train = X_train/127.5-1\\nX_train = np.expand_dims(X_train , 3)\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "(X_train , y_train),(X_test , y_test) = mnist.load_data()\n",
    "X_train = X_train/127.5-1\n",
    "X_train = np.expand_dims(X_train , 3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef load_mnist():\\n    return X_train[np.random.randint(0, X_train.shape[0], BATCH_SIZE)]\\n    \\ndef write_image_mnist(epoch):\\n    \\n    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\\n    generated_image = generator_i.predict(noise)\\n    generated_image = generated_image*0.5+0.5\\n    \\n    fig , axes = plt.pyplot.subplots(ROW , COL)\\n    \\n    count=0\\n    \\n    for i in range(ROW):\\n        for j in range(COL):\\n            axes[i][j].imshow(generated_image[count,:,:,0] , cmap = 'gray')\\n            axes[i][j].axis('off')\\n            count += 1\\n            \\n    fig.savefig('mnist_dcgan/No.%d.png' % epoch)\\n    plt.pyplot.close()\\n\\n\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def load_mnist():\n",
    "    return X_train[np.random.randint(0, X_train.shape[0], BATCH_SIZE)]\n",
    "    \n",
    "def write_image_mnist(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    generated_image = generator_i.predict(noise)\n",
    "    generated_image = generated_image*0.5+0.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count,:,:,0] , cmap = 'gray')\n",
    "            axes[i][j].axis('off')\n",
    "            count += 1\n",
    "            \n",
    "    fig.savefig('mnist_dcgan/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_image(batch_size = BATCH_SIZE):\n",
    "    global load_index\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        images.append(plt.image.imread(PATH + images_name[(load_index + i) % IMAGES_COUNT]))\n",
    "    \n",
    "    load_index += batch_size\n",
    "    \n",
    "    return (np.array(images)/127.5)-1.0\n",
    "\n",
    "def write_image(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    generated_image = generator_i.predict(noise)\n",
    "    generated_image = np.floor(((generated_image+1.0)*127.5))\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count])\n",
    "            axes[i][j].axis('off')\n",
    "            count += 1\n",
    "            \n",
    "    fig.savefig('generated_faces_dcgan/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "    \n",
    "    #plt.image.imsave('images/'+str(epoch)+'.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(output_size):\n",
    "    return Conv2D(output_size , kernel_size=(5,5) , strides=(2,2) , padding='same' , kernel_initializer=truncated_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n",
    "def dense(output_size):\n",
    "    return Dense(output_size , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n",
    "def deconv2d(output_size):\n",
    "    return Conv2DTranspose(output_size , kernel_size=(5,5) , strides=(2,2) , padding='same' , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n",
    "def batch_norm():\n",
    "    return BatchNormalization(momentum=0.9 , epsilon=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator():\n",
    "    #sample from noise z\n",
    "    model = Sequential(name='generator')\n",
    "    \n",
    "    #cartoon 图像使用 96*96*3\n",
    "    model.add(Dense(6*6*8*64 , input_shape=(LATENT_DIM,) , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0)))\n",
    "    \n",
    "    model.add(Reshape((6, 6, 64*8)))\n",
    "    \n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(deconv2d(64*4))\n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(deconv2d(64*2))\n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(deconv2d(64*1))\n",
    "    model.add(batch_norm())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(deconv2d(3))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    noise = Input(shape=(LATENT_DIM , ) , name='input1')\n",
    "    image = model(noise)\n",
    "    \n",
    "    return Model(noise , image , name='generator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    #input a image to discriminate real or fake\n",
    "    model = Sequential(name='discriminator')\n",
    "    \n",
    "    model.add(Conv2D(filters=64 , kernel_size=(5,5) , strides=(2,2) , padding='same' , input_shape=(WIDTH , HEIGHT , CHANNEL) , kernel_initializer=truncated_normal(stddev=0.02) , bias_initializer=constant(0.0) , name='conv1'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #model.add(Dropout(0.25))\n",
    "    \n",
    "    #model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(conv2d(64*2))\n",
    "    model.add(batch_norm())\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(conv2d(64*4))\n",
    "    model.add(batch_norm())  \n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    \n",
    "    model.add(conv2d(64*8))\n",
    "    model.add(batch_norm())  \n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #===\n",
    "    model.add(dense(1024))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    #===\n",
    "    model.add(dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    image = Input(shape=(WIDTH , HEIGHT , CHANNEL) , name='input1')\n",
    "    validity = model(image)\n",
    "    \n",
    "    return Model(image , validity , name='discriminator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combined_model(generator_i , discriminator_i):\n",
    "    #生成器和判别器组合成整体\n",
    "    z = Input(shape=(LATENT_DIM , ) , name='z')\n",
    "    \n",
    "    image = generator_i(z)\n",
    "    \n",
    "    #print(image.shape)\n",
    "    \n",
    "    discriminator_i.trainable = False\n",
    "    validity = discriminator_i(image)\n",
    "    \n",
    "    return Model(z , validity , name='combined_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.0002 , beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_i = discriminator()\n",
    "discriminator_i.compile(optimizer=adam , loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "generator_i = generator()\n",
    "\n",
    "combined_model_i = combined_model(generator_i , discriminator_i)\n",
    "\n",
    "\n",
    "combined_model_i.compile(optimizer=adam , loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 batch:0 loss:1.532499 accu:0.031250 gene_loss:0.709593\n",
      "epoch:0 batch:1 loss:0.472405 accu:0.523438 gene_loss:1.578565\n",
      "epoch:0 batch:2 loss:0.371663 accu:1.000000 gene_loss:2.661038\n",
      "epoch:0 batch:3 loss:0.224815 accu:0.992188 gene_loss:4.418355\n",
      "epoch:0 batch:4 loss:0.122419 accu:0.992188 gene_loss:4.013967\n",
      "epoch:0 batch:5 loss:0.157530 accu:1.000000 gene_loss:8.017440\n",
      "epoch:0 batch:6 loss:0.093054 accu:0.968750 gene_loss:6.039183\n",
      "epoch:0 batch:7 loss:0.162589 accu:0.984375 gene_loss:10.644134\n",
      "epoch:0 batch:8 loss:0.067714 accu:0.976562 gene_loss:11.256130\n",
      "epoch:0 batch:9 loss:0.026691 accu:1.000000 gene_loss:4.857416\n",
      "epoch:0 batch:10 loss:0.458809 accu:0.617188 gene_loss:15.747258\n",
      "epoch:0 batch:11 loss:0.324746 accu:0.835938 gene_loss:14.454495\n",
      "epoch:0 batch:12 loss:0.003791 accu:1.000000 gene_loss:8.059889\n",
      "epoch:0 batch:13 loss:1.871708 accu:0.500000 gene_loss:13.974639\n",
      "epoch:0 batch:14 loss:0.496819 accu:0.781250 gene_loss:10.880688\n",
      "epoch:0 batch:15 loss:0.076631 accu:0.976562 gene_loss:6.461460\n",
      "epoch:0 batch:16 loss:0.200489 accu:0.953125 gene_loss:7.631796\n",
      "epoch:0 batch:17 loss:0.097798 accu:0.968750 gene_loss:5.089967\n",
      "epoch:0 batch:18 loss:2.050732 accu:0.476562 gene_loss:9.729780\n",
      "epoch:0 batch:19 loss:0.920202 accu:0.625000 gene_loss:2.244295\n",
      "epoch:0 batch:20 loss:0.462531 accu:0.781250 gene_loss:1.955815\n",
      "epoch:0 batch:21 loss:0.492363 accu:0.718750 gene_loss:4.318455\n",
      "epoch:0 batch:22 loss:0.542715 accu:0.757812 gene_loss:3.826031\n",
      "epoch:0 batch:23 loss:0.213852 accu:0.968750 gene_loss:2.711500\n",
      "epoch:0 batch:24 loss:0.225130 accu:0.984375 gene_loss:5.347240\n",
      "epoch:0 batch:25 loss:0.381452 accu:0.820312 gene_loss:1.641806\n",
      "epoch:0 batch:26 loss:1.382396 accu:0.500000 gene_loss:8.366367\n",
      "epoch:0 batch:27 loss:0.779598 accu:0.664062 gene_loss:4.416759\n",
      "epoch:0 batch:28 loss:0.651537 accu:0.554688 gene_loss:2.309664\n",
      "epoch:0 batch:29 loss:0.246437 accu:0.843750 gene_loss:1.948718\n",
      "epoch:0 batch:30 loss:0.144878 accu:0.976562 gene_loss:0.997524\n",
      "epoch:0 batch:31 loss:0.211625 accu:0.953125 gene_loss:1.045964\n",
      "epoch:0 batch:32 loss:0.242110 accu:0.914062 gene_loss:3.632885\n",
      "epoch:0 batch:33 loss:0.943064 accu:0.507812 gene_loss:5.845024\n",
      "epoch:0 batch:34 loss:0.667987 accu:0.757812 gene_loss:2.800427\n",
      "epoch:0 batch:35 loss:0.271665 accu:0.898438 gene_loss:2.476010\n",
      "epoch:0 batch:36 loss:0.144031 accu:0.945312 gene_loss:2.140146\n",
      "epoch:0 batch:37 loss:0.442271 accu:0.812500 gene_loss:6.882345\n",
      "epoch:0 batch:38 loss:0.494259 accu:0.812500 gene_loss:4.252535\n",
      "epoch:0 batch:39 loss:0.539430 accu:0.726562 gene_loss:6.260743\n",
      "epoch:0 batch:40 loss:0.187580 accu:0.929688 gene_loss:3.082144\n",
      "epoch:0 batch:41 loss:0.935584 accu:0.578125 gene_loss:1.997057\n",
      "epoch:0 batch:42 loss:0.241414 accu:0.921875 gene_loss:2.886386\n",
      "epoch:0 batch:43 loss:0.399668 accu:0.820312 gene_loss:2.517566\n",
      "epoch:0 batch:44 loss:0.402986 accu:0.851562 gene_loss:3.952225\n",
      "epoch:0 batch:45 loss:0.207901 accu:0.929688 gene_loss:3.599007\n",
      "epoch:0 batch:46 loss:0.307885 accu:0.882812 gene_loss:4.477692\n",
      "epoch:0 batch:47 loss:0.201893 accu:0.929688 gene_loss:1.689210\n",
      "epoch:0 batch:48 loss:0.290738 accu:0.875000 gene_loss:5.731266\n",
      "epoch:0 batch:49 loss:0.450784 accu:0.757812 gene_loss:1.190922\n",
      "epoch:0 batch:50 loss:0.770381 accu:0.546875 gene_loss:8.221374\n",
      "epoch:0 batch:51 loss:0.343681 accu:0.828125 gene_loss:6.514257\n",
      "epoch:0 batch:52 loss:0.333145 accu:0.867188 gene_loss:3.369523\n",
      "epoch:0 batch:53 loss:0.245264 accu:0.914062 gene_loss:4.200732\n",
      "epoch:0 batch:54 loss:0.165340 accu:0.960938 gene_loss:1.820206\n",
      "epoch:0 batch:55 loss:0.557357 accu:0.671875 gene_loss:8.270420\n",
      "epoch:0 batch:56 loss:0.456633 accu:0.750000 gene_loss:3.687609\n",
      "epoch:0 batch:57 loss:0.207093 accu:0.945312 gene_loss:3.065517\n",
      "epoch:0 batch:58 loss:0.132259 accu:0.968750 gene_loss:1.851833\n",
      "epoch:0 batch:59 loss:0.456817 accu:0.773438 gene_loss:9.002748\n",
      "epoch:0 batch:60 loss:0.726167 accu:0.617188 gene_loss:2.370839\n",
      "epoch:0 batch:61 loss:0.797510 accu:0.554688 gene_loss:4.476697\n",
      "epoch:0 batch:62 loss:0.114180 accu:0.984375 gene_loss:4.178381\n",
      "epoch:0 batch:63 loss:0.797666 accu:0.625000 gene_loss:5.758613\n",
      "epoch:0 batch:64 loss:0.361306 accu:0.796875 gene_loss:4.298588\n",
      "epoch:0 batch:65 loss:0.411222 accu:0.804688 gene_loss:4.286874\n",
      "epoch:0 batch:66 loss:0.197630 accu:0.937500 gene_loss:3.641947\n",
      "epoch:0 batch:67 loss:0.188214 accu:0.953125 gene_loss:5.625604\n",
      "epoch:0 batch:68 loss:0.143462 accu:0.937500 gene_loss:3.786211\n",
      "epoch:0 batch:69 loss:0.346046 accu:0.835938 gene_loss:7.376120\n",
      "epoch:0 batch:70 loss:0.446018 accu:0.773438 gene_loss:2.705973\n",
      "epoch:0 batch:71 loss:1.183106 accu:0.562500 gene_loss:5.443757\n",
      "epoch:0 batch:72 loss:0.394629 accu:0.796875 gene_loss:3.929533\n",
      "epoch:0 batch:73 loss:0.283679 accu:0.906250 gene_loss:2.660759\n",
      "epoch:0 batch:74 loss:0.354472 accu:0.906250 gene_loss:4.699320\n",
      "epoch:0 batch:75 loss:0.200137 accu:0.921875 gene_loss:3.277617\n",
      "epoch:0 batch:76 loss:0.306417 accu:0.867188 gene_loss:5.082146\n",
      "epoch:0 batch:77 loss:0.260773 accu:0.914062 gene_loss:3.127244\n",
      "epoch:0 batch:78 loss:0.760594 accu:0.554688 gene_loss:6.426654\n",
      "epoch:0 batch:79 loss:0.444554 accu:0.726562 gene_loss:3.466176\n",
      "epoch:0 batch:80 loss:0.199686 accu:1.000000 gene_loss:2.358302\n",
      "epoch:0 batch:81 loss:0.152504 accu:0.992188 gene_loss:3.299081\n",
      "epoch:0 batch:82 loss:0.176173 accu:0.984375 gene_loss:4.116261\n",
      "epoch:0 batch:83 loss:0.271345 accu:0.914062 gene_loss:6.226907\n",
      "epoch:0 batch:84 loss:0.224116 accu:0.921875 gene_loss:3.595943\n",
      "epoch:0 batch:85 loss:0.740211 accu:0.601562 gene_loss:9.189350\n",
      "epoch:0 batch:86 loss:1.188479 accu:0.601562 gene_loss:1.616750\n",
      "epoch:0 batch:87 loss:0.520785 accu:0.765625 gene_loss:2.573063\n",
      "epoch:0 batch:88 loss:0.265495 accu:0.945312 gene_loss:3.149557\n",
      "epoch:0 batch:89 loss:0.222674 accu:0.960938 gene_loss:3.574497\n",
      "epoch:0 batch:90 loss:0.139184 accu:0.984375 gene_loss:3.505251\n",
      "epoch:0 batch:91 loss:0.175054 accu:0.960938 gene_loss:4.017298\n",
      "epoch:0 batch:92 loss:0.235458 accu:0.945312 gene_loss:5.003578\n",
      "epoch:0 batch:93 loss:0.188209 accu:0.960938 gene_loss:5.095632\n",
      "epoch:0 batch:94 loss:0.099633 accu:0.968750 gene_loss:1.723098\n",
      "epoch:0 batch:95 loss:0.112802 accu:0.968750 gene_loss:3.311159\n",
      "epoch:0 batch:96 loss:0.095667 accu:0.984375 gene_loss:0.807113\n",
      "epoch:0 batch:97 loss:0.031208 accu:1.000000 gene_loss:0.038556\n",
      "epoch:0 batch:98 loss:0.025460 accu:1.000000 gene_loss:0.025617\n",
      "epoch:0 batch:99 loss:0.018173 accu:1.000000 gene_loss:0.024557\n",
      "epoch:0 batch:100 loss:0.085758 accu:0.976562 gene_loss:0.276211\n",
      "epoch:0 batch:101 loss:0.020275 accu:1.000000 gene_loss:0.418967\n",
      "epoch:0 batch:102 loss:0.088017 accu:0.976562 gene_loss:2.241205\n",
      "epoch:0 batch:103 loss:0.406966 accu:0.835938 gene_loss:12.214830\n",
      "epoch:0 batch:104 loss:2.447248 accu:0.203125 gene_loss:2.445179\n",
      "epoch:0 batch:105 loss:0.097178 accu:0.976562 gene_loss:2.665331\n",
      "epoch:0 batch:106 loss:0.246529 accu:0.890625 gene_loss:1.076748\n",
      "epoch:0 batch:107 loss:0.251003 accu:0.898438 gene_loss:1.181964\n",
      "epoch:0 batch:108 loss:0.163833 accu:0.929688 gene_loss:0.599032\n",
      "epoch:0 batch:109 loss:0.222018 accu:0.937500 gene_loss:0.466370\n",
      "epoch:0 batch:110 loss:0.131631 accu:0.960938 gene_loss:0.418776\n",
      "epoch:0 batch:111 loss:0.100758 accu:0.984375 gene_loss:0.892351\n",
      "epoch:0 batch:112 loss:0.353775 accu:0.812500 gene_loss:5.073359\n",
      "epoch:0 batch:113 loss:0.663993 accu:0.679688 gene_loss:3.780151\n",
      "epoch:0 batch:114 loss:0.201937 accu:0.914062 gene_loss:3.328035\n",
      "epoch:0 batch:115 loss:0.412369 accu:0.851562 gene_loss:7.882832\n",
      "epoch:0 batch:116 loss:1.189333 accu:0.539062 gene_loss:1.096831\n",
      "epoch:0 batch:117 loss:0.700736 accu:0.703125 gene_loss:3.968498\n",
      "epoch:0 batch:118 loss:0.113402 accu:0.960938 gene_loss:3.194856\n",
      "epoch:0 batch:119 loss:0.676671 accu:0.601562 gene_loss:2.538623\n",
      "epoch:0 batch:120 loss:0.386003 accu:0.890625 gene_loss:2.429309\n",
      "epoch:0 batch:121 loss:0.282755 accu:0.953125 gene_loss:2.453111\n",
      "epoch:0 batch:122 loss:0.561648 accu:0.710938 gene_loss:6.151175\n",
      "epoch:0 batch:123 loss:0.488251 accu:0.804688 gene_loss:2.521254\n",
      "epoch:0 batch:124 loss:0.733490 accu:0.593750 gene_loss:5.113651\n",
      "epoch:0 batch:125 loss:0.530212 accu:0.765625 gene_loss:3.126773\n",
      "epoch:0 batch:126 loss:0.388771 accu:0.898438 gene_loss:3.493739\n",
      "epoch:0 batch:127 loss:0.102356 accu:0.984375 gene_loss:3.557726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 batch:128 loss:0.304907 accu:0.882812 gene_loss:5.646421\n",
      "epoch:0 batch:129 loss:0.150591 accu:0.953125 gene_loss:3.472129\n",
      "epoch:0 batch:130 loss:0.600873 accu:0.640625 gene_loss:6.791640\n",
      "epoch:0 batch:131 loss:0.494658 accu:0.742188 gene_loss:3.820701\n",
      "epoch:0 batch:132 loss:0.215073 accu:0.898438 gene_loss:2.978500\n",
      "epoch:0 batch:133 loss:0.092377 accu:0.960938 gene_loss:1.606507\n",
      "epoch:0 batch:134 loss:0.085242 accu:0.976562 gene_loss:0.337958\n",
      "epoch:0 batch:135 loss:0.050696 accu:1.000000 gene_loss:0.363656\n",
      "epoch:0 batch:136 loss:0.023948 accu:0.992188 gene_loss:0.272325\n",
      "epoch:0 batch:137 loss:0.024259 accu:1.000000 gene_loss:0.107272\n",
      "epoch:0 batch:138 loss:0.020259 accu:1.000000 gene_loss:0.071245\n",
      "epoch:0 batch:139 loss:0.030349 accu:1.000000 gene_loss:0.070611\n",
      "epoch:0 batch:140 loss:0.014010 accu:1.000000 gene_loss:0.111581\n",
      "epoch:0 batch:141 loss:0.011714 accu:1.000000 gene_loss:0.074572\n",
      "epoch:0 batch:142 loss:0.009197 accu:1.000000 gene_loss:0.080034\n",
      "epoch:0 batch:143 loss:0.016305 accu:1.000000 gene_loss:0.163487\n",
      "epoch:0 batch:144 loss:0.010260 accu:1.000000 gene_loss:0.225511\n",
      "epoch:0 batch:145 loss:0.024131 accu:1.000000 gene_loss:0.120965\n",
      "epoch:0 batch:146 loss:0.082124 accu:0.976562 gene_loss:5.700439\n",
      "epoch:0 batch:147 loss:0.883864 accu:0.710938 gene_loss:3.203856\n",
      "epoch:0 batch:148 loss:1.179575 accu:0.554688 gene_loss:7.528952\n",
      "epoch:0 batch:149 loss:2.098149 accu:0.265625 gene_loss:1.018258\n",
      "epoch:0 batch:150 loss:0.520956 accu:0.726562 gene_loss:1.458897\n",
      "epoch:0 batch:151 loss:0.417783 accu:0.867188 gene_loss:2.086727\n",
      "epoch:0 batch:152 loss:0.300964 accu:0.953125 gene_loss:1.934328\n",
      "epoch:0 batch:153 loss:0.243646 accu:0.960938 gene_loss:2.146239\n",
      "epoch:0 batch:154 loss:0.144706 accu:0.984375 gene_loss:2.159292\n",
      "epoch:0 batch:155 loss:0.098864 accu:1.000000 gene_loss:1.856696\n",
      "epoch:0 batch:156 loss:0.188528 accu:0.968750 gene_loss:3.534913\n",
      "epoch:0 batch:157 loss:0.299368 accu:0.898438 gene_loss:3.846675\n",
      "epoch:0 batch:158 loss:0.556476 accu:0.687500 gene_loss:7.214366\n",
      "epoch:0 batch:159 loss:1.085515 accu:0.601562 gene_loss:1.998083\n",
      "epoch:0 batch:160 loss:0.236854 accu:0.937500 gene_loss:2.592226\n",
      "epoch:0 batch:161 loss:0.075649 accu:0.992188 gene_loss:3.055019\n",
      "epoch:0 batch:162 loss:0.230432 accu:0.914062 gene_loss:3.401027\n",
      "epoch:0 batch:163 loss:0.147279 accu:0.960938 gene_loss:3.244554\n",
      "epoch:0 batch:164 loss:0.167149 accu:0.968750 gene_loss:3.941463\n",
      "epoch:0 batch:165 loss:0.072762 accu:0.992188 gene_loss:4.235696\n",
      "epoch:0 batch:166 loss:0.149768 accu:0.976562 gene_loss:4.937324\n",
      "epoch:0 batch:167 loss:0.073558 accu:0.976562 gene_loss:2.623736\n",
      "epoch:0 batch:168 loss:0.041997 accu:0.992188 gene_loss:0.017271\n",
      "epoch:0 batch:169 loss:0.037282 accu:0.992188 gene_loss:0.025885\n",
      "epoch:0 batch:170 loss:0.019183 accu:1.000000 gene_loss:0.013204\n",
      "epoch:0 batch:171 loss:0.009780 accu:1.000000 gene_loss:0.013482\n",
      "epoch:0 batch:172 loss:0.010561 accu:1.000000 gene_loss:0.011445\n",
      "epoch:0 batch:173 loss:0.012980 accu:1.000000 gene_loss:0.017924\n",
      "epoch:0 batch:174 loss:0.009259 accu:1.000000 gene_loss:0.021574\n",
      "epoch:0 batch:175 loss:0.010984 accu:1.000000 gene_loss:0.024446\n",
      "epoch:0 batch:176 loss:0.018648 accu:1.000000 gene_loss:0.083359\n",
      "epoch:0 batch:177 loss:0.006265 accu:1.000000 gene_loss:0.086492\n",
      "epoch:0 batch:178 loss:0.006253 accu:1.000000 gene_loss:0.118637\n",
      "epoch:0 batch:179 loss:0.015313 accu:1.000000 gene_loss:0.230973\n",
      "epoch:0 batch:180 loss:0.038175 accu:1.000000 gene_loss:0.429638\n",
      "epoch:0 batch:181 loss:0.049560 accu:1.000000 gene_loss:3.122166\n",
      "epoch:0 batch:182 loss:3.017909 accu:0.453125 gene_loss:11.984975\n",
      "epoch:0 batch:183 loss:4.903779 accu:0.468750 gene_loss:1.818733\n",
      "epoch:0 batch:184 loss:0.932457 accu:0.492188 gene_loss:0.767931\n",
      "epoch:0 batch:185 loss:0.715553 accu:0.359375 gene_loss:0.746478\n",
      "epoch:0 batch:186 loss:0.587762 accu:0.906250 gene_loss:0.821571\n",
      "epoch:0 batch:187 loss:0.628757 accu:0.710938 gene_loss:0.920556\n",
      "epoch:0 batch:188 loss:0.550343 accu:0.859375 gene_loss:0.964386\n",
      "epoch:0 batch:189 loss:0.520003 accu:0.859375 gene_loss:1.130294\n",
      "epoch:0 batch:190 loss:0.492643 accu:0.812500 gene_loss:1.252809\n",
      "epoch:0 batch:191 loss:0.430812 accu:0.898438 gene_loss:1.369347\n",
      "epoch:0 batch:192 loss:0.460075 accu:0.812500 gene_loss:1.356391\n",
      "epoch:0 batch:193 loss:0.401756 accu:0.890625 gene_loss:2.019217\n",
      "epoch:0 batch:194 loss:0.592328 accu:0.671875 gene_loss:2.002427\n",
      "epoch:0 batch:195 loss:0.540096 accu:0.750000 gene_loss:2.541893\n",
      "epoch:0 batch:196 loss:0.384347 accu:0.851562 gene_loss:2.547125\n",
      "epoch:0 batch:197 loss:0.507941 accu:0.726562 gene_loss:3.528015\n",
      "epoch:0 batch:198 loss:0.568598 accu:0.757812 gene_loss:1.883198\n",
      "epoch:0 batch:199 loss:0.338249 accu:0.867188 gene_loss:2.366450\n",
      "epoch:0 batch:200 loss:0.224982 accu:0.968750 gene_loss:3.247816\n",
      "epoch:0 batch:201 loss:0.761949 accu:0.539062 gene_loss:5.393901\n",
      "epoch:0 batch:202 loss:1.539547 accu:0.500000 gene_loss:1.642314\n",
      "epoch:0 batch:203 loss:0.601833 accu:0.718750 gene_loss:1.285482\n",
      "epoch:0 batch:204 loss:0.407804 accu:0.929688 gene_loss:1.608973\n",
      "epoch:0 batch:205 loss:0.320880 accu:0.953125 gene_loss:1.627379\n",
      "epoch:0 batch:206 loss:0.360371 accu:0.921875 gene_loss:1.848105\n",
      "epoch:0 batch:207 loss:0.289351 accu:0.945312 gene_loss:2.062940\n",
      "epoch:0 batch:208 loss:0.567847 accu:0.656250 gene_loss:2.694516\n",
      "epoch:0 batch:209 loss:0.359883 accu:0.851562 gene_loss:2.298166\n",
      "epoch:0 batch:210 loss:0.379756 accu:0.843750 gene_loss:2.993236\n",
      "epoch:0 batch:211 loss:0.334032 accu:0.906250 gene_loss:2.527823\n",
      "epoch:0 batch:212 loss:0.295950 accu:0.875000 gene_loss:3.741498\n",
      "epoch:0 batch:213 loss:0.262697 accu:0.898438 gene_loss:2.313567\n",
      "epoch:0 batch:214 loss:0.484516 accu:0.765625 gene_loss:4.672173\n",
      "epoch:0 batch:215 loss:0.475680 accu:0.796875 gene_loss:2.792203\n",
      "epoch:0 batch:216 loss:1.323273 accu:0.445312 gene_loss:4.047909\n",
      "epoch:0 batch:217 loss:0.864130 accu:0.617188 gene_loss:2.139229\n",
      "epoch:0 batch:218 loss:0.696933 accu:0.609375 gene_loss:1.341544\n",
      "epoch:0 batch:219 loss:0.473706 accu:0.843750 gene_loss:1.547922\n",
      "epoch:0 batch:220 loss:0.391369 accu:0.898438 gene_loss:1.916583\n",
      "epoch:0 batch:221 loss:0.346273 accu:0.882812 gene_loss:1.966684\n",
      "epoch:0 batch:222 loss:0.363249 accu:0.867188 gene_loss:1.956918\n",
      "epoch:0 batch:223 loss:0.235907 accu:0.968750 gene_loss:2.144658\n",
      "epoch:0 batch:224 loss:0.339386 accu:0.859375 gene_loss:2.706528\n",
      "epoch:0 batch:225 loss:0.315100 accu:0.867188 gene_loss:2.417723\n",
      "epoch:0 batch:226 loss:0.376522 accu:0.859375 gene_loss:2.474001\n",
      "epoch:0 batch:227 loss:0.364460 accu:0.867188 gene_loss:3.240352\n",
      "epoch:0 batch:228 loss:0.292535 accu:0.898438 gene_loss:1.472660\n",
      "epoch:0 batch:229 loss:0.310963 accu:0.859375 gene_loss:4.367586\n",
      "epoch:0 batch:230 loss:0.399884 accu:0.828125 gene_loss:1.444884\n",
      "epoch:0 batch:231 loss:0.772360 accu:0.648438 gene_loss:4.974278\n",
      "epoch:0 batch:232 loss:0.680607 accu:0.656250 gene_loss:2.063624\n",
      "epoch:0 batch:233 loss:0.573005 accu:0.679688 gene_loss:2.921663\n",
      "epoch:0 batch:234 loss:0.566338 accu:0.703125 gene_loss:2.898075\n",
      "epoch:0 batch:235 loss:0.335863 accu:0.906250 gene_loss:3.207685\n",
      "epoch:0 batch:236 loss:0.257812 accu:0.937500 gene_loss:2.966166\n",
      "epoch:0 batch:237 loss:0.433796 accu:0.812500 gene_loss:5.114051\n",
      "epoch:0 batch:238 loss:0.501678 accu:0.734375 gene_loss:2.747628\n",
      "epoch:0 batch:239 loss:0.292758 accu:0.914062 gene_loss:3.732128\n",
      "epoch:0 batch:240 loss:0.327624 accu:0.843750 gene_loss:2.739613\n",
      "epoch:0 batch:241 loss:0.239255 accu:0.921875 gene_loss:1.862346\n",
      "epoch:0 batch:242 loss:0.141601 accu:0.984375 gene_loss:0.648756\n",
      "epoch:0 batch:243 loss:0.232096 accu:0.945312 gene_loss:1.762550\n",
      "epoch:0 batch:244 loss:0.166424 accu:0.960938 gene_loss:0.379278\n",
      "epoch:0 batch:245 loss:0.361345 accu:0.812500 gene_loss:6.659271\n",
      "epoch:0 batch:246 loss:1.466592 accu:0.421875 gene_loss:2.264320\n",
      "epoch:0 batch:247 loss:0.193351 accu:0.968750 gene_loss:2.803931\n",
      "epoch:0 batch:248 loss:0.266881 accu:0.929688 gene_loss:3.690887\n",
      "epoch:0 batch:249 loss:0.196879 accu:0.921875 gene_loss:3.161084\n",
      "epoch:0 batch:250 loss:0.218612 accu:0.945312 gene_loss:3.723201\n",
      "epoch:0 batch:251 loss:0.139735 accu:0.968750 gene_loss:2.392024\n",
      "epoch:0 batch:252 loss:0.155100 accu:0.968750 gene_loss:3.587165\n",
      "epoch:0 batch:253 loss:0.111771 accu:0.968750 gene_loss:2.324117\n",
      "epoch:0 batch:254 loss:0.205439 accu:0.945312 gene_loss:1.157526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 batch:255 loss:0.048937 accu:0.984375 gene_loss:0.497876\n",
      "epoch:0 batch:256 loss:0.054456 accu:1.000000 gene_loss:0.026002\n",
      "epoch:0 batch:257 loss:0.031698 accu:1.000000 gene_loss:0.012093\n",
      "epoch:0 batch:258 loss:0.035077 accu:1.000000 gene_loss:0.028514\n",
      "epoch:0 batch:259 loss:0.097321 accu:0.976562 gene_loss:1.651345\n",
      "epoch:0 batch:260 loss:0.127065 accu:0.945312 gene_loss:0.203785\n",
      "epoch:0 batch:261 loss:0.322949 accu:0.906250 gene_loss:6.841724\n",
      "epoch:0 batch:262 loss:1.593414 accu:0.453125 gene_loss:3.675822\n",
      "epoch:0 batch:263 loss:0.199595 accu:0.929688 gene_loss:2.614352\n",
      "epoch:0 batch:264 loss:0.392566 accu:0.835938 gene_loss:1.682814\n",
      "epoch:0 batch:265 loss:0.319199 accu:0.882812 gene_loss:2.032523\n",
      "epoch:0 batch:266 loss:0.335020 accu:0.875000 gene_loss:1.940268\n",
      "epoch:0 batch:267 loss:0.550613 accu:0.734375 gene_loss:2.644644\n",
      "epoch:0 batch:268 loss:0.343235 accu:0.828125 gene_loss:0.860222\n",
      "epoch:0 batch:269 loss:0.158120 accu:0.945312 gene_loss:0.965958\n",
      "epoch:0 batch:270 loss:0.159493 accu:0.953125 gene_loss:0.665102\n",
      "epoch:0 batch:271 loss:0.168005 accu:0.945312 gene_loss:0.586140\n",
      "epoch:0 batch:272 loss:0.078107 accu:0.992188 gene_loss:0.795179\n",
      "epoch:0 batch:273 loss:0.206249 accu:0.945312 gene_loss:2.405503\n",
      "epoch:0 batch:274 loss:0.158181 accu:0.937500 gene_loss:0.906155\n",
      "epoch:0 batch:275 loss:0.142203 accu:0.976562 gene_loss:3.468925\n",
      "epoch:0 batch:276 loss:1.596599 accu:0.359375 gene_loss:7.364952\n",
      "epoch:0 batch:277 loss:1.601043 accu:0.515625 gene_loss:1.567332\n",
      "epoch:0 batch:278 loss:0.247287 accu:0.945312 gene_loss:1.218715\n",
      "epoch:0 batch:279 loss:0.145521 accu:1.000000 gene_loss:1.226971\n",
      "epoch:0 batch:280 loss:0.146776 accu:0.992188 gene_loss:1.193475\n",
      "epoch:0 batch:281 loss:0.104000 accu:1.000000 gene_loss:0.959363\n",
      "epoch:0 batch:282 loss:0.098012 accu:0.992188 gene_loss:0.388207\n",
      "epoch:0 batch:283 loss:0.118235 accu:0.984375 gene_loss:0.329455\n",
      "epoch:0 batch:284 loss:0.169869 accu:0.968750 gene_loss:0.147145\n",
      "epoch:0 batch:285 loss:0.048580 accu:1.000000 gene_loss:0.161022\n",
      "epoch:0 batch:286 loss:0.072222 accu:1.000000 gene_loss:0.096842\n",
      "epoch:0 batch:287 loss:0.042696 accu:0.992188 gene_loss:0.044484\n",
      "epoch:0 batch:288 loss:0.090601 accu:0.992188 gene_loss:0.730286\n",
      "epoch:0 batch:289 loss:0.066738 accu:0.976562 gene_loss:0.178906\n",
      "epoch:0 batch:290 loss:0.142383 accu:0.953125 gene_loss:1.257365\n",
      "epoch:0 batch:291 loss:0.081486 accu:0.968750 gene_loss:0.007262\n",
      "epoch:0 batch:292 loss:0.962844 accu:0.531250 gene_loss:9.277372\n",
      "epoch:0 batch:293 loss:2.012849 accu:0.476562 gene_loss:1.952103\n",
      "epoch:0 batch:294 loss:0.793598 accu:0.554688 gene_loss:1.946056\n",
      "epoch:0 batch:295 loss:0.603118 accu:0.656250 gene_loss:2.299756\n",
      "epoch:0 batch:296 loss:0.553075 accu:0.734375 gene_loss:2.093703\n",
      "epoch:0 batch:297 loss:0.348847 accu:0.906250 gene_loss:2.435800\n",
      "epoch:0 batch:298 loss:0.300242 accu:0.906250 gene_loss:2.495980\n",
      "epoch:0 batch:299 loss:0.331935 accu:0.914062 gene_loss:2.866130\n",
      "epoch:0 batch:300 loss:0.587566 accu:0.664062 gene_loss:3.077184\n",
      "epoch:0 batch:301 loss:0.493504 accu:0.742188 gene_loss:2.450881\n",
      "epoch:0 batch:302 loss:0.579855 accu:0.734375 gene_loss:1.089325\n",
      "epoch:0 batch:303 loss:0.195929 accu:0.960938 gene_loss:0.970702\n",
      "epoch:0 batch:304 loss:0.272978 accu:0.929688 gene_loss:2.012658\n",
      "epoch:0 batch:305 loss:0.266777 accu:0.906250 gene_loss:1.108464\n",
      "epoch:0 batch:306 loss:0.752729 accu:0.570312 gene_loss:5.150218\n",
      "epoch:0 batch:307 loss:1.406921 accu:0.500000 gene_loss:0.697474\n",
      "epoch:0 batch:308 loss:0.511944 accu:0.890625 gene_loss:0.439863\n",
      "epoch:0 batch:309 loss:0.261274 accu:0.945312 gene_loss:0.526824\n",
      "epoch:0 batch:310 loss:0.213379 accu:0.945312 gene_loss:0.289121\n",
      "epoch:0 batch:311 loss:0.107775 accu:1.000000 gene_loss:0.209030\n",
      "epoch:0 batch:312 loss:0.085403 accu:0.992188 gene_loss:0.160940\n",
      "epoch:0 batch:313 loss:0.114991 accu:0.984375 gene_loss:0.167091\n",
      "epoch:0 batch:314 loss:0.061597 accu:0.992188 gene_loss:0.163095\n",
      "epoch:0 batch:315 loss:0.072066 accu:0.992188 gene_loss:0.135313\n",
      "epoch:0 batch:316 loss:0.118855 accu:0.976562 gene_loss:0.231760\n",
      "epoch:0 batch:317 loss:0.102407 accu:0.992188 gene_loss:0.324947\n",
      "epoch:0 batch:318 loss:0.113504 accu:0.976562 gene_loss:0.791717\n",
      "epoch:0 batch:319 loss:0.085904 accu:0.984375 gene_loss:0.654864\n",
      "epoch:0 batch:320 loss:0.049500 accu:1.000000 gene_loss:0.141014\n",
      "epoch:0 batch:321 loss:0.296172 accu:0.867188 gene_loss:4.139277\n",
      "epoch:0 batch:322 loss:1.024825 accu:0.554688 gene_loss:1.046324\n",
      "epoch:0 batch:323 loss:0.139859 accu:0.960938 gene_loss:2.018930\n",
      "epoch:0 batch:324 loss:0.158917 accu:0.953125 gene_loss:1.374743\n",
      "epoch:0 batch:325 loss:0.111221 accu:0.992188 gene_loss:1.056125\n",
      "epoch:0 batch:326 loss:0.167208 accu:0.976562 gene_loss:2.310848\n",
      "epoch:0 batch:327 loss:0.168681 accu:0.937500 gene_loss:0.708688\n",
      "epoch:0 batch:328 loss:0.098387 accu:0.968750 gene_loss:0.271121\n",
      "epoch:0 batch:329 loss:0.039053 accu:1.000000 gene_loss:0.313003\n",
      "epoch:0 batch:330 loss:0.081800 accu:0.976562 gene_loss:0.022250\n",
      "epoch:0 batch:331 loss:0.102041 accu:0.984375 gene_loss:2.471564\n",
      "epoch:0 batch:332 loss:0.765456 accu:0.632812 gene_loss:6.695343\n",
      "epoch:0 batch:333 loss:2.772366 accu:0.414062 gene_loss:1.334007\n",
      "epoch:0 batch:334 loss:0.628253 accu:0.609375 gene_loss:1.222104\n",
      "epoch:0 batch:335 loss:0.473675 accu:0.804688 gene_loss:1.266371\n",
      "epoch:0 batch:336 loss:0.450591 accu:0.828125 gene_loss:1.764969\n",
      "epoch:0 batch:337 loss:0.281492 accu:0.945312 gene_loss:1.814147\n",
      "epoch:0 batch:338 loss:0.206047 accu:0.992188 gene_loss:2.360577\n",
      "epoch:0 batch:339 loss:0.180495 accu:0.984375 gene_loss:2.103638\n",
      "epoch:0 batch:340 loss:0.136042 accu:0.992188 gene_loss:2.385568\n",
      "epoch:0 batch:341 loss:0.121989 accu:0.984375 gene_loss:2.756401\n",
      "epoch:0 batch:342 loss:0.146709 accu:0.976562 gene_loss:1.868486\n",
      "epoch:0 batch:343 loss:0.268431 accu:0.906250 gene_loss:4.218442\n",
      "epoch:0 batch:344 loss:0.850679 accu:0.523438 gene_loss:2.068437\n",
      "epoch:0 batch:345 loss:0.087483 accu:1.000000 gene_loss:1.932295\n",
      "epoch:0 batch:346 loss:0.177711 accu:0.968750 gene_loss:1.032499\n",
      "epoch:0 batch:347 loss:0.273358 accu:0.921875 gene_loss:0.764844\n",
      "epoch:0 batch:348 loss:0.045955 accu:0.984375 gene_loss:0.292812\n",
      "epoch:0 batch:349 loss:0.139986 accu:0.953125 gene_loss:0.007496\n",
      "epoch:0 batch:350 loss:0.065830 accu:0.992188 gene_loss:0.015925\n",
      "epoch:0 batch:351 loss:0.026308 accu:1.000000 gene_loss:0.009593\n",
      "epoch:0 batch:352 loss:0.025152 accu:1.000000 gene_loss:0.015719\n",
      "epoch:0 batch:353 loss:0.040048 accu:1.000000 gene_loss:0.021025\n",
      "epoch:0 batch:354 loss:0.073033 accu:0.984375 gene_loss:0.016393\n",
      "epoch:0 batch:355 loss:0.053238 accu:0.992188 gene_loss:0.114220\n",
      "epoch:0 batch:356 loss:0.062075 accu:0.992188 gene_loss:0.496669\n",
      "epoch:0 batch:357 loss:0.027514 accu:0.992188 gene_loss:0.074565\n",
      "epoch:0 batch:358 loss:0.406973 accu:0.828125 gene_loss:6.771781\n",
      "epoch:0 batch:359 loss:1.669311 accu:0.539062 gene_loss:0.476536\n",
      "epoch:0 batch:360 loss:1.375041 accu:0.492188 gene_loss:4.030539\n",
      "epoch:0 batch:361 loss:0.604609 accu:0.695312 gene_loss:2.982796\n",
      "epoch:0 batch:362 loss:0.497775 accu:0.742188 gene_loss:1.352664\n",
      "epoch:0 batch:363 loss:0.383229 accu:0.835938 gene_loss:1.800447\n",
      "epoch:0 batch:364 loss:0.292718 accu:0.914062 gene_loss:1.670878\n",
      "epoch:0 batch:365 loss:0.206546 accu:0.992188 gene_loss:1.707506\n",
      "epoch:0 batch:366 loss:0.439626 accu:0.796875 gene_loss:3.873828\n",
      "epoch:0 batch:367 loss:0.471183 accu:0.750000 gene_loss:2.953639\n",
      "epoch:0 batch:368 loss:0.245054 accu:0.937500 gene_loss:3.332811\n",
      "epoch:0 batch:369 loss:0.079264 accu:1.000000 gene_loss:3.482793\n",
      "epoch:0 batch:370 loss:0.126328 accu:0.976562 gene_loss:3.502133\n",
      "epoch:0 batch:371 loss:0.096047 accu:0.992188 gene_loss:3.532602\n",
      "epoch:0 batch:372 loss:0.274007 accu:0.906250 gene_loss:6.207747\n",
      "epoch:0 batch:373 loss:0.615947 accu:0.671875 gene_loss:1.541511\n",
      "epoch:0 batch:374 loss:0.565305 accu:0.742188 gene_loss:6.016844\n",
      "epoch:0 batch:375 loss:0.635293 accu:0.687500 gene_loss:2.869888\n",
      "epoch:0 batch:376 loss:0.176731 accu:0.984375 gene_loss:1.027186\n",
      "epoch:0 batch:377 loss:0.294696 accu:0.906250 gene_loss:2.628422\n",
      "epoch:0 batch:378 loss:0.318566 accu:0.804688 gene_loss:1.044976\n",
      "epoch:0 batch:379 loss:0.187544 accu:0.960938 gene_loss:0.826831\n",
      "epoch:0 batch:380 loss:0.161827 accu:0.960938 gene_loss:0.170787\n",
      "epoch:0 batch:381 loss:0.121682 accu:0.992188 gene_loss:0.129632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 batch:382 loss:0.172445 accu:0.945312 gene_loss:2.111742\n",
      "epoch:0 batch:383 loss:0.259708 accu:0.851562 gene_loss:0.592207\n",
      "epoch:0 batch:384 loss:0.377197 accu:0.796875 gene_loss:4.721841\n",
      "epoch:0 batch:385 loss:0.737468 accu:0.617188 gene_loss:0.351244\n",
      "epoch:0 batch:386 loss:0.390227 accu:0.851562 gene_loss:1.421335\n",
      "epoch:0 batch:387 loss:0.126522 accu:0.953125 gene_loss:1.291909\n",
      "epoch:0 batch:388 loss:0.792786 accu:0.585938 gene_loss:3.720171\n",
      "epoch:0 batch:389 loss:0.693512 accu:0.687500 gene_loss:2.534351\n",
      "epoch:0 batch:390 loss:0.624794 accu:0.695312 gene_loss:1.710853\n",
      "epoch:0 batch:391 loss:0.236309 accu:0.953125 gene_loss:2.003317\n",
      "epoch:0 batch:392 loss:0.220816 accu:0.953125 gene_loss:2.247858\n",
      "epoch:0 batch:393 loss:0.186455 accu:0.953125 gene_loss:3.116645\n",
      "epoch:0 batch:394 loss:0.294249 accu:0.875000 gene_loss:2.635972\n",
      "epoch:0 batch:395 loss:0.161502 accu:0.968750 gene_loss:2.382519\n",
      "epoch:0 batch:396 loss:0.222917 accu:0.953125 gene_loss:1.594467\n",
      "epoch:0 batch:397 loss:0.186965 accu:0.960938 gene_loss:1.719538\n",
      "epoch:0 batch:398 loss:0.346165 accu:0.890625 gene_loss:0.815155\n",
      "epoch:0 batch:399 loss:0.074320 accu:0.992188 gene_loss:0.897198\n",
      "epoch:0 batch:400 loss:0.155205 accu:0.976562 gene_loss:0.772881\n",
      "epoch:0 batch:401 loss:0.388590 accu:0.835938 gene_loss:5.039002\n",
      "epoch:0 batch:402 loss:2.036979 accu:0.328125 gene_loss:2.156858\n",
      "epoch:0 batch:403 loss:0.273361 accu:0.906250 gene_loss:0.969779\n",
      "epoch:0 batch:404 loss:0.249247 accu:0.906250 gene_loss:2.153252\n",
      "epoch:0 batch:405 loss:0.238917 accu:0.890625 gene_loss:1.141597\n",
      "epoch:0 batch:406 loss:0.255701 accu:0.914062 gene_loss:0.897892\n",
      "epoch:0 batch:407 loss:0.087701 accu:1.000000 gene_loss:0.535827\n",
      "epoch:0 batch:408 loss:0.185168 accu:0.960938 gene_loss:0.757167\n",
      "epoch:0 batch:409 loss:0.072154 accu:1.000000 gene_loss:0.433783\n",
      "epoch:0 batch:410 loss:0.137034 accu:0.984375 gene_loss:0.969683\n",
      "epoch:0 batch:411 loss:0.101930 accu:0.976562 gene_loss:0.408207\n",
      "epoch:0 batch:412 loss:0.108052 accu:0.992188 gene_loss:0.823486\n",
      "epoch:0 batch:413 loss:0.286157 accu:0.851562 gene_loss:2.839711\n",
      "epoch:0 batch:414 loss:0.507024 accu:0.742188 gene_loss:0.811807\n",
      "epoch:0 batch:415 loss:0.025724 accu:1.000000 gene_loss:0.865597\n",
      "epoch:0 batch:416 loss:1.099015 accu:0.601562 gene_loss:10.491129\n",
      "epoch:0 batch:417 loss:2.664093 accu:0.500000 gene_loss:3.891686\n",
      "epoch:0 batch:418 loss:0.732608 accu:0.562500 gene_loss:1.360613\n",
      "epoch:0 batch:419 loss:0.486091 accu:0.757812 gene_loss:0.999700\n",
      "epoch:0 batch:420 loss:0.375089 accu:0.875000 gene_loss:1.044307\n",
      "epoch:0 batch:421 loss:0.390631 accu:0.851562 gene_loss:1.173340\n",
      "epoch:0 batch:422 loss:0.327976 accu:0.914062 gene_loss:1.131354\n",
      "epoch:0 batch:423 loss:0.337651 accu:0.890625 gene_loss:0.934476\n",
      "epoch:0 batch:424 loss:0.579804 accu:0.703125 gene_loss:2.051150\n",
      "epoch:0 batch:425 loss:0.530360 accu:0.742188 gene_loss:1.734771\n",
      "epoch:0 batch:426 loss:0.374835 accu:0.867188 gene_loss:1.543633\n",
      "epoch:0 batch:427 loss:0.312674 accu:0.921875 gene_loss:2.101497\n",
      "epoch:0 batch:428 loss:0.278837 accu:0.898438 gene_loss:2.170286\n",
      "epoch:0 batch:429 loss:0.379590 accu:0.828125 gene_loss:3.100857\n",
      "epoch:0 batch:430 loss:0.240802 accu:0.906250 gene_loss:2.419073\n",
      "epoch:0 batch:431 loss:0.203215 accu:0.937500 gene_loss:2.443547\n",
      "epoch:0 batch:432 loss:0.241185 accu:0.937500 gene_loss:2.127143\n",
      "epoch:0 batch:433 loss:0.248277 accu:0.929688 gene_loss:2.958180\n",
      "epoch:0 batch:434 loss:0.393040 accu:0.828125 gene_loss:1.678066\n",
      "epoch:0 batch:435 loss:0.559490 accu:0.718750 gene_loss:5.828534\n",
      "epoch:0 batch:436 loss:1.133191 accu:0.539062 gene_loss:2.819463\n",
      "epoch:0 batch:437 loss:0.567810 accu:0.671875 gene_loss:1.975246\n",
      "epoch:0 batch:438 loss:0.302412 accu:0.914062 gene_loss:2.298571\n",
      "epoch:0 batch:439 loss:0.274805 accu:0.914062 gene_loss:2.023915\n",
      "epoch:0 batch:440 loss:0.151509 accu:0.976562 gene_loss:1.609769\n",
      "epoch:0 batch:441 loss:0.277310 accu:0.898438 gene_loss:2.719083\n",
      "epoch:0 batch:442 loss:0.171821 accu:0.953125 gene_loss:2.427283\n",
      "epoch:0 batch:443 loss:0.222085 accu:0.929688 gene_loss:2.145037\n",
      "epoch:0 batch:444 loss:0.303632 accu:0.898438 gene_loss:2.483448\n",
      "epoch:0 batch:445 loss:0.463751 accu:0.773438 gene_loss:4.070028\n",
      "epoch:0 batch:446 loss:0.453322 accu:0.781250 gene_loss:2.033507\n",
      "epoch:0 batch:447 loss:0.316675 accu:0.843750 gene_loss:2.524511\n",
      "epoch:0 batch:448 loss:0.251885 accu:0.890625 gene_loss:1.744830\n",
      "epoch:0 batch:449 loss:0.527028 accu:0.750000 gene_loss:4.319326\n",
      "epoch:0 batch:450 loss:0.712236 accu:0.609375 gene_loss:2.301896\n",
      "epoch:0 batch:451 loss:0.159106 accu:0.960938 gene_loss:1.209711\n",
      "epoch:0 batch:452 loss:0.374973 accu:0.812500 gene_loss:3.463839\n",
      "epoch:0 batch:453 loss:0.532258 accu:0.695312 gene_loss:2.070596\n",
      "epoch:0 batch:454 loss:0.814612 accu:0.562500 gene_loss:3.604785\n",
      "epoch:0 batch:455 loss:0.486491 accu:0.710938 gene_loss:2.415807\n",
      "epoch:0 batch:456 loss:0.953374 accu:0.570312 gene_loss:2.754283\n",
      "epoch:0 batch:457 loss:0.432896 accu:0.828125 gene_loss:1.957165\n",
      "epoch:0 batch:458 loss:0.478044 accu:0.773438 gene_loss:1.484790\n",
      "epoch:0 batch:459 loss:0.436603 accu:0.828125 gene_loss:1.564065\n",
      "epoch:0 batch:460 loss:0.222178 accu:0.921875 gene_loss:1.135873\n",
      "epoch:0 batch:461 loss:0.183381 accu:0.984375 gene_loss:0.623768\n",
      "epoch:0 batch:462 loss:0.152430 accu:0.976562 gene_loss:0.451627\n",
      "epoch:0 batch:463 loss:0.073671 accu:0.992188 gene_loss:0.247862\n",
      "epoch:0 batch:464 loss:0.367296 accu:0.851562 gene_loss:1.364415\n",
      "epoch:0 batch:465 loss:0.844937 accu:0.523438 gene_loss:3.301015\n",
      "epoch:0 batch:466 loss:0.747399 accu:0.632812 gene_loss:0.718842\n",
      "epoch:0 batch:467 loss:0.477224 accu:0.757812 gene_loss:1.932858\n",
      "epoch:0 batch:468 loss:0.502811 accu:0.750000 gene_loss:0.838311\n",
      "epoch:0 batch:469 loss:0.561988 accu:0.687500 gene_loss:2.406685\n",
      "epoch:0 batch:470 loss:0.569151 accu:0.671875 gene_loss:1.061140\n",
      "epoch:0 batch:471 loss:0.824405 accu:0.492188 gene_loss:3.075780\n",
      "epoch:0 batch:472 loss:0.685250 accu:0.593750 gene_loss:1.913752\n",
      "epoch:0 batch:473 loss:0.351952 accu:0.898438 gene_loss:1.652964\n",
      "epoch:0 batch:474 loss:0.224314 accu:0.960938 gene_loss:1.629897\n",
      "epoch:0 batch:475 loss:0.165521 accu:0.976562 gene_loss:1.097359\n",
      "epoch:0 batch:476 loss:0.234431 accu:0.953125 gene_loss:2.203958\n",
      "epoch:0 batch:477 loss:0.160950 accu:0.945312 gene_loss:1.661253\n",
      "epoch:0 batch:478 loss:0.156095 accu:0.992188 gene_loss:1.155297\n",
      "epoch:0 batch:479 loss:0.541169 accu:0.703125 gene_loss:5.362641\n",
      "epoch:0 batch:480 loss:1.193713 accu:0.585938 gene_loss:2.417499\n",
      "epoch:0 batch:481 loss:0.674299 accu:0.625000 gene_loss:3.200258\n",
      "epoch:0 batch:482 loss:0.450113 accu:0.726562 gene_loss:2.604908\n",
      "epoch:0 batch:483 loss:0.412339 accu:0.828125 gene_loss:1.948453\n",
      "epoch:0 batch:484 loss:0.245156 accu:0.945312 gene_loss:1.541619\n",
      "epoch:0 batch:485 loss:0.226806 accu:0.914062 gene_loss:0.816975\n",
      "epoch:0 batch:486 loss:0.157311 accu:1.000000 gene_loss:1.124266\n",
      "epoch:0 batch:487 loss:0.093432 accu:1.000000 gene_loss:1.095253\n",
      "epoch:0 batch:488 loss:0.138969 accu:0.976562 gene_loss:0.922424\n",
      "epoch:0 batch:489 loss:0.240195 accu:0.921875 gene_loss:2.089805\n",
      "epoch:0 batch:490 loss:0.193292 accu:0.953125 gene_loss:1.536793\n",
      "epoch:0 batch:491 loss:0.235738 accu:0.914062 gene_loss:3.357322\n",
      "epoch:0 batch:492 loss:0.922066 accu:0.445312 gene_loss:4.582853\n",
      "epoch:0 batch:493 loss:1.008343 accu:0.562500 gene_loss:1.472977\n",
      "epoch:0 batch:494 loss:0.369312 accu:0.796875 gene_loss:1.986636\n",
      "epoch:0 batch:495 loss:0.119378 accu:0.984375 gene_loss:2.802011\n",
      "epoch:0 batch:496 loss:0.212623 accu:0.953125 gene_loss:2.010391\n",
      "epoch:0 batch:497 loss:0.382727 accu:0.843750 gene_loss:4.004564\n",
      "epoch:0 batch:498 loss:0.348836 accu:0.828125 gene_loss:2.474792\n",
      "epoch:0 batch:499 loss:0.240151 accu:0.921875 gene_loss:3.267175\n",
      "epoch:0 batch:500 loss:0.218099 accu:0.937500 gene_loss:2.285024\n",
      "epoch:0 batch:501 loss:0.256856 accu:0.906250 gene_loss:2.811429\n",
      "epoch:0 batch:502 loss:0.167061 accu:0.929688 gene_loss:0.906205\n",
      "epoch:0 batch:503 loss:0.429005 accu:0.765625 gene_loss:4.580252\n",
      "epoch:0 batch:504 loss:0.931727 accu:0.570312 gene_loss:0.880702\n",
      "epoch:0 batch:505 loss:0.105881 accu:0.976562 gene_loss:0.257492\n",
      "epoch:0 batch:506 loss:0.366295 accu:0.796875 gene_loss:1.984815\n",
      "epoch:0 batch:507 loss:0.283761 accu:0.875000 gene_loss:1.455582\n",
      "epoch:0 batch:508 loss:0.802881 accu:0.578125 gene_loss:2.801630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 batch:509 loss:0.729638 accu:0.578125 gene_loss:1.845765\n",
      "epoch:0 batch:510 loss:0.729393 accu:0.578125 gene_loss:2.595599\n"
     ]
    }
   ],
   "source": [
    "real_labels = np.ones(shape=(BATCH_SIZE , 1)) #真实样本label为1\n",
    "fake_labels = np.zeros(shape=(BATCH_SIZE , 1)) #假样本label为0\n",
    "\n",
    "for i in range(1000):\n",
    "    for j in range(int(IMAGES_COUNT/BATCH_SIZE)):\n",
    "        noise = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "\n",
    "        real_image = load_image()\n",
    "        #real_image = load_mnist()\n",
    "        #训练判别器\n",
    "        fake_image = generator_i.predict(noise)\n",
    "\n",
    "        real_loss = discriminator_i.train_on_batch(real_image , real_labels)\n",
    "        fake_loss = discriminator_i.train_on_batch(fake_image , fake_labels)\n",
    "\n",
    "        loss = np.add(real_loss , fake_loss)/2\n",
    "\n",
    "        #训练生成器\n",
    "        noise2 = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "        generator_loss = combined_model_i.train_on_batch(noise2 , real_labels)\n",
    "\n",
    "        print('epoch:%d batch:%d loss:%f accu:%f gene_loss:%f' % (i , j , loss[0] , loss[1] , generator_loss))\n",
    "\n",
    "    write_image(i)\n",
    "    #write_image_mnist(i)\n",
    "    \n",
    "write_image(999)\n",
    "#write_image_mnist(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator (Sequential)   (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 0\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator (Sequential)       (None, 28, 28, 1)         1097744   \n",
      "=================================================================\n",
      "Total params: 1,097,744\n",
      "Trainable params: 1,095,184\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z (InputLayer)               (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator_Model (Model)      (None, 96, 96, 3)         29029120  \n",
      "_________________________________________________________________\n",
      "discriminator_Model (Model)  (None, 1)                 14320641  \n",
      "=================================================================\n",
      "Total params: 43,349,761\n",
      "Trainable params: 29,025,536\n",
      "Non-trainable params: 14,324,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeli = Sequential(name='generator')\n",
    "\n",
    "#cartioon 图像使用 96*96*3\n",
    "modeli.add(Dense(6*6*8*64 , input_shape=(LATENT_DIM,) , kernel_initializer=random_normal(stddev=0.02) , bias_initializer=constant(0.0)))\n",
    "\n",
    "modeli.add(Reshape((6, 6, 64*8)))\n",
    "modeli.add(batch_norm())\n",
    "modeli.add(LeakyReLU(0.2))\n",
    "\n",
    "modeli.add(deconv2d(64*4))\n",
    "modeli.add(batch_norm())\n",
    "modeli.add(LeakyReLU(0.2))\n",
    "\n",
    "modeli.add(deconv2d(64*2))\n",
    "modeli.add(batch_norm())\n",
    "modeli.add(LeakyReLU(0.2))\n",
    "\n",
    "modeli.add(deconv2d(64*1))\n",
    "modeli.add(batch_norm())\n",
    "modeli.add(LeakyReLU(0.2))\n",
    "\n",
    "modeli.add(deconv2d(3))\n",
    "modeli.add(Activation('tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7872"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800.359375"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGES_COUNT/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51200"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "800*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51223"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGES_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "22:9:30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
