{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense ,  BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D , Conv2DTranspose , UpSampling2D , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU , PReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "#addin cycleGAN 使用instance-norm\n",
    "from keras_contrib.layers.normalization import InstanceNormalization\n",
    "\n",
    "from keras.initializers import truncated_normal , constant , random_normal\n",
    "\n",
    "from keras.optimizers import Adam , RMSprop\n",
    "\n",
    "#残差块使用\n",
    "from keras.layers import Add\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#导入存在的模型\n",
    "from keras.applications import VGG16 , VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "CHANNEL = 3\n",
    "\n",
    "SHAPE = (WIDTH , HEIGHT , CHANNEL)\n",
    "\n",
    "BATCH_SIZE = 4 #crazy!!! slow turtle\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = '../dataset/vangogh2photo/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 2 #几行决定显示几个测试样例 显示2个\n",
    "COL = 3 #3列是因为要显示 原图像 另一个特征空间的图像 还原后的图像\n",
    "\n",
    "TRAIN_APPLE_PATH = glob(PATH + 'trainA/*')\n",
    "TRAIN_ORANGE_PATH = glob(PATH + 'trainB/*')\n",
    "TEST_APPLE_PATH = glob(PATH + 'testA/*')\n",
    "TEST_ORANGE_PATH = glob(PATH + 'testB/*')\n",
    "\n",
    "#卷积使用 基卷积核大小\n",
    "G_filters = 64\n",
    "D_filters = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch = int(HEIGHT/(2**4)) #16\n",
    "disc_patch = (patch , patch , 1) #16*16*1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(batch_size = BATCH_SIZE , training = True):\n",
    "    #随机在图片库中挑选\n",
    "    if training:\n",
    "        APPLE_PATH = TRAIN_APPLE_PATH\n",
    "        ORANGE_PATH = TRAIN_ORANGE_PATH\n",
    "    else:\n",
    "        APPLE_PATH = TEST_APPLE_PATH\n",
    "        ORANGE_PATH = TEST_ORANGE_PATH\n",
    "        \n",
    "    images_apple = np.random.choice(APPLE_PATH , size=batch_size)\n",
    "    images_orange = np.random.choice(ORANGE_PATH , size=batch_size)\n",
    "    \n",
    "    apples = []\n",
    "    oranges = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        apple = scipy.misc.imread(images_apple[i] , mode='RGB').astype(np.float)\n",
    "        orange = scipy.misc.imread(images_orange[i] , mode='RGB').astype(np.float)\n",
    "        \n",
    "        #随机性地对训练样本进行 左右反转\n",
    "        if training and np.random.random()<0.5:\n",
    "            apple = np.fliplr(apple)\n",
    "            orange = np.fliplr(orange)\n",
    "        \n",
    "        apples.append(apple)\n",
    "        oranges.append(orange)\n",
    "        \n",
    "    apples = np.array(apples)/127.5 - 1\n",
    "    oranges = np.array(oranges)/127.5 - 1\n",
    "    \n",
    "    return apples , oranges\n",
    "\n",
    "\n",
    "def write_image(epoch):\n",
    "    #生成高分图像时 进行对比显示\n",
    "    apples , oranges = load_image(batch_size=1 , training=False) #1个batch就是两幅图像 一个苹果的 一个橘子的\n",
    "    \n",
    "    fake_apples = generator_apple2orange.predict(apples) #橘子风格的苹果\n",
    "    fake_oranges = generator_orange2apple.predict(oranges) #苹果风格的橘子\n",
    "    \n",
    "    apples_hat = generator_orange2apple.predict(fake_apples) #还原后的苹果\n",
    "    oranges_hat = generator_apple2orange.predict(fake_oranges) #还原后的橘子\n",
    "    \n",
    "    \n",
    "    apples = apples*0.5+0.5\n",
    "    oranges = oranges*0.5+0.5\n",
    "    \n",
    "    fake_apples = fake_apples*0.5+0.5\n",
    "    fake_oranges = fake_oranges*0.5+0.5\n",
    "    \n",
    "    apples_hat = apples_hat*0.5+0.5\n",
    "    oranges_hat = oranges_hat*0.5+0.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    count=0\n",
    "    \n",
    "    axes[0][0].imshow(apples[0])\n",
    "    axes[0][0].set_title('apple')\n",
    "    axes[0][0].axis('off')\n",
    "\n",
    "    axes[0][1].imshow(fake_apples[0])\n",
    "    axes[0][1].set_title('apple-orange')\n",
    "    axes[0][1].axis('off')\n",
    "    \n",
    "    axes[0][2].imshow(apples_hat[0])\n",
    "    axes[0][2].set_title('restruct apple')\n",
    "    axes[0][2].axis('off')\n",
    "\n",
    "    axes[1][0].imshow(oranges[0])\n",
    "    axes[1][0].set_title('orange')\n",
    "    axes[1][0].axis('off')\n",
    "\n",
    "    axes[1][1].imshow(fake_oranges[0])\n",
    "    axes[1][1].set_title('orange-apple')\n",
    "    axes[1][1].axis('off')\n",
    "    \n",
    "    axes[1][2].imshow(oranges_hat[0])\n",
    "    axes[1][2].set_title('restruct orange')\n",
    "    axes[1][2].axis('off')\n",
    "      \n",
    "    fig.savefig('edges2shoes_discogan/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input_data , output_size , filter_size=4 , instance_norm=True):\n",
    "    h = Conv2D(output_size , filter_size , strides=(2,2) , padding='same')(input_data)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    if instance_norm:\n",
    "        h = InstanceNormalization()(h)\n",
    "    \n",
    "    return h\n",
    "\n",
    "\n",
    "#实现U-Net使用 需要网络的跳连接\n",
    "def deconv2d(input_data , skip_input , output_size , filter_size=4 , dropout_rate=0.0):\n",
    "    h = UpSampling2D(size=2)(input_data)\n",
    "    h = Conv2D(output_size , filter_size , strides=(1,1) , padding='same')(h)\n",
    "    h = Activation('relu')(h)\n",
    "    \n",
    "    if dropout_rate:\n",
    "        h = Dropout(rate=dropout_rate)(h)\n",
    "    \n",
    "    h = InstanceNormalization()(h)\n",
    "    h =  Concatenate()([h , skip_input]) #跳连接具体实现\n",
    "\n",
    "    return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G使用encoder-decoder结构 但是需要引入跳连接 即U-Net\n",
    "def generator(G_filters , name):\n",
    "    style = Input(shape=SHAPE) #输入一个风格的图像 生成另一个风格的图像\n",
    "    \n",
    "    #encoder\n",
    "    d1 = conv2d(style , G_filters , instance_norm=False)\n",
    "    d2 = conv2d(d1 , G_filters*2)\n",
    "    d3 = conv2d(d2 , G_filters*4)\n",
    "    d4 = conv2d(d3 , G_filters*8)\n",
    "    d5 = conv2d(d4 , G_filters*8)\n",
    "    d6 = conv2d(d5 , G_filters*8)\n",
    "    d7 = conv2d(d6 , G_filters*8)\n",
    " \n",
    "\n",
    "    #decoder\n",
    "    \n",
    "    u1 = deconv2d(d7 , d6 , G_filters*8)\n",
    "    u2 = deconv2d(u1 , d5 , G_filters*8)\n",
    "    u3 = deconv2d(u2 , d4 , G_filters*8)\n",
    "    u4 = deconv2d(u3 , d3 , G_filters*4)\n",
    "    u5 = deconv2d(u4 , d2 , G_filters*2)\n",
    "    u6 = deconv2d(u5 , d1 , G_filters)\n",
    "    \n",
    "    u7 = UpSampling2D(size=(2,2))(u6)\n",
    "    other_style = Conv2D(filters=CHANNEL , kernel_size=(4,4) , strides=(1,1) , padding='same' , activation='tanh')(u7) #还原后的图像\n",
    "    \n",
    "    return Model(style , other_style , name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(D_filters , name):\n",
    "    style = Input(shape=SHAPE) #风格1 的图像\n",
    "    #style2 = Input(shape=SHAPE) #风格2 的图像\n",
    "    \n",
    "    #style = Concatenate()([style1 , style2])\n",
    "    \n",
    "    h1 = conv2d(style , output_size=D_filters , instance_norm=False)\n",
    "    h2 = conv2d(h1 , output_size=D_filters*2)\n",
    "    h3 = conv2d(h2 , output_size=D_filters*4)\n",
    "    h4 = conv2d(h3 , output_size=D_filters*8)\n",
    "    \n",
    "    validity =  Conv2D(1 , kernel_size=(4,4) , strides=(1,1) , padding='same')(h4)\n",
    "    \n",
    "    return Model(style , validity , name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.0002 , beta_1=0.5)\n",
    "\n",
    "discriminator_apple = discriminator(D_filters , name='discriminator_apple') #判别苹果风格\n",
    "discriminator_apple.compile(optimizer = adam , loss='mse' , metrics=['accuracy'])\n",
    "discriminator_orange = discriminator(D_filters , name='discriminator_orange') #判别橘子风格\n",
    "discriminator_orange.compile(optimizer = adam , loss='mse' , metrics=['accuracy'])\n",
    "\n",
    "generator_apple2orange = generator(G_filters , name='generator_apple2orange')\n",
    "generator_orange2apple = generator(G_filters , name='generator_orange2apple')\n",
    "\n",
    "apples = Input(shape=SHAPE)\n",
    "oranges = Input(shape=SHAPE)\n",
    "\n",
    "fake_apples = generator_apple2orange(apples) #使用G来 将苹果变成橘子风格的苹果\n",
    "fake_oranges = generator_orange2apple(oranges) #使用F来 将橘子变成苹果风格的橘子\n",
    "\n",
    "apples_hat = generator_orange2apple(fake_apples) #使用F将橘子风格的苹果还原为原苹果\n",
    "oranges_hat = generator_apple2orange(fake_oranges) #使用G将苹果风格的橘子还原为原橘子\n",
    "\n",
    "#freeze D\n",
    "discriminator_apple.trainable = False\n",
    "discriminator_orange.trainable = False\n",
    "\n",
    "validity_apple = discriminator_apple(fake_oranges) #真苹果 和 苹果风格的橘子 之间的潜在模式相似度\n",
    "validity_orange = discriminator_orange(fake_apples) #真橘子 和 橘子风格的苹果 之间的潜在模式相似度\n",
    "\n",
    "#一共6个输出 最后4个输出希望和原图像一致 这样图像同时具有两个风格\n",
    "combined = Model([apples , oranges] , [validity_apple , validity_orange , fake_apples , fake_oranges , apples_hat , oranges_hat])\n",
    "combined.compile(optimizer=adam , loss=['mse' , 'mse' , 'mae' , 'mae' , 'mae' , 'mae']) # , loss_weights=[1 ,1,10, 10 , 1, 1]) #cycleGAN的损失权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ccabd4cdcbeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#tuple类型相加 相当于cat连接\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreal_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdisc_patch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfake_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdisc_patch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#tuple类型相加 相当于cat连接\n",
    "real_labels = np.ones(shape=(BATCH_SIZE , )+disc_patch) \n",
    "fake_labels = np.zeros(shape=(BATCH_SIZE , )+disc_patch)\n",
    "\n",
    "\n",
    "for i in range(1001):\n",
    "    apples_ , oranges_ = load_image()\n",
    "    \n",
    "    fake_apples_ = generator_apple2orange.predict(apples_) #使用G将苹果变成 橘子风格的苹果\n",
    "    fake_oranges_ = generator_orange2apple.predict(oranges_) #使用F将橘子变成 苹果风格的橘子\n",
    "    #训练判别器\n",
    "    apple_loss = discriminator_apple.train_on_batch(apples_ , real_labels)\n",
    "    fake_apple_loss = discriminator_apple.train_on_batch(fake_apples_ , fake_labels)\n",
    "    loss_apple = np.add(apple_loss , fake_apple_loss)/2\n",
    "\n",
    "    orange_loss = discriminator_orange.train_on_batch(oranges_ , real_labels)\n",
    "    fake_orange_loss = discriminator_orange.train_on_batch(fake_oranges_ , fake_labels)\n",
    "    loss_orange = np.add(orange_loss , fake_orange_loss)/2\n",
    "\n",
    "    loss = np.add(loss_apple , loss_orange)/2\n",
    "\n",
    "    #训练生成器\n",
    "    generator_loss = combined.train_on_batch([apples_ , oranges_] , [real_labels , real_labels , oranges_ , apples_ , apples_ , oranges_])\n",
    "    \n",
    "    print('epoch:%d loss:%f accu:%f |mse1:%f :mse2:%f mae1:%f mae2:%f mae3:%f mae4:%f' % (i , loss[0] , loss[1] , generator_loss[0] , generator_loss[1] , generator_loss[2] , generator_loss[3] , generator_loss[4] , generator_loss[5]))\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        write_image(i)\n",
    "\n",
    "write_image(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
