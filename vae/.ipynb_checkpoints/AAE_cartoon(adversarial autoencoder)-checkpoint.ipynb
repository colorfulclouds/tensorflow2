{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense ,  BatchNormalization , Reshape , Input , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D , Conv2DTranspose , UpSampling2D , ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.layers import Add , Multiply\n",
    "\n",
    "from keras.initializers import random_normal\n",
    "from keras.initializers import constant\n",
    "from keras.initializers import truncated_normal\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH = 96\n",
    "HEIGHT = 96\n",
    "CHANNEL = 3\n",
    "\n",
    "LATENT_DIM = 100 #latent variable z sample from normal distribution\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "\n",
    "PATH = '../gans/faces/'\n",
    "\n",
    "#生成多少个图像 长*宽\n",
    "ROW = 5\n",
    "COL = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_index = 0\n",
    "\n",
    "images_name = os.listdir(PATH)\n",
    "\n",
    "IMAGES_COUNT = len(images_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_image(batch_size = BATCH_SIZE):\n",
    "    global load_index\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        images.append(plt.image.imread(PATH + images_name[(load_index + i) % IMAGES_COUNT]))\n",
    "    \n",
    "    load_index += batch_size\n",
    "    \n",
    "    return np.array(images)/127.5-1\n",
    "\n",
    "def write_image(epoch):\n",
    "    \n",
    "    noise = np.random.normal(size = (ROW*COL , LATENT_DIM))\n",
    "    generated_image = decoder_i.predict(noise)\n",
    "    generated_image = (generated_image+1)*127.5\n",
    "    \n",
    "    fig , axes = plt.pyplot.subplots(ROW , COL)\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for i in range(ROW):\n",
    "        for j in range(COL):\n",
    "            axes[i][j].imshow(generated_image[count])\n",
    "            axes[i][j].axis('off')\n",
    "            count += 1\n",
    "            \n",
    "    fig.savefig('cartoon_aae/No.%d.png' % epoch)\n",
    "    plt.pyplot.close()\n",
    "    \n",
    "    #plt.image.imsave('images/'+str(epoch)+'.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    #input a image to discriminate real or fake\n",
    "    model = Sequential(name='discriminator')\n",
    "    \n",
    "    model.add(Dense(512 , input_shape=(LATENT_DIM , )))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1 , activation='sigmoid'))\n",
    "    \n",
    "    encoder_feature = Input(shape=(LATENT_DIM , ))\n",
    "    validity = model(encoder_feature)\n",
    "    \n",
    "    return Model(encoder_feature , validity , name='discriminator_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(output_size):\n",
    "    return Conv2D(output_size , kernel_size=(5,5) , strides=(2,2) , padding='same' , kernel_initializer=truncated_normal(stddev=0.02),bias_initializer=constant(0.0))\n",
    "\n",
    "def batch_norm():\n",
    "    return BatchNormalization(momentum=0.9 , epsilon=1e-5)\n",
    "\n",
    "def deconv2d(output_size):\n",
    "    return Conv2DTranspose(output_size , kernel_size=(5,5) , strides=(2,2) , padding='same' , kernel_initializer=truncated_normal(stddev=0.02) , bias_initializer=constant(0.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp(x):\n",
    "    return K.exp(x)\n",
    "\n",
    "def encoder():\n",
    "    image = Input(shape=(HEIGHT , WIDTH , CHANNEL))\n",
    "    \n",
    "    h = Conv2D(64 , input_shape=(HEIGHT , WIDTH , CHANNEL) , kernel_size=(5,5) , strides=(2,2) , padding='same' , kernel_initializer=truncated_normal(stddev=0.02),bias_initializer=constant(0.0))(image)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    h = conv2d(64*2)(h)\n",
    "    h = batch_norm()(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    h = conv2d(64*4)(h)\n",
    "    h = batch_norm()(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    h = conv2d(64*8)(h)\n",
    "    h = batch_norm()(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    h = Flatten()(h)\n",
    "    \n",
    "    mean = Dense(LATENT_DIM)(h)\n",
    "    log_var = Dense(LATENT_DIM)(h)\n",
    "    \n",
    "    a=Activation(exp)(log_var)\n",
    "    b=K.random_normal(shape=K.shape(log_var))\n",
    "    encoder_feature = Add()([mean , Multiply()([a , b])])\n",
    "    #    \n",
    "    return Model(image , a)\n",
    "\n",
    "def decoder():\n",
    "    input_feature = Input(shape=(LATENT_DIM , ))\n",
    "    \n",
    "    h = Dense(6*6*8*64 , input_shape=(LATENT_DIM , ))(input_feature)\n",
    "    h = Reshape(target_shape=(6,6,64*8))(h)\n",
    "    \n",
    "    h = batch_norm()(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    h = deconv2d(64*4)(h)\n",
    "    h = batch_norm()(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    h = deconv2d(64*2)(h)\n",
    "    h = batch_norm()(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    h = deconv2d(64*1)(h)\n",
    "    h = batch_norm()(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    \n",
    "    h = deconv2d(3)(h)\n",
    "    h = Activation('tanh')(h)\n",
    "    \n",
    "    image_hat = h\n",
    "    \n",
    "    return Model(input_feature , image_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr = 0.0001 , beta_1=0.5)\n",
    "#learning rate设置为0.0002容易出现nan情况\n",
    "#增大batchsize or 降低learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator_i = discriminator()\n",
    "discriminator_i.compile(optimizer=adam , loss='binary_crossentropy' , metrics=['accuracy'])\n",
    "\n",
    "\n",
    "encoder_i = encoder()\n",
    "decoder_i = decoder()\n",
    "\n",
    "image = Input(shape=(HEIGHT , WIDTH , CHANNEL))\n",
    "\n",
    "encoder_feature = encoder_i(image)\n",
    "image_hat = decoder_i(encoder_feature)\n",
    "\n",
    "discriminator_i.trainable = False\n",
    "\n",
    "validity = discriminator_i(encoder_feature)\n",
    "\n",
    "#aae为重新构造的组合model\n",
    "aae = Model(image , [image_hat , validity])\n",
    "\n",
    "aae.compile(optimizer=adam , loss=['mse' , 'binary_crossentropy'] , loss_weights = [0.999 , 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 loss:0.760958 accu:0.253906 aae_loss_1:0.385436 aae_loss_2:0.384872\n",
      "epoch:1 loss:1.474787 accu:0.472656 aae_loss_1:0.368721 aae_loss_2:0.366708\n",
      "epoch:2 loss:0.774396 accu:0.636719 aae_loss_1:0.368552 aae_loss_2:0.364419\n",
      "epoch:3 loss:1.369915 accu:0.597656 aae_loss_1:0.354331 aae_loss_2:0.351153\n",
      "epoch:4 loss:2.690154 accu:0.464844 aae_loss_1:0.359615 aae_loss_2:0.356323\n",
      "epoch:5 loss:2.424586 accu:0.449219 aae_loss_1:0.344994 aae_loss_2:0.339629\n",
      "epoch:6 loss:3.071923 accu:0.378906 aae_loss_1:0.346112 aae_loss_2:0.339765\n",
      "epoch:7 loss:2.815377 accu:0.382812 aae_loss_1:0.368055 aae_loss_2:0.358943\n",
      "epoch:8 loss:4.520477 accu:0.304688 aae_loss_1:0.371252 aae_loss_2:0.358368\n",
      "epoch:9 loss:0.495848 accu:0.550781 aae_loss_1:0.348392 aae_loss_2:0.333556\n",
      "epoch:10 loss:0.517954 accu:0.535156 aae_loss_1:0.352856 aae_loss_2:0.338217\n",
      "epoch:11 loss:0.514346 accu:0.542969 aae_loss_1:0.343539 aae_loss_2:0.329559\n",
      "epoch:12 loss:0.510888 accu:0.531250 aae_loss_1:0.353562 aae_loss_2:0.340126\n",
      "epoch:13 loss:0.510447 accu:0.519531 aae_loss_1:0.357158 aae_loss_2:0.344214\n",
      "epoch:14 loss:0.532690 accu:0.515625 aae_loss_1:0.341907 aae_loss_2:0.330705\n",
      "epoch:15 loss:0.523724 accu:0.546875 aae_loss_1:0.329993 aae_loss_2:0.318095\n",
      "epoch:16 loss:0.501282 accu:0.542969 aae_loss_1:0.336259 aae_loss_2:0.325082\n",
      "epoch:17 loss:0.506270 accu:0.539062 aae_loss_1:0.326178 aae_loss_2:0.314026\n",
      "epoch:18 loss:0.510512 accu:0.542969 aae_loss_1:0.326269 aae_loss_2:0.314730\n",
      "epoch:19 loss:0.490156 accu:0.582031 aae_loss_1:0.331678 aae_loss_2:0.320172\n",
      "epoch:20 loss:0.480351 accu:0.566406 aae_loss_1:0.318164 aae_loss_2:0.308221\n",
      "epoch:21 loss:0.497040 accu:0.566406 aae_loss_1:0.318736 aae_loss_2:0.310221\n",
      "epoch:22 loss:0.508932 accu:0.589844 aae_loss_1:0.330352 aae_loss_2:0.322172\n",
      "epoch:23 loss:0.502595 accu:0.589844 aae_loss_1:0.303930 aae_loss_2:0.295436\n",
      "epoch:24 loss:0.494579 accu:0.609375 aae_loss_1:0.331639 aae_loss_2:0.323648\n",
      "epoch:25 loss:0.507875 accu:0.585938 aae_loss_1:0.279337 aae_loss_2:0.271005\n",
      "epoch:26 loss:0.467940 accu:0.621094 aae_loss_1:0.311855 aae_loss_2:0.303721\n",
      "epoch:27 loss:0.509198 accu:0.648438 aae_loss_1:0.268209 aae_loss_2:0.264951\n",
      "epoch:28 loss:0.446977 accu:0.636719 aae_loss_1:0.276590 aae_loss_2:0.266330\n",
      "epoch:29 loss:0.409804 accu:0.644531 aae_loss_1:0.265347 aae_loss_2:0.254492\n",
      "epoch:30 loss:0.417256 accu:0.644531 aae_loss_1:0.265621 aae_loss_2:0.253260\n",
      "epoch:31 loss:0.399026 accu:0.675781 aae_loss_1:0.336645 aae_loss_2:0.325135\n",
      "epoch:32 loss:0.402622 accu:0.695312 aae_loss_1:0.271155 aae_loss_2:0.260134\n",
      "epoch:33 loss:0.421071 accu:0.671875 aae_loss_1:0.306346 aae_loss_2:0.294281\n",
      "epoch:34 loss:0.393508 accu:0.683594 aae_loss_1:0.300353 aae_loss_2:0.287658\n",
      "epoch:35 loss:0.377605 accu:0.718750 aae_loss_1:0.298040 aae_loss_2:0.285719\n",
      "epoch:36 loss:0.384100 accu:0.710938 aae_loss_1:0.314589 aae_loss_2:0.302318\n",
      "epoch:37 loss:0.383479 accu:0.734375 aae_loss_1:0.297154 aae_loss_2:0.284178\n",
      "epoch:38 loss:0.372977 accu:0.734375 aae_loss_1:0.286640 aae_loss_2:0.275368\n",
      "epoch:39 loss:0.358124 accu:0.789062 aae_loss_1:0.298180 aae_loss_2:0.285934\n",
      "epoch:40 loss:0.361600 accu:0.812500 aae_loss_1:0.265329 aae_loss_2:0.253102\n",
      "epoch:41 loss:0.370130 accu:0.792969 aae_loss_1:0.278395 aae_loss_2:0.265348\n",
      "epoch:42 loss:0.359035 accu:0.796875 aae_loss_1:0.267894 aae_loss_2:0.254317\n",
      "epoch:43 loss:0.394173 accu:0.753906 aae_loss_1:0.263823 aae_loss_2:0.251017\n",
      "epoch:44 loss:0.373946 accu:0.804688 aae_loss_1:0.261813 aae_loss_2:0.248764\n",
      "epoch:45 loss:0.350362 accu:0.785156 aae_loss_1:0.253376 aae_loss_2:0.240144\n",
      "epoch:46 loss:0.331340 accu:0.816406 aae_loss_1:0.251258 aae_loss_2:0.236230\n",
      "epoch:47 loss:0.329968 accu:0.824219 aae_loss_1:0.269231 aae_loss_2:0.256198\n",
      "epoch:48 loss:0.321847 accu:0.835938 aae_loss_1:0.229492 aae_loss_2:0.216381\n",
      "epoch:49 loss:0.308763 accu:0.855469 aae_loss_1:0.234188 aae_loss_2:0.220868\n",
      "epoch:50 loss:0.308713 accu:0.902344 aae_loss_1:0.224544 aae_loss_2:0.211575\n",
      "epoch:51 loss:0.298463 accu:0.886719 aae_loss_1:0.249328 aae_loss_2:0.237024\n",
      "epoch:52 loss:0.274978 accu:0.941406 aae_loss_1:0.265249 aae_loss_2:0.251069\n",
      "epoch:53 loss:0.342048 accu:0.867188 aae_loss_1:0.245614 aae_loss_2:0.231880\n",
      "epoch:54 loss:0.319190 accu:0.855469 aae_loss_1:0.249736 aae_loss_2:0.235234\n",
      "epoch:55 loss:0.343576 accu:0.871094 aae_loss_1:0.253866 aae_loss_2:0.240454\n",
      "epoch:56 loss:0.332679 accu:0.886719 aae_loss_1:0.248349 aae_loss_2:0.235604\n",
      "epoch:57 loss:0.365815 accu:0.839844 aae_loss_1:0.241059 aae_loss_2:0.228585\n",
      "epoch:58 loss:0.316798 accu:0.886719 aae_loss_1:0.241198 aae_loss_2:0.227884\n",
      "epoch:59 loss:0.313626 accu:0.894531 aae_loss_1:0.254654 aae_loss_2:0.241025\n",
      "epoch:60 loss:0.328351 accu:0.859375 aae_loss_1:0.245145 aae_loss_2:0.231721\n",
      "epoch:61 loss:0.317135 accu:0.898438 aae_loss_1:0.240169 aae_loss_2:0.226873\n",
      "epoch:62 loss:0.322492 accu:0.929688 aae_loss_1:0.229252 aae_loss_2:0.216670\n",
      "epoch:63 loss:0.289245 accu:0.902344 aae_loss_1:0.234012 aae_loss_2:0.220369\n",
      "epoch:64 loss:0.274257 accu:0.933594 aae_loss_1:0.236074 aae_loss_2:0.222327\n",
      "epoch:65 loss:0.266603 accu:0.925781 aae_loss_1:0.242056 aae_loss_2:0.227578\n",
      "epoch:66 loss:0.298315 accu:0.945312 aae_loss_1:0.223126 aae_loss_2:0.209906\n",
      "epoch:67 loss:0.330211 accu:0.929688 aae_loss_1:0.239899 aae_loss_2:0.228912\n",
      "epoch:68 loss:0.260116 accu:0.945312 aae_loss_1:0.239171 aae_loss_2:0.225859\n",
      "epoch:69 loss:0.302991 accu:0.945312 aae_loss_1:0.256610 aae_loss_2:0.244928\n",
      "epoch:70 loss:0.296689 accu:0.933594 aae_loss_1:0.233244 aae_loss_2:0.220135\n",
      "epoch:71 loss:0.291509 accu:0.941406 aae_loss_1:0.259312 aae_loss_2:0.245732\n",
      "epoch:72 loss:0.478980 accu:0.867188 aae_loss_1:0.242933 aae_loss_2:0.228322\n",
      "epoch:73 loss:0.298568 accu:0.894531 aae_loss_1:0.218680 aae_loss_2:0.205172\n",
      "epoch:74 loss:0.338289 accu:0.800781 aae_loss_1:0.283810 aae_loss_2:0.270572\n",
      "epoch:75 loss:0.300003 accu:0.867188 aae_loss_1:0.245590 aae_loss_2:0.230876\n",
      "epoch:76 loss:0.294534 accu:0.898438 aae_loss_1:0.236779 aae_loss_2:0.222483\n",
      "epoch:77 loss:0.281398 accu:0.910156 aae_loss_1:0.244800 aae_loss_2:0.229834\n",
      "epoch:78 loss:0.319536 accu:0.859375 aae_loss_1:0.226993 aae_loss_2:0.212215\n",
      "epoch:79 loss:0.295281 accu:0.890625 aae_loss_1:0.217504 aae_loss_2:0.202996\n",
      "epoch:80 loss:0.275360 accu:0.937500 aae_loss_1:0.227525 aae_loss_2:0.212879\n",
      "epoch:81 loss:0.280821 accu:0.902344 aae_loss_1:0.244794 aae_loss_2:0.230391\n",
      "epoch:82 loss:0.255736 accu:0.917969 aae_loss_1:0.248196 aae_loss_2:0.232883\n",
      "epoch:83 loss:0.301749 accu:0.875000 aae_loss_1:0.232496 aae_loss_2:0.218239\n",
      "epoch:84 loss:0.302538 accu:0.878906 aae_loss_1:0.247450 aae_loss_2:0.234034\n",
      "epoch:85 loss:0.308146 accu:0.890625 aae_loss_1:0.227706 aae_loss_2:0.214442\n",
      "epoch:86 loss:0.302631 accu:0.898438 aae_loss_1:0.233293 aae_loss_2:0.219833\n",
      "epoch:87 loss:0.264102 accu:0.933594 aae_loss_1:0.235360 aae_loss_2:0.221166\n",
      "epoch:88 loss:0.280044 accu:0.902344 aae_loss_1:0.222332 aae_loss_2:0.208521\n",
      "epoch:89 loss:0.288026 accu:0.937500 aae_loss_1:0.215632 aae_loss_2:0.201946\n",
      "epoch:90 loss:0.249413 accu:0.957031 aae_loss_1:0.209955 aae_loss_2:0.196081\n",
      "epoch:91 loss:0.267277 accu:0.933594 aae_loss_1:0.206639 aae_loss_2:0.192946\n",
      "epoch:92 loss:0.246686 accu:0.953125 aae_loss_1:0.229621 aae_loss_2:0.215226\n",
      "epoch:93 loss:0.244985 accu:0.953125 aae_loss_1:0.223133 aae_loss_2:0.208987\n",
      "epoch:94 loss:0.269112 accu:0.929688 aae_loss_1:0.224438 aae_loss_2:0.211248\n",
      "epoch:95 loss:0.238358 accu:0.953125 aae_loss_1:0.224103 aae_loss_2:0.210570\n",
      "epoch:96 loss:0.245407 accu:0.949219 aae_loss_1:0.211429 aae_loss_2:0.198020\n",
      "epoch:97 loss:0.226269 accu:0.968750 aae_loss_1:0.215979 aae_loss_2:0.201657\n",
      "epoch:98 loss:0.247979 accu:0.949219 aae_loss_1:0.208770 aae_loss_2:0.195245\n",
      "epoch:99 loss:0.239237 accu:0.957031 aae_loss_1:0.238772 aae_loss_2:0.225722\n",
      "epoch:100 loss:0.246959 accu:0.949219 aae_loss_1:0.231987 aae_loss_2:0.218521\n",
      "epoch:101 loss:0.231143 accu:0.953125 aae_loss_1:0.208305 aae_loss_2:0.194470\n",
      "epoch:102 loss:0.223349 accu:0.980469 aae_loss_1:0.230475 aae_loss_2:0.216685\n",
      "epoch:103 loss:0.215023 accu:0.984375 aae_loss_1:0.223624 aae_loss_2:0.209615\n",
      "epoch:104 loss:0.228280 accu:0.964844 aae_loss_1:0.242264 aae_loss_2:0.229204\n",
      "epoch:105 loss:0.209750 accu:0.980469 aae_loss_1:0.217279 aae_loss_2:0.203583\n",
      "epoch:106 loss:0.201689 accu:0.972656 aae_loss_1:0.211507 aae_loss_2:0.197887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:107 loss:0.208827 accu:0.988281 aae_loss_1:0.220064 aae_loss_2:0.206522\n",
      "epoch:108 loss:0.212189 accu:0.968750 aae_loss_1:0.228173 aae_loss_2:0.213940\n",
      "epoch:109 loss:0.207834 accu:0.964844 aae_loss_1:0.238820 aae_loss_2:0.225270\n",
      "epoch:110 loss:0.198953 accu:0.980469 aae_loss_1:0.231217 aae_loss_2:0.217596\n",
      "epoch:111 loss:0.174124 accu:0.996094 aae_loss_1:0.224593 aae_loss_2:0.210338\n",
      "epoch:112 loss:0.175385 accu:0.992188 aae_loss_1:0.220802 aae_loss_2:0.206034\n",
      "epoch:113 loss:0.163089 accu:1.000000 aae_loss_1:0.215603 aae_loss_2:0.201254\n",
      "epoch:114 loss:0.148157 accu:0.996094 aae_loss_1:0.301502 aae_loss_2:0.285811\n",
      "epoch:115 loss:0.219028 accu:0.941406 aae_loss_1:0.202640 aae_loss_2:0.189280\n",
      "epoch:116 loss:0.906095 accu:0.937500 aae_loss_1:0.235861 aae_loss_2:0.221703\n",
      "epoch:117 loss:0.172958 accu:0.980469 aae_loss_1:0.225758 aae_loss_2:0.211546\n",
      "epoch:118 loss:0.163587 accu:0.984375 aae_loss_1:0.237572 aae_loss_2:0.222625\n",
      "epoch:119 loss:0.181927 accu:0.953125 aae_loss_1:0.228114 aae_loss_2:0.214163\n",
      "epoch:120 loss:0.220506 accu:0.960938 aae_loss_1:0.218034 aae_loss_2:0.203731\n",
      "epoch:121 loss:1.115116 accu:0.929688 aae_loss_1:0.228200 aae_loss_2:0.214309\n",
      "epoch:122 loss:0.158750 accu:0.984375 aae_loss_1:0.233523 aae_loss_2:0.218449\n",
      "epoch:123 loss:0.168393 accu:0.980469 aae_loss_1:0.244032 aae_loss_2:0.229496\n",
      "epoch:124 loss:0.155410 accu:0.980469 aae_loss_1:0.224848 aae_loss_2:0.209755\n",
      "epoch:125 loss:0.159022 accu:0.996094 aae_loss_1:0.223253 aae_loss_2:0.208069\n",
      "epoch:126 loss:0.160489 accu:0.984375 aae_loss_1:0.218086 aae_loss_2:0.202966\n",
      "epoch:127 loss:0.149147 accu:0.992188 aae_loss_1:0.212865 aae_loss_2:0.197613\n",
      "epoch:128 loss:0.144594 accu:0.992188 aae_loss_1:0.224921 aae_loss_2:0.209575\n",
      "epoch:129 loss:0.157731 accu:0.980469 aae_loss_1:0.216066 aae_loss_2:0.201311\n",
      "epoch:130 loss:0.165650 accu:0.960938 aae_loss_1:0.213054 aae_loss_2:0.198447\n",
      "epoch:131 loss:0.140250 accu:0.996094 aae_loss_1:0.217839 aae_loss_2:0.202436\n",
      "epoch:132 loss:0.132461 accu:0.992188 aae_loss_1:0.223862 aae_loss_2:0.208574\n",
      "epoch:133 loss:0.129874 accu:0.996094 aae_loss_1:0.220482 aae_loss_2:0.205279\n",
      "epoch:134 loss:0.138913 accu:0.988281 aae_loss_1:0.202374 aae_loss_2:0.187434\n",
      "epoch:135 loss:0.121306 accu:0.996094 aae_loss_1:0.217931 aae_loss_2:0.202708\n",
      "epoch:136 loss:0.142366 accu:0.988281 aae_loss_1:0.214821 aae_loss_2:0.199990\n",
      "epoch:137 loss:0.124781 accu:0.996094 aae_loss_1:0.203007 aae_loss_2:0.187514\n",
      "epoch:138 loss:0.168985 accu:0.984375 aae_loss_1:0.208217 aae_loss_2:0.193366\n",
      "epoch:139 loss:0.564733 accu:0.960938 aae_loss_1:0.210808 aae_loss_2:0.196356\n",
      "epoch:140 loss:0.674795 accu:0.964844 aae_loss_1:0.218395 aae_loss_2:0.203627\n",
      "epoch:141 loss:0.180279 accu:0.941406 aae_loss_1:0.221701 aae_loss_2:0.208471\n",
      "epoch:142 loss:0.180143 accu:0.949219 aae_loss_1:0.215034 aae_loss_2:0.202051\n",
      "epoch:143 loss:0.197141 accu:0.957031 aae_loss_1:0.221997 aae_loss_2:0.208329\n",
      "epoch:144 loss:0.723141 accu:0.921875 aae_loss_1:0.220267 aae_loss_2:0.206401\n",
      "epoch:145 loss:0.142671 accu:0.984375 aae_loss_1:0.218659 aae_loss_2:0.204418\n",
      "epoch:146 loss:0.158552 accu:0.960938 aae_loss_1:0.202120 aae_loss_2:0.188168\n",
      "epoch:147 loss:0.126827 accu:0.984375 aae_loss_1:0.224242 aae_loss_2:0.209735\n",
      "epoch:148 loss:0.113614 accu:1.000000 aae_loss_1:0.233162 aae_loss_2:0.217968\n",
      "epoch:149 loss:0.135731 accu:0.984375 aae_loss_1:0.220602 aae_loss_2:0.206240\n",
      "epoch:150 loss:0.120291 accu:0.988281 aae_loss_1:0.215135 aae_loss_2:0.200704\n",
      "epoch:151 loss:0.132625 accu:0.984375 aae_loss_1:0.215874 aae_loss_2:0.200873\n",
      "epoch:152 loss:0.116840 accu:0.992188 aae_loss_1:0.229425 aae_loss_2:0.214252\n",
      "epoch:153 loss:0.133260 accu:0.984375 aae_loss_1:0.225479 aae_loss_2:0.210887\n",
      "epoch:154 loss:0.118118 accu:0.980469 aae_loss_1:0.230407 aae_loss_2:0.215311\n",
      "epoch:155 loss:0.111576 accu:1.000000 aae_loss_1:0.230327 aae_loss_2:0.215166\n",
      "epoch:156 loss:0.108480 accu:0.992188 aae_loss_1:0.215403 aae_loss_2:0.200256\n",
      "epoch:157 loss:0.098751 accu:0.996094 aae_loss_1:0.225895 aae_loss_2:0.210366\n",
      "epoch:158 loss:0.095148 accu:0.996094 aae_loss_1:0.211436 aae_loss_2:0.195947\n",
      "epoch:159 loss:0.108431 accu:0.984375 aae_loss_1:0.220678 aae_loss_2:0.205255\n",
      "epoch:160 loss:0.094659 accu:1.000000 aae_loss_1:0.214905 aae_loss_2:0.199330\n",
      "epoch:161 loss:0.093817 accu:0.996094 aae_loss_1:0.208684 aae_loss_2:0.193134\n",
      "epoch:162 loss:0.091829 accu:0.996094 aae_loss_1:0.218537 aae_loss_2:0.202823\n",
      "epoch:163 loss:0.091521 accu:1.000000 aae_loss_1:0.227922 aae_loss_2:0.212104\n",
      "epoch:164 loss:0.086146 accu:1.000000 aae_loss_1:0.236953 aae_loss_2:0.221220\n",
      "epoch:165 loss:0.087746 accu:1.000000 aae_loss_1:0.253198 aae_loss_2:0.237317\n",
      "epoch:166 loss:0.116299 accu:0.988281 aae_loss_1:0.243620 aae_loss_2:0.228848\n",
      "epoch:167 loss:0.118047 accu:0.988281 aae_loss_1:0.240072 aae_loss_2:0.225784\n",
      "epoch:168 loss:0.098135 accu:0.988281 aae_loss_1:0.224250 aae_loss_2:0.209035\n",
      "epoch:169 loss:0.082466 accu:1.000000 aae_loss_1:0.217379 aae_loss_2:0.202223\n",
      "epoch:170 loss:0.102155 accu:0.984375 aae_loss_1:0.228835 aae_loss_2:0.214045\n",
      "epoch:171 loss:0.096597 accu:0.988281 aae_loss_1:0.221575 aae_loss_2:0.206764\n",
      "epoch:172 loss:0.694606 accu:0.960938 aae_loss_1:0.217855 aae_loss_2:0.203199\n",
      "epoch:173 loss:0.082444 accu:1.000000 aae_loss_1:0.207481 aae_loss_2:0.191743\n",
      "epoch:174 loss:0.092045 accu:0.996094 aae_loss_1:0.215994 aae_loss_2:0.200075\n",
      "epoch:175 loss:0.083217 accu:1.000000 aae_loss_1:0.210419 aae_loss_2:0.194797\n",
      "epoch:176 loss:0.081884 accu:0.996094 aae_loss_1:0.221960 aae_loss_2:0.206251\n",
      "epoch:177 loss:0.077789 accu:0.996094 aae_loss_1:0.212557 aae_loss_2:0.197149\n",
      "epoch:178 loss:0.079490 accu:1.000000 aae_loss_1:0.207921 aae_loss_2:0.192211\n",
      "epoch:179 loss:0.078220 accu:1.000000 aae_loss_1:0.209321 aae_loss_2:0.193507\n",
      "epoch:180 loss:0.081516 accu:1.000000 aae_loss_1:0.213167 aae_loss_2:0.197447\n",
      "epoch:181 loss:0.081810 accu:0.992188 aae_loss_1:0.200396 aae_loss_2:0.184584\n",
      "epoch:182 loss:0.076565 accu:1.000000 aae_loss_1:0.208794 aae_loss_2:0.192910\n",
      "epoch:183 loss:0.076159 accu:1.000000 aae_loss_1:0.207081 aae_loss_2:0.191154\n",
      "epoch:184 loss:1.758696 accu:0.894531 aae_loss_1:0.339103 aae_loss_2:0.327186\n",
      "epoch:185 loss:0.073649 accu:1.000000 aae_loss_1:0.240902 aae_loss_2:0.225171\n",
      "epoch:186 loss:0.077034 accu:0.996094 aae_loss_1:0.253818 aae_loss_2:0.238143\n",
      "epoch:187 loss:0.096137 accu:0.976562 aae_loss_1:0.218739 aae_loss_2:0.203625\n",
      "epoch:188 loss:0.076565 accu:0.996094 aae_loss_1:0.226592 aae_loss_2:0.210980\n",
      "epoch:189 loss:0.067156 accu:1.000000 aae_loss_1:0.222387 aae_loss_2:0.206569\n",
      "epoch:190 loss:0.079034 accu:0.996094 aae_loss_1:0.222258 aae_loss_2:0.206759\n",
      "epoch:191 loss:0.067991 accu:1.000000 aae_loss_1:0.223919 aae_loss_2:0.208100\n",
      "epoch:192 loss:0.065555 accu:1.000000 aae_loss_1:0.222893 aae_loss_2:0.206982\n",
      "epoch:193 loss:0.068473 accu:0.996094 aae_loss_1:0.234315 aae_loss_2:0.218563\n",
      "epoch:194 loss:0.074828 accu:1.000000 aae_loss_1:0.225870 aae_loss_2:0.210098\n",
      "epoch:195 loss:0.072449 accu:1.000000 aae_loss_1:0.212062 aae_loss_2:0.196217\n",
      "epoch:196 loss:0.063712 accu:1.000000 aae_loss_1:0.215970 aae_loss_2:0.200052\n",
      "epoch:197 loss:0.063423 accu:1.000000 aae_loss_1:0.222411 aae_loss_2:0.206500\n",
      "epoch:198 loss:0.064017 accu:1.000000 aae_loss_1:0.213919 aae_loss_2:0.197999\n",
      "epoch:199 loss:0.058726 accu:1.000000 aae_loss_1:0.211319 aae_loss_2:0.195396\n",
      "epoch:200 loss:0.064392 accu:1.000000 aae_loss_1:0.205116 aae_loss_2:0.189187\n",
      "epoch:201 loss:0.059995 accu:1.000000 aae_loss_1:0.201400 aae_loss_2:0.185467\n",
      "epoch:202 loss:0.058364 accu:1.000000 aae_loss_1:0.216636 aae_loss_2:0.200743\n",
      "epoch:203 loss:0.056332 accu:1.000000 aae_loss_1:0.212244 aae_loss_2:0.196322\n",
      "epoch:204 loss:0.060113 accu:1.000000 aae_loss_1:0.210440 aae_loss_2:0.194516\n",
      "epoch:205 loss:0.056657 accu:1.000000 aae_loss_1:0.201850 aae_loss_2:0.185918\n",
      "epoch:206 loss:0.056578 accu:1.000000 aae_loss_1:0.203843 aae_loss_2:0.187913\n",
      "epoch:207 loss:0.055673 accu:1.000000 aae_loss_1:0.223375 aae_loss_2:0.207464\n",
      "epoch:208 loss:0.060442 accu:1.000000 aae_loss_1:0.211824 aae_loss_2:0.195902\n",
      "epoch:209 loss:0.075567 accu:0.976562 aae_loss_1:0.237330 aae_loss_2:0.222482\n",
      "epoch:210 loss:0.071956 accu:0.984375 aae_loss_1:0.220226 aae_loss_2:0.205072\n",
      "epoch:211 loss:0.080410 accu:0.972656 aae_loss_1:0.217548 aae_loss_2:0.202579\n",
      "epoch:212 loss:0.065742 accu:0.992188 aae_loss_1:0.214826 aae_loss_2:0.199383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:213 loss:0.061381 accu:0.992188 aae_loss_1:0.210854 aae_loss_2:0.195277\n",
      "epoch:214 loss:0.060061 accu:0.996094 aae_loss_1:0.221319 aae_loss_2:0.205589\n",
      "epoch:215 loss:0.054179 accu:1.000000 aae_loss_1:0.220636 aae_loss_2:0.204883\n",
      "epoch:216 loss:0.051971 accu:1.000000 aae_loss_1:0.223423 aae_loss_2:0.207513\n",
      "epoch:217 loss:0.053617 accu:1.000000 aae_loss_1:0.209276 aae_loss_2:0.193352\n",
      "epoch:218 loss:0.051067 accu:1.000000 aae_loss_1:0.225706 aae_loss_2:0.209964\n",
      "epoch:219 loss:0.050281 accu:1.000000 aae_loss_1:0.214499 aae_loss_2:0.198688\n",
      "epoch:220 loss:0.046443 accu:1.000000 aae_loss_1:0.205519 aae_loss_2:0.189591\n",
      "epoch:221 loss:0.050374 accu:1.000000 aae_loss_1:0.224609 aae_loss_2:0.208713\n",
      "epoch:222 loss:0.047786 accu:1.000000 aae_loss_1:0.213368 aae_loss_2:0.197558\n",
      "epoch:223 loss:0.046861 accu:1.000000 aae_loss_1:0.221177 aae_loss_2:0.205264\n",
      "epoch:224 loss:0.046570 accu:1.000000 aae_loss_1:0.208443 aae_loss_2:0.192611\n",
      "epoch:225 loss:0.054550 accu:1.000000 aae_loss_1:0.212118 aae_loss_2:0.196316\n",
      "epoch:226 loss:0.046474 accu:1.000000 aae_loss_1:0.202748 aae_loss_2:0.186869\n",
      "epoch:227 loss:0.042449 accu:1.000000 aae_loss_1:0.220627 aae_loss_2:0.204714\n",
      "epoch:228 loss:0.043714 accu:1.000000 aae_loss_1:0.210290 aae_loss_2:0.194423\n",
      "epoch:229 loss:0.044283 accu:1.000000 aae_loss_1:0.212826 aae_loss_2:0.196905\n",
      "epoch:230 loss:0.039664 accu:1.000000 aae_loss_1:0.205898 aae_loss_2:0.189970\n",
      "epoch:231 loss:0.039173 accu:1.000000 aae_loss_1:0.206751 aae_loss_2:0.190871\n",
      "epoch:232 loss:0.039775 accu:1.000000 aae_loss_1:0.201156 aae_loss_2:0.185223\n",
      "epoch:233 loss:0.043532 accu:1.000000 aae_loss_1:0.204118 aae_loss_2:0.188188\n",
      "epoch:234 loss:0.051156 accu:1.000000 aae_loss_1:0.214733 aae_loss_2:0.199215\n",
      "epoch:235 loss:0.041840 accu:1.000000 aae_loss_1:0.206684 aae_loss_2:0.190850\n",
      "epoch:236 loss:0.042655 accu:1.000000 aae_loss_1:0.225444 aae_loss_2:0.209535\n",
      "epoch:237 loss:0.039684 accu:1.000000 aae_loss_1:0.216380 aae_loss_2:0.200511\n",
      "epoch:238 loss:0.038219 accu:1.000000 aae_loss_1:0.229687 aae_loss_2:0.213783\n",
      "epoch:239 loss:0.040024 accu:1.000000 aae_loss_1:0.206268 aae_loss_2:0.190512\n",
      "epoch:240 loss:0.036824 accu:1.000000 aae_loss_1:0.223308 aae_loss_2:0.207397\n",
      "epoch:241 loss:0.038785 accu:1.000000 aae_loss_1:0.211045 aae_loss_2:0.195122\n",
      "epoch:242 loss:0.046119 accu:0.992188 aae_loss_1:0.219942 aae_loss_2:0.204929\n",
      "epoch:243 loss:0.069111 accu:0.976562 aae_loss_1:0.227851 aae_loss_2:0.213088\n",
      "epoch:244 loss:0.054882 accu:0.988281 aae_loss_1:0.217228 aae_loss_2:0.202282\n",
      "epoch:245 loss:0.042829 accu:1.000000 aae_loss_1:0.198717 aae_loss_2:0.183105\n",
      "epoch:246 loss:0.060456 accu:0.984375 aae_loss_1:0.194214 aae_loss_2:0.178957\n",
      "epoch:247 loss:0.053078 accu:0.992188 aae_loss_1:0.204029 aae_loss_2:0.188899\n",
      "epoch:248 loss:0.053139 accu:0.992188 aae_loss_1:0.197466 aae_loss_2:0.182190\n",
      "epoch:249 loss:0.035355 accu:1.000000 aae_loss_1:0.223993 aae_loss_2:0.208250\n",
      "epoch:250 loss:0.035957 accu:1.000000 aae_loss_1:0.194150 aae_loss_2:0.178387\n",
      "epoch:251 loss:0.040942 accu:0.996094 aae_loss_1:0.206300 aae_loss_2:0.190843\n",
      "epoch:252 loss:0.035438 accu:1.000000 aae_loss_1:0.199323 aae_loss_2:0.183552\n",
      "epoch:253 loss:0.038101 accu:1.000000 aae_loss_1:0.209938 aae_loss_2:0.194086\n",
      "epoch:254 loss:0.065475 accu:0.992188 aae_loss_1:0.211429 aae_loss_2:0.196066\n",
      "epoch:255 loss:0.037703 accu:1.000000 aae_loss_1:0.210122 aae_loss_2:0.194312\n",
      "epoch:256 loss:0.036281 accu:0.996094 aae_loss_1:0.210194 aae_loss_2:0.194597\n",
      "epoch:257 loss:0.032997 accu:1.000000 aae_loss_1:0.204957 aae_loss_2:0.189183\n",
      "epoch:258 loss:0.058802 accu:0.996094 aae_loss_1:0.205581 aae_loss_2:0.189870\n",
      "epoch:259 loss:0.040075 accu:0.996094 aae_loss_1:0.218657 aae_loss_2:0.202868\n",
      "epoch:260 loss:0.344883 accu:0.980469 aae_loss_1:0.256118 aae_loss_2:0.241009\n",
      "epoch:261 loss:0.033465 accu:1.000000 aae_loss_1:0.223515 aae_loss_2:0.207779\n",
      "epoch:262 loss:0.533350 accu:0.964844 aae_loss_1:0.245694 aae_loss_2:0.229806\n",
      "epoch:263 loss:0.068496 accu:0.968750 aae_loss_1:0.233933 aae_loss_2:0.219234\n",
      "epoch:264 loss:0.059461 accu:0.984375 aae_loss_1:0.233842 aae_loss_2:0.218800\n",
      "epoch:265 loss:0.045361 accu:0.992188 aae_loss_1:0.220962 aae_loss_2:0.205376\n",
      "epoch:266 loss:0.050383 accu:0.988281 aae_loss_1:0.208713 aae_loss_2:0.193348\n",
      "epoch:267 loss:0.062223 accu:0.980469 aae_loss_1:0.205371 aae_loss_2:0.190175\n",
      "epoch:268 loss:0.042867 accu:0.996094 aae_loss_1:0.202606 aae_loss_2:0.187001\n",
      "epoch:269 loss:0.040072 accu:0.996094 aae_loss_1:0.204460 aae_loss_2:0.188654\n",
      "epoch:270 loss:0.034938 accu:1.000000 aae_loss_1:0.202446 aae_loss_2:0.186514\n",
      "epoch:271 loss:0.038393 accu:1.000000 aae_loss_1:0.207695 aae_loss_2:0.191904\n",
      "epoch:272 loss:0.047411 accu:0.996094 aae_loss_1:0.197788 aae_loss_2:0.182230\n",
      "epoch:273 loss:0.048177 accu:0.988281 aae_loss_1:0.210001 aae_loss_2:0.194481\n",
      "epoch:274 loss:0.034539 accu:1.000000 aae_loss_1:0.196987 aae_loss_2:0.181207\n",
      "epoch:275 loss:0.034178 accu:1.000000 aae_loss_1:0.194676 aae_loss_2:0.178789\n",
      "epoch:276 loss:0.036177 accu:1.000000 aae_loss_1:0.220706 aae_loss_2:0.204793\n",
      "epoch:277 loss:0.035451 accu:0.996094 aae_loss_1:0.197356 aae_loss_2:0.181538\n",
      "epoch:278 loss:0.036011 accu:1.000000 aae_loss_1:0.203484 aae_loss_2:0.187553\n",
      "epoch:279 loss:0.032927 accu:1.000000 aae_loss_1:0.196688 aae_loss_2:0.180751\n",
      "epoch:280 loss:0.032828 accu:1.000000 aae_loss_1:0.200763 aae_loss_2:0.184829\n",
      "epoch:281 loss:0.037412 accu:1.000000 aae_loss_1:0.207357 aae_loss_2:0.191430\n",
      "epoch:282 loss:0.036972 accu:1.000000 aae_loss_1:0.204207 aae_loss_2:0.188363\n",
      "epoch:283 loss:0.034972 accu:1.000000 aae_loss_1:0.207402 aae_loss_2:0.191475\n",
      "epoch:284 loss:0.033929 accu:1.000000 aae_loss_1:0.194912 aae_loss_2:0.178973\n",
      "epoch:285 loss:0.035545 accu:1.000000 aae_loss_1:0.205190 aae_loss_2:0.189261\n",
      "epoch:286 loss:0.032144 accu:1.000000 aae_loss_1:0.184984 aae_loss_2:0.169035\n",
      "epoch:287 loss:0.031069 accu:1.000000 aae_loss_1:0.207060 aae_loss_2:0.191133\n",
      "epoch:288 loss:0.028754 accu:1.000000 aae_loss_1:0.194558 aae_loss_2:0.178618\n",
      "epoch:289 loss:0.032653 accu:1.000000 aae_loss_1:0.214472 aae_loss_2:0.198568\n",
      "epoch:290 loss:0.030671 accu:1.000000 aae_loss_1:0.222222 aae_loss_2:0.206310\n",
      "epoch:291 loss:0.031187 accu:1.000000 aae_loss_1:0.218827 aae_loss_2:0.202912\n",
      "epoch:292 loss:0.033625 accu:0.996094 aae_loss_1:0.237017 aae_loss_2:0.221243\n",
      "epoch:293 loss:0.031522 accu:1.000000 aae_loss_1:0.210969 aae_loss_2:0.195046\n",
      "epoch:294 loss:0.028854 accu:1.000000 aae_loss_1:0.206698 aae_loss_2:0.190771\n",
      "epoch:295 loss:0.028479 accu:1.000000 aae_loss_1:0.211195 aae_loss_2:0.195272\n",
      "epoch:296 loss:0.027071 accu:1.000000 aae_loss_1:0.215412 aae_loss_2:0.199493\n",
      "epoch:297 loss:0.030425 accu:1.000000 aae_loss_1:0.213924 aae_loss_2:0.198004\n",
      "epoch:298 loss:0.028013 accu:1.000000 aae_loss_1:0.204994 aae_loss_2:0.189065\n",
      "epoch:299 loss:0.027312 accu:1.000000 aae_loss_1:0.210958 aae_loss_2:0.195035\n",
      "epoch:300 loss:0.027603 accu:1.000000 aae_loss_1:0.213361 aae_loss_2:0.197440\n",
      "epoch:301 loss:0.030477 accu:1.000000 aae_loss_1:0.217736 aae_loss_2:0.201819\n",
      "epoch:302 loss:0.027987 accu:1.000000 aae_loss_1:0.214211 aae_loss_2:0.198291\n",
      "epoch:303 loss:0.029609 accu:1.000000 aae_loss_1:0.230566 aae_loss_2:0.214777\n",
      "epoch:304 loss:0.027692 accu:0.996094 aae_loss_1:0.226174 aae_loss_2:0.210386\n",
      "epoch:305 loss:0.028548 accu:1.000000 aae_loss_1:0.207853 aae_loss_2:0.191955\n",
      "epoch:306 loss:0.026081 accu:1.000000 aae_loss_1:0.211860 aae_loss_2:0.195938\n"
     ]
    }
   ],
   "source": [
    "real_labels = np.ones(shape=(BATCH_SIZE , 1)) #真实样本label为1\n",
    "fake_labels = np.zeros(shape=(BATCH_SIZE , 1)) #假样本label为0\n",
    "\n",
    "for i in range(1000):\n",
    "    for j in range(int(IMAGES_COUNT/BATCH_SIZE)):\n",
    "        noise_encoder_feature = np.random.normal(size=(BATCH_SIZE , LATENT_DIM))\n",
    "\n",
    "        real_image = load_image()\n",
    "        #训练判别器\n",
    "        real_encoder_feature = encoder_i.predict(real_image)\n",
    "\n",
    "        #从高斯分布采样的噪声 与 True label 组成训练集\n",
    "        #真实的图像经过encoder后得到的特征与 False label 组成训练集\n",
    "        noise_loss = discriminator_i.train_on_batch(noise_encoder_feature , real_labels)\n",
    "        real_loss = discriminator_i.train_on_batch(real_encoder_feature , fake_labels)\n",
    "\n",
    "        loss = np.add(noise_loss , real_loss)/2\n",
    "\n",
    "        #训练aae\n",
    "        aae_loss = aae.train_on_batch(real_image , [real_image , real_labels])\n",
    "\n",
    "        print('epoch:%d batch:%d loss:%f accu:%f aae_loss_1:%f aae_loss_2:%f' % (i , j , loss[0] , loss[1] , aae_loss[0] , aae_loss[1]))\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            write_image(i)\n",
    "    \n",
    "write_image(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator (Sequential)   (None, 1)                 533505    \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 0\n",
      "Non-trainable params: 533,505\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator (Sequential)       (None, 28, 28, 1)         1097744   \n",
      "=================================================================\n",
      "Total params: 1,097,744\n",
      "Trainable params: 1,095,184\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z (InputLayer)               (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "generator_Model (Model)      (None, 96, 96, 3)         29029120  \n",
      "_________________________________________________________________\n",
      "discriminator_Model (Model)  (None, 1)                 14320641  \n",
      "=================================================================\n",
      "Total params: 43,349,761\n",
      "Trainable params: 29,025,536\n",
      "Non-trainable params: 14,324,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined_model_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modeli = Sequential()\n",
    "\n",
    "modeli.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=(LATENT_DIM,)))\n",
    "modeli.add(Reshape((7, 7, 128)))\n",
    "modeli.add(UpSampling2D())\n",
    "modeli.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "modeli.add(BatchNormalization(momentum=0.8))\n",
    "modeli.add(Activation(\"relu\"))\n",
    "modeli.add(UpSampling2D())\n",
    "modeli.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "modeli.add(BatchNormalization(momentum=0.8))\n",
    "modeli.add(Activation(\"relu\"))\n",
    "modeli.add(Conv2D(CHANNEL, kernel_size=3, padding=\"same\"))\n",
    "modeli.add(Activation(\"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modeli.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_inbound_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-514ad70b5d55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-17d76ed16df1>\u001b[0m in \u001b[0;36mencoder\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mencoder_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmean\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mencoder_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[1;32m--> 235\u001b[1;33m             self.inputs, self.outputs)\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1410\u001b[0m                   \u001b[0mlayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                   \u001b[0mnode_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1412\u001b[1;33m                   tensor_index=tensor_index)\n\u001b[0m\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[1;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[0;32m   1397\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[1;32m-> 1399\u001b[1;33m                       node_index, tensor_index)\n\u001b[0m\u001b[0;32m   1400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[1;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[0;32m   1397\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[1;32m-> 1399\u001b[1;33m                       node_index, tensor_index)\n\u001b[0m\u001b[0;32m   1400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[1;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[0;32m   1369\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcycle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdetected\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \"\"\"\n\u001b[1;32m-> 1371\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[1;31m# Prevent cycles.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_inbound_nodes'"
     ]
    }
   ],
   "source": [
    "aa=encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
